{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_0sryk6FzyU"
      },
      "source": [
        "# Building a RAG application from scratch\n",
        "\n",
        "Here is a high-level overview of the system we want to build:\n",
        "\n",
        "<img src='https://github.com/haoransun/youtube-rag/blob/main/images/system1.png?raw=1' width=\"1200\">"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install langchain_community\n",
        "!pip install wikipedia\n",
        "!pip install sentence_transformers\n",
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU-cT4puGZKC",
        "outputId": "f98ec706-6c26-4a15-d4fd-90cf73e1c9a4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.9)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.10 (from langchain_community)\n",
            "  Downloading langchain-0.3.10-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.22 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.22-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.10->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.10->langchain_community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.28.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.10->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.10->langchain_community) (2.27.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.3.10-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.10-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.22-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.7/409.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.21\n",
            "    Uninstalling langchain-core-0.3.21:\n",
            "      Successfully uninstalled langchain-core-0.3.21\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.9\n",
            "    Uninstalling langchain-0.3.9:\n",
            "      Successfully uninstalled langchain-0.3.9\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.10 langchain-core-0.3.22 langchain_community-0.3.10 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=d4550c7e2f950b32b8945432450824e835c3f456331dae810c8c9bbb7b9291fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.26.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6L-AyCEbKEW",
        "outputId": "fd6a77c3-396e-45e6-8dfb-b7854e0c0ff8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.3.22)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.54.5)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.28.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.66.6)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain_openai) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain_openai) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.3)\n",
            "Downloading langchain_openai-0.2.11-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain_openai\n",
            "Successfully installed langchain_openai-0.2.11 tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n"
      ],
      "metadata": {
        "id": "ZQzgZRxX8frh",
        "outputId": "42c750fe-35cb-41f5-9f37-42137e208dd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF"
      ],
      "metadata": {
        "id": "gx-F6GE0BowE",
        "outputId": "0eee4afe-f244-4c51-d3f7-7cd8ed07f3e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from PyPDF) (4.12.2)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m235.5/298.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF\n",
            "Successfully installed PyPDF-5.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install load_dotenv\n",
        "!pip install whisper\n",
        "!pip install pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f97c57LnbPRR",
        "outputId": "5f107396-917a-4ad5-8daa-bbaaa5192d3e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting load_dotenv\n",
            "  Downloading load_dotenv-0.1.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from load_dotenv) (1.0.1)\n",
            "Downloading load_dotenv-0.1.0-py3-none-any.whl (7.2 kB)\n",
            "Installing collected packages: load_dotenv\n",
            "Successfully installed load_dotenv-0.1.0\n",
            "Collecting whisper\n",
            "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from whisper) (1.16.0)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41120 sha256=08909f72f8e44e1786240a2fc03264af4923955d2fe8734751ca644e0f437baa\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/7c/1d/015619716e2facae6631312503baf3c3220e6a9a3508cb14b6\n",
            "Successfully built whisper\n",
            "Installing collected packages: whisper\n",
            "Successfully installed whisper-1.1.10\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvBtNcGuHqLD",
        "outputId": "a573bc7b-0183-48f1-d106-ceca184f6307"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_pinecone\n",
            "  Downloading langchain_pinecone-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting aiohttp<3.10,>=3.9.5 (from langchain_pinecone)\n",
            "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (0.3.22)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (1.26.4)\n",
            "Collecting pinecone-client<6.0.0,>=5.0.0 (from langchain_pinecone)\n",
            "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (1.18.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (4.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (4.12.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2024.8.30)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone)\n",
            "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (4.66.6)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2.2.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain_pinecone) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (0.28.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain_pinecone) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain_pinecone) (2.27.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.10,>=3.9.5->langchain_pinecone) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.10,>=3.9.5->langchain_pinecone) (0.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (3.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_pinecone) (1.2.2)\n",
            "Downloading langchain_pinecone-0.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Installing collected packages: pinecone-plugin-interface, pinecone-plugin-inference, pinecone-client, aiohttp, langchain_pinecone\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.9\n",
            "    Uninstalling aiohttp-3.11.9:\n",
            "      Successfully uninstalled aiohttp-3.11.9\n",
            "Successfully installed aiohttp-3.9.5 langchain_pinecone-0.2.0 pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain import LLMChain\n",
        "from langchain import HuggingFaceHub"
      ],
      "metadata": {
        "id": "k4ITR_tuGbuq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4o6xqRBFzyX"
      },
      "source": [
        "Let's start by loading the environment variables we need to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "4HwAmGIsFzyY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# # This is the YouTube video we're going to use.\n",
        "YOUTUBE_VIDEO = \"https://www.youtube.com/watch?v=cdiD-9MMpb0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp8wMDR2FzyZ"
      },
      "source": [
        "## Setting up the model\n",
        "Let's define the LLM model that we'll use as part of the workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a7m68DJFzyZ"
      },
      "outputs": [],
      "source": [
        "# from langchain_openai.chat_models import ChatOpenAI\n",
        "\n",
        "# model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = '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'"
      ],
      "metadata": {
        "id": "S5SitAVQKbkR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = HuggingFaceHub(repo_id = \"google/gemma-2-2b-it\")#, model_kwargs = {\"temperature\":0.1, \"max_length\":64}) # general purpose\n"
      ],
      "metadata": {
        "id": "ZBUw-B4HKVHL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE_oE3pIFzyZ"
      },
      "source": [
        "We can test the model by asking a simple question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "rhLb3kPmFzya",
        "outputId": "5180784c-07a3-4a51-9ec8-10ecdfb5effa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What MLB team won the World Series during the COVID-19 pandemic?\\n\\nThe **Los Angeles Dodgers** won the World Series during the COVID-19 pandemic in 2020. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model.invoke(\"What MLB team won the World Series during the COVID-19 pandemic?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iai_O3ySFzya"
      },
      "source": [
        "The result from the model is an `AIMessage` instance containing the answer. We can extract this answer by chaining the model with an [output parser](https://python.langchain.com/docs/modules/model_io/output_parsers/).\n",
        "\n",
        "Here is what chaining the model with an output parser looks like:\n",
        "\n",
        "<img src='https://github.com/haoransun/youtube-rag/blob/main/images/chain1.png?raw=1' width=\"1200\">\n",
        "\n",
        "For this example, we'll use a simple `StrOutputParser` to extract the answer as a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "RiLNSPmgFzya",
        "outputId": "6b423ef9-f70a-421a-c8be-bafec958aab0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What MLB team won the World Series during the COVID-19 pandemic?\\n\\nThe **Los Angeles Dodgers** won the World Series during the COVID-19 pandemic in 2020. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "chain = model | parser\n",
        "chain.invoke(\"What MLB team won the World Series during the COVID-19 pandemic?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0Obozm1Fzyb"
      },
      "source": [
        "## Introducing prompt templates\n",
        "\n",
        "We want to provide the model with some context and the question. [Prompt templates](https://python.langchain.com/docs/modules/model_io/prompts/quick_start) are a simple way to define and reuse prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "MBmaRkTTFzyb",
        "outputId": "d74c0431-0a1b-4c9d-89d4-39b4fe7d80a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: \\nAnswer the question based on the context below. If you can\\'t\\nanswer the question, reply \"I don\\'t know\".\\n\\nContext: Mary\\'s sister is Susana\\n\\nQuestion: Who is Mary\\'s sister?\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "Answer the question based on the context below. If you can't\n",
        "answer the question, reply \"I don't know\".\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "prompt.format(context=\"Mary's sister is Susana\", question=\"Who is Mary's sister?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grating_template = \"\"\"\n",
        "Answer the question based on the context below. If you can answer that question,\n",
        "add addtional comments \"I am glad I can help you\".\n",
        "\n",
        "Context:{context}\n",
        "Question:{question}\n",
        "\"\"\"\n",
        "prompt_grating = ChatPromptTemplate.from_template(grating_template)\n",
        "prompt_grating.format(context=\"Mary'sister is Susana\", question=\"Who is Mary's sister\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "F4YOk9ItuLXv",
        "outputId": "ebb9e754-a641-4961-c169-d9bb7d083499"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: \\nAnswer the question based on the context below. If you can answer that question,\\nadd addtional comments \"I am glad I can help you\".\\n\\nContext:Mary\\'sister is Susana\\nQuestion:Who is Mary\\'s sister\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CL3u3wXFzyb"
      },
      "source": [
        "We can now chain the prompt with the model and the output parser.\n",
        "\n",
        "<img src='https://github.com/haoransun/youtube-rag/blob/main/images/chain2.png?raw=1' width=\"1200\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "eHBcHeACFzyb",
        "outputId": "a7bf895f-6224-4f80-be9c-59657dad2559"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: \\nAnswer the question based on the context below. If you can\\'t\\nanswer the question, reply \"I don\\'t know\".\\n\\nContext: Mary\\'s sister is Susana\\n\\nQuestion: Who is Mary\\'s sister?\\nAnswer: Susana \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "chain = prompt | model | parser\n",
        "chain.invoke({\n",
        "    \"context\": \"Mary's sister is Susana\",\n",
        "    \"question\": \"Who is Mary's sister?\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain2 = prompt |prompt_grating| model | parser\n",
        "chain.invoke({\n",
        "    \"context\": \"Mary's sister is Susana\",\n",
        "    \"question\": \"Who is Mary's sister?\"\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "rQIrKcNdu0az",
        "outputId": "c79ac873-25d5-457b-c03a-8436ba059ae1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: \\nAnswer the question based on the context below. If you can\\'t\\nanswer the question, reply \"I don\\'t know\".\\n\\nContext: Mary\\'s sister is Susana\\n\\nQuestion: Who is Mary\\'s sister?\\nAnswer: Susana \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6usW_yx9Fzyb"
      },
      "source": [
        "## Combining chains\n",
        "\n",
        "We can combine different chains to create more complex workflows. For example, let's create a second chain that translates the answer from the first chain into a different language.\n",
        "\n",
        "Let's start by creating a new prompt template for the translation chain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "CzSyFrAxFzyc"
      },
      "outputs": [],
      "source": [
        "translation_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Translate {answer} to {language}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws5XXY3CFzyc"
      },
      "source": [
        "We can now create a new translation chain that combines the result from the first chain with the translation prompt.\n",
        "\n",
        "Here is what the new workflow looks like:\n",
        "\n",
        "<img src='https://github.com/haoransun/youtube-rag/blob/main/images/chain3.png?raw=1' width=\"1200\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "YiUxZbHkFzyc",
        "outputId": "04f11c64-43c4-4475-feb8-17fb24946387"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: Translate Human: \\nAnswer the question based on the context below. If you can\\'t\\nanswer the question, reply \"I don\\'t know\".\\n\\nContext: Mary\\'s sister is Susana. She doesn\\'t have any more siblings.\\n\\nQuestion: How many sisters does Mary have?\\nAnswer: I don\\'t know. \\n to Spanish: \\nAnswer: I don\\'t know. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "translation_chain = (\n",
        "    {\"answer\": chain, \"language\": itemgetter(\"language\")} | translation_prompt | model | parser\n",
        ")\n",
        "\n",
        "translation_chain.invoke(\n",
        "    {\n",
        "        \"context\": \"Mary's sister is Susana. She doesn't have any more siblings.\",\n",
        "        \"question\": \"How many sisters does Mary have?\",\n",
        "        \"language\": \"Spanish\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiLRMj27Fzyc"
      },
      "source": [
        "## Transcribing the YouTube Video\n",
        "\n",
        "The context we want to send the model comes from a YouTube video. Let's download the video and transcribe it using [OpenAI's Whisper](https://openai.com/research/whisper)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "FrHHVejoFzyc",
        "outputId": "68b93895-1c19-47bb-dfb1-83d52053a5a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 403: Forbidden",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-10b6dc2ac047>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transcription.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0myoutube\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYouTube\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYOUTUBE_VIDEO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myoutube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly_audio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Let's load the base model. This is not the most accurate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/__main__.py\u001b[0m in \u001b[0;36mstreams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \"\"\"\n\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_availability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mStreamQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt_streams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/__main__.py\u001b[0m in \u001b[0;36mfmt_streams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fmt_streams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mstream_manifest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_descrambler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreaming_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# If the cached js doesn't work, try fetching a new js file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/__main__.py\u001b[0m in \u001b[0;36mstreaming_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvid_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'streamingData'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbypass_age_gate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvid_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'streamingData'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/__main__.py\u001b[0m in \u001b[0;36mbypass_age_gate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mallow_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_oauth_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         )\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0minnertube_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minnertube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mplayability_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minnertube_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'playabilityStatus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/innertube.py\u001b[0m in \u001b[0;36mplayer\u001b[0;34m(self, video_id)\u001b[0m\n\u001b[1;32m    446\u001b[0m         }\n\u001b[1;32m    447\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/innertube.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, endpoint, query, data)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         response = request._execute_request(\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0mendpoint_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;34m'POST'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/request.py\u001b[0m in \u001b[0;36m_execute_request\u001b[0;34m(url, method, headers, data, timeout)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid URL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# nosec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
          ]
        }
      ],
      "source": [
        "import tempfile\n",
        "import whisper\n",
        "from pytube import YouTube\n",
        "\n",
        "\n",
        "# Let's do this only if we haven't created the transcription file yet.\n",
        "if not os.path.exists(\"transcription.txt\"):\n",
        "    youtube = YouTube(YOUTUBE_VIDEO)\n",
        "    audio = youtube.streams.filter(only_audio=True).first()\n",
        "\n",
        "    # Let's load the base model. This is not the most accurate\n",
        "    # model but it's fast.\n",
        "    whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "    with tempfile.TemporaryDirectory() as tmpdir:\n",
        "        file = audio.download(output_path=tmpdir)\n",
        "        transcription = whisper_model.transcribe(file, fp16=False)[\"text\"].strip()\n",
        "\n",
        "        with open(\"transcription.txt\", \"w\") as file:\n",
        "            file.write(transcription)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxRTkq5zFzyc"
      },
      "source": [
        "Let's read the transcription and display the first few characters to ensure everything works as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "ssJxh1RjFzyc",
        "outputId": "20b329a2-884e-40e0-8ab6-f520c8e334c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I think it's possible that physics has exploits and we should be trying to find them. arranging some\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "with open(\"transcription.txt\") as file:\n",
        "    transcription = file.read()\n",
        "\n",
        "transcription[:100]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(transcription))"
      ],
      "metadata": {
        "id": "bch6WgGZApLq",
        "outputId": "a8ce8799-7a54-43ca-df06-0628b27df377",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Use 'with' to handle file operations\n",
        "with open(\"xstoresuite-2300-dpg.pdf\", \"rb\") as pdf_file:\n",
        "    reader = PdfReader(pdf_file)\n",
        "    for page in reader.pages:\n",
        "        transcription_xstore=page.extract_text().strip()\n",
        "        # print(transcription2)\n",
        "\n"
      ],
      "metadata": {
        "id": "1IFhrZ4l9p6n"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    print(type(transcription_xstore))"
      ],
      "metadata": {
        "id": "oeAkaoEW-_uB",
        "outputId": "95788b3c-13e9-4c9e-c324-d13f5f5af924",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFeSIfMxFzyd"
      },
      "source": [
        "## Using the entire transcription as context\n",
        "\n",
        "If we try to invoke the chain using the transcription as context, the model will return an error because the context is too long.\n",
        "\n",
        "Large Language Models support limitted context sizes. The video we are using is too long for the model to handle, so we need to find a different solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ZjV7QrFxFzyd"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    chain.invoke({\n",
        "        \"context\": transcription_xstore,\n",
        "        \"question\": \"Is reading papers a good idea?\"\n",
        "    })\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJhiQyRiFzyd"
      },
      "source": [
        "## Splitting the transcription\n",
        "\n",
        "Since we can't use the entire transcription as the context for the model, a potential solution is to split the transcription into smaller chunks. We can then invoke the model using only the relevant chunks to answer a particular question:\n",
        "\n",
        "<img src='https://github.com/haoransun/youtube-rag/blob/main/images/system2.png?raw=1' width=\"1200\">\n",
        "\n",
        "Let's start by loading the transcription in memory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cErwfR9SFzyd",
        "outputId": "a0db0170-d945-4ea1-c4dd-78743b624250"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'transcription.txt'}, page_content=\"I think it's possible that physics has exploits and we should be trying to find them. arranging some kind of a crazy quantum mechanical system that somehow gives you buffer overflow, somehow gives you a rounding error in the floating point. Synthetic intelligences are kind of like the next stage of development. And I don't know where it leads to. Like at some point, I suspect the universe is some kind of a puzzle. These synthetic AIs will uncover that puzzle and solve it. The following is a conversation with Andre Kappathi, previously the director of AI at Tesla. And before that, at OpenAI and Stanford, he is one of the greatest scientist engineers and educators in the history of artificial intelligence. This is the Lex Friedman podcast to support it. Please check out our sponsors and now to your friends. Here's Andre Kappathi. What is a neural network? And what does it seem to do such a surprisingly good job of learning? What is a neural network? It's a mathematical abstraction of the brain. I would say that's how it was originally developed. At the end of the day, it's a mathematical expression. And it's a fairly simple mathematical expression when you get down to it. It's basically a sequence of meter smoke applies, whichever link dot products mathematically. And some non-linearities throw them in. And so it's a very simple mathematical expression. And it's got knobs in it. Many knobs. Many knobs. And these knobs are loosely related to basically the synapses in your brain. They're trainable, they're modifiable. And so the idea is we need to find the setting of the knobs that makes the neural net do whatever you want it to do, like classify images and so on. And so there's not too much mystery I would say in it. Like you might think that basically don't want to end out with too much meaning with respect to the brain and how it works. It's really just a complicated mathematical expression with knobs. And those knobs need a proper setting for it to do something desirable. Yeah, but poetry is just the collection of letters with spaces. But it can make us feel a certain way. And in that same way, when you get a large number of knobs together, whether it's inside the brain or inside a computer, they seem to they seem to surprise us with their power. Yeah, I think that's fair. So basically I'm underselling it by a lot because you definitely do get very surprising emergent behaviors out of these neural nets when they're large enough and trained on complicated enough problems. Like say, for example, the next word prediction in a massive data set from the internet. And then these neural nets take on pretty surprising magical properties. Yeah, I think it's kind of interesting how much you can get out of even very simple mathematical formalism. When your brain right now is talking, is it doing next word prediction? Or is it doing something more interesting? Well, it's definitely some kind of a generative model that's a GPT-like and prompted by you. Yeah, so you're giving me a prompt and I'm kind of like responding to it in a generative way. And by yourself, perhaps a little bit like are you adding extra prompts from your own memory inside your head? Or no? Well, definitely feels like you're referencing some kind of a declarative structure of like memory and so on. And then you're putting that together with your prompt and giving away some extra. How much of what you just said has been said by you before? Nothing, basically, right? No, but if you actually look at all the words you've ever said in your life and you do a search, you'll probably said a lot of the same words in the same order before. Yeah, could be. I mean, I'm using phrases that are common, etc. But I'm remixing it into a pretty sort of unique sentence at the end of the day. But you're right, definitely, there's like a ton of remixing. Why you didn't, you just like Magnus Carlson said, I'm rated 2,900, whatever, which is pretty decent. I think you're talking very, you're not giving enough credit to neural nets here. Why do they seem to, what's your best intuition about this emergent behavior? I mean, it's kind of interesting because I'm simultaneously underselling them. But I also feel like there's an element to which I'm over like, it's actually kind of incredible that you can get so much emergent magical behavior out of them, despite them being so simple mathematically. So I think those are kind of like two surprising statements that are kind of just juxtaposed together. And I think basically what it is is we are actually fairly good at optimizing these neural nets. And when you give them a hard enough problem, they are forced to learn very interesting solutions in the optimization. And those solutions basically have these emergent properties that are very interesting. There's wisdom and knowledge in the knobs. And so this representation that's in the knobs doesn't make sense to you intuitively. The large number of knobs can hold a representation that captures some deep wisdom about the data. It has looked at a lot of knobs. It's a lot of knobs. And somehow, so speaking concretely, one of the neural nets that people are very excited about right now are our GPs, which are basically just next word prediction networks. So you consume a sequence of words from the internet and you try to predict the next word. And once you train these on a large enough data set, they you can basically prompt these neural nets in arbitrary ways and you can ask them to solve problems. And they will. So you can just tell them you can make it look like you're trying to solve some kind of mathematical problem and they will continue what they think is the solution based on what they've seen on the internet. And very often those solutions look very remarkably consistent. Look correct potentially. Do you still think about the brain side of it? So as neural nets is an abstraction or mathematical abstraction of the brain, you still draw wisdom from the biological neural networks or even the bigger question. So your big fan of biology and biological computation. What impressive thing is biology doing to you the computer, not yet, the gap? I would say I'm definitely on a much more hesitant with the analogies to the brain than I think he would see potentially in the field. And I kind of feel like certainly the way neural networks started is everything stemmed from inspiration by the brain. But at the end of the day, artifacts that you get after training, they are arrived at by a very different optimization process than the optimization process that gave rise to the brain. And so I think I kind of think of it as a very complicated alien artifact. It's something different. I'm sorry, the neural nets that were training. They are complicated alien artifact. I do not make analogies to the brain because I think the optimization process that gave rise to it is very different from the brain. So there was no multi agent, self play kind of setup and evolution. It was an optimization that is basically a, what amounts to a compression objective on a massive amount of data. Okay, so artificial neural networks are doing compression and biological neural networks. Now to survive. And I'm not really doing any of their, they're an agent in a multi agent, self play system that's been running for very, very long time. That said, evolution has found that it is very useful to, to predict and have a predictive model in the brain. And so I think our brain utilizes something that looks like that as a part of it. But it has a lot more, you know, catches and gizmos and value functions and ancient nuclei that are all trying to like make a survivor and reproduce and everything else. And the whole thing through embryogenesis is built from a single cell. I mean, it's just the code is inside the DNA and it just builds it up like the entire organism with the sound. Crazy. And the head and legs. Yes. And like it does it pretty well. It should not be possible. So there's some learning going on. There's some, there's some, there's some kind of computation going through that building process. I mean, I don't know where, if you were just to look at the entirety of history of life on Earth, what do you think is the most interesting invention? Is it the origin of life itself? Is it just jumping to eukaryotes? Is it mammals? Is it humans themselves, homo sapiens? Are the origin of intelligence or highly complex intelligence? Or is it all just a continuation of the same kind of process? Certainly, I would say it's an extremely remarkable story that I'm only like briefly learning about recently. All the way from, actually, like, you almost have to start at the formation of Earth and all of its conditions and the entire solar system and how everything is arranged with Jupiter and Moon and the habitable zone and everything. And then you have an active Earth that's turning over material. And then you start with a biogenesis and everything. And so it's all like a pretty remarkable story. I'm not sure that I can pick like a single unique piece of it that I find most interesting. I guess for me as an artificial intelligence researcher, it's probably the last piece. We have lots of animals that are not building technological society, but we do. And it seems to have happened very quickly. It seems to have happened very recently. And something very interesting happened there that I don't fully understand. I almost understand everything else, I think intuitively, but I don't understand exactly that part and how quick it was. Both explanations would be interesting. One is that this is just a continuation of the same kind of process. There's nothing special about humans. That would be deeply understanding that would be very interesting. That we think of ourselves as special, but it was obvious. All it was already written in the code that you would have greater and greater intelligence emerging. And then the other explanation, which is something truly special happened, something like a rare event, whether it's like crazy rare event, like space Odyssey. What would it be? See, if you say like the invention of fire, or the, as Richard and Rangham says, the beta males deciding a clever way to kill the alpha males by collaborating. So just optimizing the collaboration, the multi-agent aspect of the multi-agent. And that really being constrained on resources and trying to survive the collaboration aspect is what created the complex intelligence. But it seems like it's a natural algorithm to the evolution process. What could possibly be a magical thing that happened? Like a rare thing that would say that humans are actually human level intelligence, actually a really rare thing in the universe. Yeah, I'm hesitant to say that it is rare, by the way, but it definitely seems like it's kind of like a punctuated equilibrium where you have lots of exploration and then you have certain leaps, sparse leaps in between. So of course, like origin of life would be one, you know, DNA, sex, eukaryotic, eukaryotic life, the endosymbiosis event where the archaeon ate the old bacteria, you know, just the whole thing. And then of course, emergence of consciousness and so on. So it seems like definitely there are sparse events where mass amount of progress was made. But yeah, it's kind of hard to pick one. So you don't think humans are unique. You've got to ask you how many intelligent alien civilizations do you think are out there? And is there intelligence different or similar to ours? Yeah, I've been preoccupied with this question quite a bit recently, basically the Fermi Paradox and just thinking through. And the reason actually that I am very interested in the origin of life is fundamentally trying to understand how common it is that there are technological societies out there in space. And the more I study it, the more I think that there should be quite a lot. Why haven't we heard from them? Because I agree with you. It feels like I just don't see why what we did here and it's so difficult to do. Yeah, and especially when you get into the details of it, I used to think origin of life was very, it was this magical rare event, but then you read books like, for example, in the claim, the vital question, life ascending, etc. And he really gets in and he really makes you believe that this is not that rare basic chemistry. You have an activist and you have your alkaline vents and you have lots of alkaline waters, mixing with a devotion and you have your proton gradients and you have the little porous pockets of these alkaline vents that concentrate chemistry. And basically as he steps through all of these little pieces, you start to understand that actually this is not that crazy. You could see this happen on other systems. And he really takes you from just a geology to primitive life and he makes it feel like it's actually pretty plausible. And also like the origin of life didn't, was actually fairly fast after formation of Earth. If I'm recurrently just a few hundred million years for something like that after basically when it was possible, life actually arose. And so that makes me feel that that is not the constraint, that is not the limiting variable and that life should actually be fairly common. And then where the drop offs are is very interesting to think about. I currently think that there's no major drop offs basically and so there should be quite a lot of life. And basically where that brings me to then is the only way to reconcile the fact that we haven't found anyone and so on is that we just can't see them. We can't observe them. Just a quick brief comment, Nick Lane and a lot of biologists I talked to, they really seem to think that the jump from bacteria to more complex organisms is the hardest jump. The you carry it like this. Yeah, which I don't, I get it, they're much more knowledgeable than me about like the intricacies of biology. But that seems like crazy because how many single cell organisms are there? And how much time you have, surely, it's not that difficult. Like an ability in years is not even that long of a time really. Just all these bacteria under constrained resources battling it out. I'm sure they can invent more complex. I don't understand. It's like how to move from a hello world program to like invent a function or something like that. I don't yeah. So I don't, yeah, so I'm with you. I just feel like I don't see any. If the origin of life, that would be my intuition. That's the hardest thing. But if that's not the hardest thing because it happens so quickly, then it's got to be everywhere. And yeah, maybe we're just too dumb to see it. Well, it's just, we don't have really good mechanisms for seeing this life. I mean, by what how? So I'm not an expert just to preface this, but just from I want to meet an expert on alien intelligence and how to communicate. I'm very suspicious of our ability to to find these intelligence is out there and to find these Earth like radio waves, for example, are terrible. Their power drops off as basically one over our square. So I remember reading that our current radio waves would not be the ones that we are broadcasting would not be measurable by our devices today. Only like, was it like one tenth of a light year away? Like not even basically tiny distance because you really need like a targeted transmission of massive power directed somewhere for this to be picked up on long long distances. And so I just think that our ability to measure is is not amazing. I think there's probably other civilizations out there. And then the big question is why don't they build one element probes and why don't they interstellar travel across the entire galaxy? And my current answer is it's probably interstellar travel is like really hard. You have the interstellar medium. If you want to move at close to speed of light, you're going to be encountering bullets along the way because even like tiny hydrogen atoms and little particles of dust are basically have like massive kinetic energy at those speeds. And so basically you need some kind of shielding. You need that you have all the cosmic radiation. It's just like brutal out there. It's really hard. And so my thinking is maybe interstellar travel is just extremely hard. I think you have to do it very slow. It feels like we're not a billion years away from doing that. It just might be that it's very you have to go very slowly potentially as an example through space. Right. As opposed to close to speed of light. So I'm suspicious basically of our ability to measure life. And I'm suspicious of the ability to just permeate all of space in the galaxy or across galaxies. And that's the only way that I can certainly see away around it. Yeah, it's kind of mind blowing. I think that there's trillions of intelligent alien civilizations out there kind of slowly traveling through space. Mm-hmm. Made to meet each other and some of them meet some of them go to war some of them collaborate. Mm-hmm. Or they're all just independent. They general just like little pockets. Well, statistically if there's like if it's the trillions of them surely some of them some of the pockets are close enough to get some of them happen to be close. Yeah. And close enough to see each other. And then once you see once you see something that is definitely complex life like if we see something. Yeah. We're probably going to be severe like intensely aggressively motivated to figure out what the hell that is and try to meet them. Well, it will be your first instinct to try to like at a generational level. Meet them or defend against them or it will be your instinct as a president of the United States. And the scientist. I don't know which hat you prefer in this question. Yeah, I think the question it's really hard. I will say like for example for us we have lots of primitive life forms on earth. Next to us we have all kinds of ants and everything else and we share space with them. And we are hesitant to impact on them and to we are trying to protect them by default because they are amazing interesting dynamical systems that took a long time to evolve and they are interesting and special and I don't know that you want to destroy that by default. And so I like complex dynamical systems that took a lot of time to evolve. I think I'd like to preserve it if I can afford to. And I'd like to think that the same would be true about the galactic resources and that they would think that we're kind of incredible interesting story that took time. It took a few billion years to unravel and you don't want to just destroy it. I could see two aliens talking about earth right now and saying I'm a big fan of complex dynamical systems. So I think it's with a value to preserve these and we'll basically are a video game they watch or show a TV show that they watch. Yeah, I think you would need like a very good reason I think to destroy it. Like why don't we destroy these ant farms and so on? It's because we're not actually like really indirect competition with them right now. We do it accidentally and so on but there's plenty of resources. And so why would you destroy something that is so interesting and precious? Well, from a scientific perspective, you might probe it. You might interact with it lately. Exactly. You might want to learn something from it. So I wonder there's could be certain physical phenomena that we think is a physical phenomena but it's actually interacting with us to like poke the finger and see what happens. I think it should be very interesting to scientists. Other alien scientists what happened here. And you know, it's a what we're seeing today as a snapshot basically. It's a result of a huge amount of computation over like billion years or something like that. So it could have been initiated by aliens. This could be a computer running a program like when okay, if you had the power to do this, when you okay, for sure, at least I would, I would pick a earth-like planet that has the conditions based my understanding of the chemistry prerequisites for life. And I would see it with life and run it. Right? Like, yeah, when you 100% do that and observe it and then protect, I mean, that's not just the hell of a good TV show. It's a good scientific experiment. And it's physical simulation, right? Maybe the evolution is the most like actually running it is the most efficient way to understand computation or to compute stuff. For understand life or you know, what life looks like and what branches it can take. It does make me kind of feel weird there were part of a science experiment but maybe it's everything's a science experiment. Does that change anything for us? For a science experiment? I don't know. Two descendants of Apes talking about being inside of a science experiment. I'm suspicious of this idea of like a deliberate pens premiere as you described it. And I don't see a divine intervention in some way in the historical record right now. I do feel like the story in these books like Nikolai's books and so on sort of makes sense and it makes sense how life arose on earth uniquely. And yeah, I don't need a, I mean, I don't need to reach for more exotic explanations right now. Sure, but NPCs inside a video game don't don't observe any divine intervention either. We might just be all NPCs running a kind of code. Maybe eventually they will. Currently, NPCs are really dumb but once they're running GPs, maybe they will be like, hey, this is really suspicious with the hell. So you famously tweeted, it looks like if you bombard earth with photons for a while, you can emit a roaster. So if like an Hitchhiker's guide to the galaxy, we would summarize the story of earth. So in that book it's mostly harmless. What do you think is all the possible stories, like a paragraph long or a sentence long, that earth could be summarized as? At once it's done, it's computation. So like all the possible full, if earth is a book, right? Yeah. Probably there has to be an ending. I mean, there's going to be an end to earth and it could end in all kinds of ways. It can end soon. It can end later. What do you think are the possible stories? Well, definitely there seems to be, yeah, you're sort of, it's pretty incredible that the self-replicating systems will basically arise from the dynamics and then they perpetuate themselves and become more complex and eventually become conscious and build a society. And I kind of feel like in some sense it's kind of like a deterministic wave that kind of just happens on any sufficiently well-arranged system like earth. And so I kind of feel like there's a certain sense of inevitability in it. And it's really beautiful. And it ends somehow, right? So it's a chemically diverse environment where complex dynamical systems can evolve and become more further further complex. But then there's a certain, what is it? There's certain terminating conditions. Yeah, I don't know what the terminating conditions are, but definitely there's a trend line of something. And we're part of that story. And like, where does that, where does it go? So, you know, we're famously described often as a biological bootloader for AIs. And that's because humans, I mean, we're an incredible biological system and we're capable of computation and, you know, and love and so on. But we're extremely inefficient as well. Like we're talking to each other through audio. It's just kind of embarrassing, honestly, that we're manipulating like seven symbols, uh, serially, we're using vocal chords. It's all happening over like multiple seconds. It's just like kind of embarrassing when you step down to the frequencies at which computers operate or are able to operate on. And so basically, it does seem like, um, synthetic intelligences are kind of like the next stage of development. And, um, I don't know where it leads to like at some point, I suspect the universe is some kind of a puzzle. And these synthetic AIs will uncover that puzzle and solve it. And then what happens after, right? Like what? Because if you just like fast forward earth, many billions of years, it's like, it's quiet. And then it's like, to the terminal, you see like city lights and stuff like that. And then what happens at like at the end, like, is it like a pool? Or is it like a calming? Is it explosion? Is it like earth like open like a giant? Because you said, admit roasters like we'll start emitting like like a giant number of like satellites. Yes. It's some kind of a crazy explosion. And we're living, we're like, we're stepping through a explosion. And we're like living day to day and it doesn't look like it. But it's actually, if you, I saw a very cool animation of earth, uh, and life on earth and basically nothing happens for a long time. And then the last like two seconds, like basically cities and everything. And the lower orbit just gets cluttered. And just the whole thing happens in the last two seconds. And you're like, this is exploding. This is a statement explosion. So if you play, yeah, yeah, if you play at a normal speed, yeah, it'll just look like an explosion. It's a firecracker. We're living in a firecracker where it's going to start emitting all kinds of interesting things. Yeah. And then the explosion doesn't, it might actually look like a little explosion with lights and fire and energy emitted, all that kind of stuff. But when you look in the inside, the details of the explosion, there's actual complexity happening where there's like, yeah, human life or some kind of life. We hope it's another destructive firecracker. It's kind of like a constructive firecracker. All right. So given that, I think, uh, hilarious. It's going to be really interesting to think about like what the puzzle of the universe is. Did the creator of the universe give us a message? Like for example, in the book contact, um, Carl Sagan, uh, there's a message for humanity, for any civilization in the digits in the expansion of pie and base 11 eventually. We're just kind of interesting thought. Maybe, maybe we're supposed to be giving a message to our creator. Maybe we're supposed to somehow create some kind of a quantum mechanical system that alerts them to our intelligent presence here. Because if you think about it from their perspective, it's just say like quantum field theory, massive like cellular atomic bomb like thing. And like, how do you even notice that we exist? You might not even be able to pick us up in that simulation. And so how do you, uh, how do you prove that you exist, uh, that you're intelligent and that you're part of the universe? So this is like a touring test for intelligence from Earth. Yeah. So creators, uh, I mean, maybe this is like trying to complete the next origin and sense. This is a complicated way of that. Like Earth is just is basically sending a message back. Yeah. The puzzle is basically like alerting the creator that we exist. Yeah. Uh, or maybe the puzzle is just to, uh, just break out of the system and just, uh, you know, stick it to the creator in some way. Yeah. Basically, like if you're playing a video game, you can, um, you can somehow find an exploit and find a way to execute on the host machine, uh, in the arbitrary code. Uh, there's some, uh, for example, I believe someone got a Mario, a game of Mario to play pong just by, um, exploiting it and then, um, creating a, basically writing, writing code and being able to execute arbitrary code in the game. And so maybe we should be, maybe that's the puzzle is that we should be, um, uh, find a way to exploit it. So, so I think like some of these synthetic ares will eventually find the universe to be some kind of a puzzle and then solve it in some way. And that's kind of like the end game somehow. Do you often think about it as, uh, as a simulation? So, uh, as, or the universe being a kind of computation that has, might have bugs and exploits. Yes. Yeah. I think so. I think it's possible that physics has exploits and we should be trying to find them, uh, arranging some kind of a crazy quantum mechanical system that somehow gives you buffer overflow, uh, somehow gives you a rounding error in the floating point. Uh, uh, uh, yeah. That's right. And like more and more sophisticated exploits that those are jokes, but that could be actually, yeah, we'll find some way to extract infinite energy. Uh, for example, when you train reinforcement learning agents, um, in physical simulations and you ask them to say run quickly on the flat ground, they'll end up doing all kinds of like weird things, um, in part of that optimization, right? They'll get on their back leg and they'll slide across the floor. And it's because the optimization, um, the enforcement learning optimization on that agent has figured out a way to extract infinite energy from the friction forces and, um, basically their poor implementation and they found a way to generate infinite energy and just slide across the surface. And it's not what you expected. It's just a, it's sort of like a, perverse solution. And so maybe we can find something like that. Maybe we can be that little dog in this physical simulation. The, like, the cracks or escapes the intended consequences of the physics that universe came up with. Yeah. We'll figure out some kind of shortcut to some weirdness. Yeah. And then, man, you see the problem with that weirdness is the first person to discover the weirdness, like sliding in the back legs. That's all we're going to do. Yeah. It's very quickly become everybody does that thing. So like the paperclip maximizer is a ridiculous idea, but that very well, you know, could be what then we'll just, we'll just all switch that because it's so fun. Well, no person will discover it, I think, by the way, I think it's going to have to be, uh, some kind of a super intelligent AGI of a Thorpe generation. Like we're building the first generation AGI. And you know, third generation. Yeah. So the bootloader for an AI, that AI will be a bootloader for another AI. Yeah. And then there's no way for us to interest back like what that would have been. I think it's very likely that these things, for example, like say you have these AGIs, it's very likely that, for example, they will be completely inert. I like these kinds of sci-fi books sometimes where these things are just completely inert. They don't interact with anything. And I find that kind of beautiful because they probably, they've probably figured out the meta game of the universe in some way, potentially. They're, they're doing something completely beyond our imagination. And they don't interact with simple chemical life forms. Why would you do that? So I find those kinds of ideas compelling. What's their source of fun? What are they, what are they doing? What's the source of pleasure? Well, probably solving in the universe. But inert, so can you define what it means in nerds? So they escape the actual physics. They will behave in some very like strange way to us because they're beyond, they're playing the meta game. And the meta game is probably say like arranging quantum mechanical systems in some very weird ways to extract infinite energy, solve the digital expansion of pie to whatever amount they will build their own like little fusion reactors or something crazy. Like they're doing something beyond comprehension. And not understandable to us and actually brilliant under the hood. What if quantum mechanics itself is the system and we're just thinking it's physics. But we're really parasites on, on not parasite, we're not really hurting physics. We're just living on this organisms. This organism and we're like trying to understand it, but really it is an organism. And with a deep, deep intelligence, maybe physics itself is the organism that's doing the super interesting thing. And we're just like one little thing, yeah, and sitting on top of it, trying to get energy from it. We're just kind of like these particles in the wave that I feel like is mostly deterministic and takes universe from some kind of a big bang to some kind of a super intelligent replicator, some kind of a stable point in the universe given these laws of physics. You don't think, as Einstein said, God doesn't play dice. So you think it's mostly deterministic. There's no randomness in the thing. I think as a deterministic, there's tons of, well, I'm I'm going to be careful with randomness pseudo random. Yeah, I don't like random. I think maybe the laws of physics are deterministic. Yeah, I think they're deterministic. He's just got really uncomfortable with the question. Do you have anxiety about whether the universe is random or not? There's no randomness. You say you like goodwill hunting. It's not your fault, Andre. It's not your fault, man. So you don't like randomness. Yeah, I think it's unsettling. I think it's a deterministic system. I think that things that look random, like say the collapse of the wave function, etc. I think they're actually deterministic, just entanglement and so on. And some kind of a multi-verse theory, something, something. Okay, so why does it feel like we have a free will? Like if I raise this hand, I chose to do this now. What that doesn't feel like a deterministic thing. It feels like I'm making a choice. It feels like it. Okay, so it's all feelings. It's just feelings. Yeah. So when RLA agent does make any choice, is that it's not really make any choice. The choice is already there. Yeah, you're interpreting the choice and you're creating a narrative for having made it. Yeah, and now we're talking about the narrative. It's very meta. Looking back, what is the most beautiful or surprising idea in deep learning or AI in general, that you've come across. You've seen this field explode and grow in interesting ways. Just what cool idea is like we made you sit back and go. Small, bigger, small. Well, the one that I've been thinking about recently, the most probably is the the transformer architecture. So basically, neural networks have a lot of architectures that where trendy have come and gone for different sensor modalities like for vision, audio, text. You would process them with different looking neural nets. And recently, we've seen this convergence towards one architecture, the transformer. And you can feed it video or you can feed it, images or speech or text and it just gobbles it up. And it's kind of like a bit of a general purpose computer. There is also trainable and very efficient to run in our hardware. And so this paper came out in 2016, I want to say attention is all you need. Detention is all you need. You could have said the paper title in retrospect that it wasn't it didn't foresee the bigness of the impact that it was going to have. Yeah, I'm not sure if the authors were aware of the impact that that paper would go on to have probably they weren't. But I think they were aware of some of the motivations and design decisions behind the transformer and they chose not to, I think, expand on it in that way in the paper. And so I think they had an idea that there was more than just the surface of just like over just doing translation and here's a better architecture. You're not just doing translation. This is like a really cool, differentiable, optimizable, efficient computer that you've proposed. And maybe they didn't have all of that foresight, but I think it's really interesting. Isn't it funny? Sorry to interrupt that title is memeable that they went for such a profound idea they went with the I don't think anyone used that kind of title before, right? Attention is all you need. Yeah, it's like a meme or something. Yeah, it's not funny that one. Like maybe if it was a more serious title, we don't have the impact. Honestly, yeah, there's an element of me that honestly agrees with you and prefers it this way. Yes. If it was too grand, it would overpromise and then underdeveloper potentially. So you want to just meme your way to greatness. That should be a t-shirt. So you tweeted the transformers and magnificent neural network architecture because it is a general purpose, differentiable computer. It is simultaneously expressive in the forward pass, optimizable via back propagation gradient descent and efficient high parallelism compute graph. Can you discuss some of those details expressed of optimizable, efficient, yeah, for memory or in general, whatever comes to your heart? You want to have a general purpose computer that you can train on arbitrary problems. Like say the task of next work prediction or detecting if there's a cat in a image or something like that. And you want to train this computer so you want to set its weights. And I think there's a number of design criteria that sort of overlap in the transformer simultaneously that made it very successful. And I think the author is where kind of deliberately trying to make this really powerful architecture. And so in a, basically it's very powerful in the forward pass because it's able to express very general computation as sort of something that looks like message passing. You have nodes and the old store vectors. And these nodes get to basically look at each other and it's each other's vectors. And they get to communicate. And basically nodes get to broadcast, hey, I'm looking for certain things. And then other nodes get to broadcast, hey, these are the things I have. Those are the keys in the values. So it's not just attention. Yeah, exactly. Chessformer is much more than just the attention component that's got many pieces architectural that went into it. The residual connection of the weights arranged. There's a multi-layer perceptron and they're the weights stacked and so on. But basically there's a message passing scheme where nodes get to look at each other, decide what's interesting, and then update each other. And so I think the, when you get to the details of it, I think it's a very expressive function. So it can express lots of different types of algorithms in forward pass. Not only that, but the weights designed with the residual connections, lane normalizations, the softmatics, attention and everything. It's also optimizable. This is a really big deal because there's lots of computers. There are powerful that you can't optimize. Or they are not easy to optimize using the techniques that we have, which is backpropocation and gradient descent. These are our first order methods, very simple optimizers, really. And so you also needed to be optimizable. And then lastly, you wanted to run efficiently in our hardware. Our hardware is a massive throughput machine, like GPUs. They prefer lots of parallelism. So you don't want to do lots of sequential operations. You want to do a lot of operations seriously. And the transformer is designed with that in mind as well. And so it's designed for our hardware and is designed to both be very expressive in a forward pass, but also very optimizable in the backward pass. And you said that the residual connection support of kind of ability to learn short algorithms fast and first and then gradually extend them longer during training. Yeah. What's the idea of learning short algorithms? Right. Think of it as a, so basically a transformer is a series of blocks, right. And these blocks have attention and a little more to the upper section. And so you go off into a block and you come back to this residual pathway. And then you go off and you come back. And then you have a number of layers arranged sequentially. And so the way to look at it, I think, is because of the residual pathway in the backward pass, the gradients sort of flow allowing it uninterrupted because addition distributes the gradient equally to all of its branches. So the gradient from the supervision at the top just floats directly to the first layer. And the all the residual connections are arranged so that in the beginning and during initialization, they contribute nothing to the residual pathway. So what it kind of looks like is imagine the transformer is kind of like a Python function, like a death. And you get to do various kinds of like lines of code. So you have a hundred layers deep transformer. Typically they would be much shorter, say 20. So you have 20 lines of code and you can do something in them. And so think of during the optimization, basically what it looks like is first you optimize the first line of code and then the second line of code can kick in and the third line of code can kick in. And I kind of feel like because of the residual pathway and the dynamics of the optimization, you can sort of learn a very short algorithm that gets the approximate answer. But then the other layers can sort of kick in and start to create a contribution. And at the end of it, you're optimizing over an algorithm that is 20 lines of code. Except these lines of code are very complex because this is an entire block of a transformer. You can do a lot in there. Well, it's really interesting is that this transformer architecture actually has been a remarkably resilient. Basically, the transformer that came out in 2016 is the transformer you would use today, except you reshuffle some delayer norms. The delayer normalizations have been reshuffle to a pre-norm formulation. And so it's been remarkably stable, but there's a lot of bells and whistles that people have attached on it and try to improve it. I do think that basically it's a big step in simultaneously optimizing for lots of properties of a desirable neural network architecture. And I think people have been trying to change it, but it's proven remarkably resilient. But I do think that there should be even better architectures potentially. But it's you admire the resilience here. There's something profound about this architecture that at least reshuffle. So maybe we can everything can be turned into a problem that transformers can solve. Currently, definitely looks like the transformer is taking over AI and you can feed basically arbitrary problems into it. And it's a general, the Frenchable computer and it's extremely powerful. And this conversion in AI has been really interesting to watch for me personally. What else do you think could be discovered here about transformers? Like what's the surprising thing? Or is it a stable, I want a stable place. Is there something interesting where my discover about transformers? Like a Ha moment, maybe has to do with memory, maybe knowledge representation, that kind of stuff. Definitely the zeitgeist today is just pushing, like basically right now the zeitgeist is do not touch the transformer, touch everything else. So people are scaling up the data sets, making them much, much bigger. They're working on the evaluation, making the evaluation much, much bigger. And they're basically keeping the architecture unchanged. And that's how we've, that's the last five years of progress in AI kind of. What do you think about one flavor of it, which is language models? Have you been surprised? Has your sort of imagination been captivated by you mentioned GPD and all the big and big and bigger language models? And what are the limits of those models do you think? So just the task of natural language. Basically the way GPD is trained, right? As you just download a massive amount of text data from the internet and you try to predict the next word in a sequence, roughly speaking. You're predicting a little work chunks, but roughly speaking, that's it. And what's been really interesting to watch is basically it's a language model. Language models have actually existed for a very long time. There's papers on language modeling from 2003, even earlier. Can you explain in that case what language model is? Yeah, so language model just basically the rough idea is just predicting the next word in a sequence, roughly speaking. So there's a paper from, for example, Ben Geo and the team from 2003, where for the first time they were using a neural network to take say like three or five words and predict the next word. And they're doing this on much smaller datasets and the neural net is not a transformer. It's a multi-air perceptron, but it's the first time that a neural network has been applied in that setting. But even before neural networks, there were language models, except they were using N-gram models. So N-gram models are just a count-based models. So if you try to take two words and predict the third one, you just count up how many times you've seen any two word combinations and what came next. And what you predict as coming next is just what you've seen the most of in the training set. And so language modeling has been around for a long time. Neural networks have done language modeling for a long time. So really what's new or interesting or exciting is just realizing that when you scale it up with powerful enough neural net transformer, you have all these emerging properties where basically what happens is if you have a large enough dataset of text, you are in the task of predicting the next word, you are multitasking a huge amount of different kinds of problems. You are multitasking understanding of chemistry, physics, human nature. Lots of things are sort of clustered in that objective. It's a very simple objective, but actually you have to understand a lot about the world to make that prediction. You just said the you word understanding. Are you in terms of chemistry and physics and so on? What do you feel like is doing? Is it searching for the right context? What is the actual process happening here? Yeah, so basically it gets a thousand words and is trying to predict a thousand at first. And in order to do that very, very well over the entire dataset available on the internet, you actually have to basically kind of understand the context of what's going on in there. It's a sufficiently hard problem that if you have a powerful enough computer like a transformer, you end up with interesting solutions. You can ask it to do all kinds of things. It shows a lot of emerging properties like in context learning. That was the big deal with GPD and the original paper when they published it is that you can just sort of prompt it in various ways and ask it to do various things and it will just kind of complete the sentence. But in a process of just completing the sentence, it's actually solving all kinds of really interesting problems that we care about. Do you think it's doing something like understanding? When we use the word understanding for us humans, I think it's doing some understanding. In its way, it understands I think a lot about the world and it has to in order to predict the next word in the sequence. So let's train on the data from the internet. What do you think about this this approach in terms of datasets of using data from the internet? Do you think the internet has enough structured data to teach AI about human civilization? Yes, so I think the internet has a huge amount of data. I'm not sure if it's a complete enough set. I don't know that text is enough for having a sufficiently powerful AGI as an outcome. Of course, there is audio and video and images and all that kind of stuff. Yeah, so text by itself, I'm a little bit suspicious about. There's a ton of things we don't put in text in writing just because they're obvious to us about how the world works and the physics of it and the things fall. We don't put that stuff in text because why would you? We share that understanding. And so text is communication medium between humans and it's not a all-encompassing medium of knowledge about the world. But as you pointed out, we do have video and we have images and we have audio. And so I think that definitely helps a lot. But we haven't trained models sufficiently across all of those modalities yet. So I think that's what a lot of people are interested in. But I wonder what that shared understanding of what we may call common sense has to be learned inferred in order to complete the sentence correctly. So maybe the fact that it's implied on the internet, the model's going to have to learn that not by reading about it, by inferring it in the representation. So like common sense, just like we, I don't think we learn common sense. Like nobody says, tells us explicitly, we just figure it all out by interacting with the world. And so here's a model of reading about the way people interact with the world. It might have to infer that. I wonder. Yeah. You briefly worked on a project called World of Bits training in our RL system to take actions on the internet versus just consuming the internet. Like you talked about, do you think there's a future for that kind of system interacting with the internet to help the learning? Yes, I think that's probably the final frontier for a lot of these models. Because as you mentioned, when I was at OpenAI, I was working on this project World of Bits. And basically, it was the idea of giving neural networks access to a keyboard and a mouse. And the idea is possibly go wrong. So basically, you, you perceive the input of the screen pixels and basically the state of the computer is sort of visualized for human consumption in images of the web browser and stuff like that. And then you give the neural or the ability to press keyboards and use the mouse. And we're trying to get it to, for example, complete bookings and interact with user interfaces. And would you learn from that experience? Like, what was some fun stuff? This is super cool idea. Yeah. I mean, it's like, yeah, I mean, the step between observer to actor is a super fascinating step. Yeah. Well, it's the universal interface in the digital realm, I would say. And there's a universal interface in like the physical realm, which in my mind is a humanoid form factor kind of thing. We can later talk about optimists and so on. But I feel like there's a, they're kind of like similar philosophy in some way, where the human, the world, the physical world is designed for the human form. And the digital world is designed for the human form of seeing the screen and using keyword, not keyboard and mouse. And so it's the universal, universal interface that can basically command the digital infrastructure we've built up for ourselves. And so it feels like a very powerful interface to, to command and to build on top of. Now, to your question is to like what I learned from that? It's interesting because the world of bits was basically too early, I think at OpenAI at the time. This is around 2015 or so. And the zeitgeist at that time was very different in AI from the zeitgeist today. At the time, everyone was super excited about reinforcement learning from scratch. This is the time of the Atari paper where neural networks were playing Atari games and beating humans in some cases, AlphaGo and so on. So everyone was very excited about training, training neural networks from scratch using reinforcement learning directly. It turns out that reinforcement learning is extremely an efficient way of training neural networks because you're taking all these actions and all these observations and you get some sparse rewards once in a while. So you do all this stuff based on all these inputs. And once in a while, you're like told you did a good thing, you did a bad thing. And it's just an extremely hard problem when you can't learn from that. You can burn a forest and you can sort of brute force through it. And we saw that I think with Go and Dota and so on, and does work. But it's extremely inefficient and not how you want to approach problems practically speaking. And so that's the approach that at the time we also took to world of bits. We would have an agent initialize randomly, so with keyboard mash and mouse mash and try to make a booking. And it's just like revealed the insanity of that approach very quickly, where you have to stumble by the correct booking in order to get a reward of you did it correctly. And you're never going to stumble by it by chance at random. So even with a simple web interface, there's too many options. There's just too many options. And it's two sparse reward signal. And you're starting from scratch at the time. And so you don't know how to read. You don't understand pictures, images, buttons. You don't understand what it needs to like make a booking. But now what's happened is it is time to revisit that and opening eyes is interesting in this. Companies like ADEPT are interested in this and so on. And the idea is coming back because the interface is very powerful. But now you're not training an agent from scratch. You are taking the GPT as an initialization. So GPT is pre-trained on all of text. And it understands what's a booking. It understands what's a submit. It understands quite a bit more. And so it already has those representations. They are very powerful. And that makes all of the training significantly more efficient and makes the problem intractable. Should the interaction be like the way humans see it, with the buttons and the language, or should be with the HTML JavaScript and the CSS? What do you think is the better? Today all of this interaction is mostly on the level of HTML, CSS and so on. That's done because of computational constraints. But I think ultimately everything is designed for a human visual consumption. And so at the end of the day, there's all the additional information is in the layout of the web page and what's next to it and what's our red background and all this kind of stuff and what it looks like visually. So I think that's the final frontier as we are taking in pixels and we're giving out the keyboard mouse commands. But I think it's in practical still today. Do you worry about bots on the internet? Given these ideas, given how exciting they are, do you worry about bots on Twitter being not the stupid bots that we see now with the crypto bots? But the bots that might be out there actually that we don't see that they're interacting interesting ways. So this kind of system feels like it should be able to pass the, I'm not a robot click button, whatever. Which do you actually understand how that test works? I don't quite like there's a check box or whatever that you click. It's presumably tracking mouse movement and the timing and so on. So exactly this kind of system we're talking about should be able to pass that. So yeah, what do you feel about bots that are language models plus have some interactability and are able to tweet and reply and so on. Do you worry about that world? Yeah, I think it's always been a bit of an arms race between sort of the attack and the defense. So the attack will get stronger but the defense will get stronger as well. Our ability to detect that. How do you defend? How do you detect? How do you know that your Carpate account on Twitter is human? How would you approach that? Like if people were claim, you know, how would you defend yourself in the court of law that I'm a human? This account is. Yeah, at some point I think it might be, I think the society will evolve a little bit like we might start signing digitally signing some of our correspondence or things that we create. Right now it's not necessary but maybe in the future it I do think that we are going towards a world where we share the digital space with AI's synthetic beings. Yeah, and they will get much better and they will share our digital realm and they'll eventually share our physical realm as well. It's much harder. But that's kind of like the world we're going towards and most of them will be benign and awful and some of them will be malicious and it's going to be an arms race trying to detect them. So I mean the worst isn't the AI's the worst is the AI is pretending to be human. So I don't know if it's always malicious. There's obviously a lot of malicious applications but it could also be, if I was an AI I would try very hard to pretend to be human because we're in a human world. I wouldn't get in your respect as an AI. I want to get some love and respect. I don't think the problem is intractable. People are thinking about the proof of personhood and we might start digitally signing our stuff and we might all end up having like, yeah, basically some solution for proof of personhood. It doesn't seem to me intractable. It's just something that we haven't had to do until now but I think once the need like really starts to emerge which is soon I think people will think about it much more. But that too will be a race because obviously you can probably spoof or fake the proof of personhood. So you have to try to figure out how to probably. I mean it's weird that we have like social security numbers and like passports and stuff. It seems like it's harder to fake stuff in the physical space but in the digital space it just feels like it's going to be very tricky. Very tricky to out because it seems to be pretty low cost to fake stuff. What are you going to put an AI in jail for like trying to use a fake personhood proof? I mean okay fine you'll put a lot of AI in jail but there'll be more AI's like exponentially more. The cost of creating bought is very low. Unless there's some kind of way to track accurately like you're not allowed to create any program without showing tying yourself to that program. Like any program that runs on the internet you'll be able to trace every single human program that was involved with that program. Yeah maybe you have to start declaring when you know we have to start drawing those boundaries and keeping track of okay what are digital entities versus human entities and what is the ownership of human entities and digital entities and something like that. I don't know but I think I'm optimistic that this is possible and in some sense we're currently in like the worst time of it because all these bots suddenly have become very capable but we don't have the fences yet built up the society but I think that doesn't seem to me intractable it's just something that we have to deal with. It seems weird that the Twitter bot like really crappy Twitter bots are so numerous. I guess. So I presume that the engineers at Twitter are very good. So it seems like what I would infer from that is it seems like a hard problem. They're probably catching... All right if I were to sort of steal man the case it's a hard problem and there's a huge cost to false positive to removing a post by somebody that's not a bot. That's a crazy very bad user experience so they're very cautious about removing. So maybe it's and maybe the bots are really good at learning what gets removed and not such that they can stay ahead of the removal process very quickly. My impression of it honestly is there's a lot of blowing fruit. I mean yeah just that's what I... It's not so hard. It's my impression of it. It's not so hard. But you have to... Yeah that's my impression as well but it feels like maybe you're seeing the the tip of the iceberg. Maybe the number of bots isn't like the trillions and you have to like just it's a constant assault of bots and yeah you yeah yeah I don't know. You have to steal man the case because the bots I'm seeing are pretty like obvious. I could write a few lines of code that catch these bots. I mean definitely there's a lot of blowing fruit but I will say I agree that if you are a sophisticated actor you could probably create a pretty good bot right now. You know using tools like GPTs because it's a language model. You can generate faces that look quite good now and you can do this at scale. And so I think yeah it's quite plausible and it's going to be hard to defend. There was a Google engineer that claimed that the Lambda was sentient. Do you think there's any inkling of truth to what he felt and more importantly to me at least do you think language models will achieve sentience or the illusion of sentience? Sunish. Yeah to me it's a little bit of a canary in a coal mine kind of moment honestly a little bit because so this engineer spoke to like a chat bot at Google and we can convince that this bot is sentient. Asked it's some existential philosophical question and it gave like reasonable answers and looked real and so on. So to me it's a he was he wasn't sufficiently trying to stress the system I think and exposing the truth of it as it is today but I think this will be increasingly harder over time. So yeah I think more and more people will basically become yeah I think more and more there will be more people like that over time as this gets better like form and emotional connection to an AI. Yeah perfectly plausible in my mind. I think these AI's are actually quite good at human connection human emotion. A ton of text on the internet is about humans and connection and love and so on. So I think they have a very good understanding in some in some sense of of how people speak to each other about this and they're very capable of creating a lot of that kind of text. There's a lot of like sci-fi from 50s and 60s that imagined AI's in a very different way. They are calculating coal Balkan-like machines. That's not what we're getting today. We're getting pretty emotional AI's that actually are very competent and capable of generating you know possible sounding text with respect to all of these topics. Yeah I'm really hopeful about AI systems that are like companions that help you grow, develop as a human being, help you maximize long term happiness. But I'm also very worried about AI systems that figure out from the internet that humans get attracted to drama. So these would just be like shit talking AI's. Did you hear it? They'll do gossip. They'll do they'll try to plant seeds of suspicion to other humans that you love and trust and just kind of mess with people. You know because that's going to get a lot of attention. So drama, maximize drama on the path to maximizing engagement and us humans will feed into that machine. Yeah. And get it'll be a giant drama shit storm. Yeah. So I'm worried about that. So it's the objective function really defines the way that humans of physician progresses with AI's in it. Yeah. I think right now at least today they are not sort of it's not correct to really think of them as goal seeking agents that want to do something. They have no long term memory or anything. It's literally a good approximation of it is you get a thousand words and you're trying to pretty good a thousand at first and then you continue feeding it in. And you are free to prompt it in whatever way you want. So in text, so you say okay you are a psychologist and you are very good and you love humans. And here's a conversation between you and another human, human calling something, you something. And then it just continues the pattern. And suddenly you're having a conversation with a fake psychologist who's trying to help you. And so it's still kind of like an enrollment rate tool. It is a, people can prompt it in arbitrary ways and it can create really incredible text. But it doesn't have long term goals over long periods of time. It doesn't try to, so it doesn't look that way right now. Yeah. But you can do short term goals that have long term effects. So if my prompting short term goal is to get Andrzej Kapatich respond to me on Twitter whenever. Like I think I might, that's the goal, but it might figure out that talking shit to you will be the best in a highly sophisticated interesting way. And then you build up a relationship when you respond once. And then it like over time it gets to not be sophisticated and just like just talk shit. And okay, maybe you won't get to Andrzej, but it might get to another celebrity and might get into other big accounts. And then it'll just, so with just that simple goal, get them to respond. Yeah. Maximize the probability of actual response. Yeah, I mean, you could prompt a powerful model like this with their, it's opinion about how to do any possible thing you're interested in. So they will check us. They're kind of on track to become these oracles. I could sort of think of it that way. They are oracles currently is just text, but they will have calculators, they will have access to Google search, they will have all kinds of gadgets and gizmos, they will be able to operate the internet and find different information. And yeah, in some sense, that's kind of like currently what it looks like in terms of the development. Do you think it'll be an improvement eventually over what Google is for access to human knowledge? Like it'll be a more effective search engine to access human knowledge. I think there's definitely scope in building a better search engine today. And I think Google, they have all the tools, all the people, they have everything they need, they have all the puzzle pieces, they have people training transformers at scale, they have all the data. It's just not obvious if they are capable as an organization to innovate on their search engine right now. And if they don't, someone else will, there's absolute scope for building a significantly better search engine built on these tools. It's so interesting. A large company where the search, there's already an infrastructure, it works as it brings out a lot of money. So where structuring inside a company is their motivation to pivot to say we're going to build a new search engine. That's hard. So it's usually going to come from a startup. That's that would be yeah, or some other more competent organization. So I don't know. So currently, for example, maybe Bing has another shot at it. You know, as an example, Microsoft, we're talking offline. I mean, I definitely, it's really interesting because search engines used to be about, okay, here's some query, here's, here's web pages that look like the stuff that you have, but you could just directly go to answer and then have supporting evidence. And these models basically, they've read all the texts and they've read all the web pages. And so sometimes when you see yourself going over to search results and sort of getting like a sense of like the average answer to whatever you're interested in, like that just directly comes out. You don't have to do that work. So they're kind of like, yeah, I think they have a way to this of distilling all that knowledge into like some level of insight, basically. Do you think of prompting as a kind of teaching and learning like this whole process, like another layer? You know, because maybe that's what humans are. We already have that background model and the world is prompting you. Yeah, exactly. I think the way we are programming these computers now, like GPDs, is converging to how you program humans. I mean, how do I program humans via prompt? I go to people and I prompt them to do things. I prompt them for information. And so natural language prompt is how we program humans. And we're starting to program computers directly in that interface. It's like pretty remarkable, honestly. So you've spoken a lot about the idea of software 2.0. All good ideas become like clichés so quickly like the terms. It's kind of hilarious. It's like I think M&M once said that like if he gets annoyed by a song he's written very quickly, that means it's going to be a big hit because it's too catchy. But can you describe this idea and how you're thinking about it has evolved over the months and years since you coined it? Yeah. Yes, I had a blog post on software 2.0. I think several years ago now. And the reason I wrote that post is because I kept, I kind of saw something remarkable happening in like software development and how a lot of code was being transitioned to be written not in sort of like C++ and so on, but it's written in the weights of a neural net. Basically just saying that neural nets are taken over software, the realm of software and taking more and more and more tasks. And at the time, I think not many people understood this deeply enough that this is a big deal, this is a big transition. Neural networks were seen as one of multiple classification algorithms you might use for your dataset problem on Kaggle. Like this is not that. This is a change in how we program computers. And I saw neural nets as this is going to take over. The way we program computers is going to change. It's not going to be people writing a software in C++ or something like that and directly programming the software. It's going to be accumulating training sets and data sets and crafting these objectives by which you train these neural nets. And at some point, there's going to be a compilation process from the datasets and the objective and the architecture specification into the binary, which is really just the neural net weights and the forward pass of the neural net. And then you can deploy that binary. And so I was talking about that sort of transition and that's what the post is about. And I saw this sort of play out in a lot of fields, you know, auto, auto, auto, auto, being one of them, but also just simple image classification. People thought originally, you know, in the 80s and so on that they would write the algorithm for detecting a dog in an image. And they had all these ideas about how the brain does it. And first we detect corners and then we detect lines and then we stitch them up. And they were like really going at it. They were like thinking about how they're going to write the algorithm. And this is not the way you build it. And there was a smooth transition where, okay, first we thought we were going to build everything. Then we were building the features, so like hog features and things like that that detect these little statistical patterns from image patches. And then there was a little bit of learning on top of it, like a support vector machine or binary classifier for cat versus dog and images on top of the features. So we wrote the features, but we trained the last layer sort of the classifier. And then people are like, actually let's not even design the features because we can't honestly, we're not very good at it. So let's also learn the features. And then you end up with basically a convolution on your own where you're learning most of it. You're just specifying the architecture. And the architecture has tons of filling blanks, which is all the knobs. And you let the optimization write most of it. And so this transition is happening across the industry everywhere. And suddenly we end up with a ton of code that is written in neural net weights. And I was just pointing out that the analogy is actually pretty strong. And we have a lot of developer environments for software 1.0, like we have IDEs, how you work with code, how you debug code, how you run code, how do you maintain code, we have GitHub. So I was trying to make those analogies in the URL. Like what is the GitHub software 2.0? Turns out it's something that looks like hugging face right now. And so I think some people took it seriously and built cool companies. And many people originally attacked the post. It actually was not built received when I wrote it. And I think maybe it has something to do with the title, but the post was not well received. And I think more people have been coming around to it over time. Yeah. So you were the director of AI at Tesla, where I think this idea was really implemented at scale, which is how you have engineering teams doing software 2.0. So can you sort of linger on that idea of I think we're in the really early stages of everything you just said, which is like GitHub IDEs, like how do we build engineering teams that that work in software 2.0 systems and the data collection and the data annotation, which is all part of that software 2.0. Like what do you think is the task of programming software 2.0? Is it debugging in the space of hyper parameters or is it also debugging in the space of data? Yeah. The way by which you program the computer and influence its algorithm is not by writing the commands yourself. You're changing mostly the data set. You're changing the loss functions of what the neural net is trying to do, how it's trying to predict things, but basically the data sets and the architecture of the neural net. And so in the case of the autopilot, a lot of the data sets had to do with, for example, detection of objects and lane line markings and traffic lights and so on. So you accumulate massive data sets of, here's an example, here's the desired label. And then here's roughly what the algorithm should look like, and that's a completion on your own net. So the specification of the architecture is like a hint as to what the algorithm should roughly look like. And then the fill in the blanks process of optimization is the training process. And then you take your neural net that was trained, it gives all the right answers on your data set and you deploy it. So there's in that case, perhaps it all machine learning cases, there's a lot of tasks. So is coming up formulating a task, like for a multi-headed neural network is formulating a task part of the programming. Yeah, very much so. How you break down a problem into a set of tasks. Yeah. I'm going to high level, I would say, if you look at the software running in the autopilot, I give a number of talks on this topic. I would say originally a lot of it was written in software 1.0. There was, imagine lots of C++, right? And then gradually there was a tiny neural net that was, for example, predicting given a single image, is there like a traffic light or not, or is there a lane line marking or not? And this neural net didn't have too much to do in the scope of the software. It was making tiny predictions on individual image. And then the rest of the system stitched it up. So okay, we're actually, we don't have just a single camera with eight cameras. We actually have eight cameras over time. And so what do you do with these predictions? How do you put them together? How do you do the fusion of all that information and how do you act on it? All of that was written by humans in C++. And then we decided, okay, we don't actually want to do all of that fusion in C++ code because we're actually not good enough to write that algorithm. We want the neural net to write the algorithm. And we want to port all of that software into the 2.0 stack. And so then we actually had neural net that now take all the eight camera images simultaneously and make predictions for all of that. So, and actually they don't make predictions in the space of images. They now make predictions directly in 3D. And actually they don't, in three dimensions around the car. And now actually we don't manually fuse the predictions over in 3D over time. We don't trust ourselves to write that tracker. So actually we give the neural net the information over time. So it takes these videos now and makes those predictions. And so you're starting just like putting more and more power into the neural net, more and more processing. And at the end of it, the eventual sort of goal is to have most of the software potentially be in the 2.0 land because it works significantly better. Humans are just not very good at writing software, basically. So the prediction is happening in this like 4D land with three dimensional world over time. How do you do annotation in that world? So data annotation, whether it's self-supervised or manual by humans is a big part of the software 2.0 world. I would say by far in the industry, if you're like talking about the industry and how what is the technology of what we have available, everything is supervised learning. So you need a data sets of input desired output and you need lots of it. And there are three properties of it that you need. You need it to be very large. You need it to be accurate, no mistakes, and you need it to be diverse. You don't want to just have a lot of correct examples of one thing. You need to really cover the space of possibility as much as you can. And the more you can cover the space of possible inputs, the better the algorithm will work at the end. Now, once you have really good data sets that you're collecting, curating, and cleaning, you can train your neural net on top of that. So a lot of the work goes into cleaning those data sets. Now, as you pointed out, it's probably, it could be the question is, how do you achieve a ton of, if you want to basically predict in 3D, you need data in 3D to back that up. So in this video, we have eight videos coming from all the cameras of the system. And this is what they saw. And this is the truth of what actually was around. There was this car, there was this car, this car, these are the lane line markings. This is geometry of the road. There is traffic light in this redimensional position. You need the ground truth. And so the big question that team was solving, of course, is how do you, how do you arrive at that ground truth? Because once you have a million of it, and it's large, clean, and diverse, then training a neural net on it works extremely well. And you can ship that into the car. And so there's many mechanisms by which we collected that training data. You can always go for a human annotation. You can go for simulation as a source of grunt truth. You can also go for what we call the offline tracker that we spoken about at the AI day and so on, which is basically an automatic reconstruction process for taking those videos and recovering the three-dimensional sort of reality of what was around that car. So basically think of doing like a three-dimensional reconstruction as an offline thing. And then understanding that, okay, there's 10 seconds of video. This is what we saw. And therefore, here's all the lane lines cars and so on. And then once you have that annotation, you can train your neural nets to imitate it. And how difficult is the reconstruction? It's difficult. But it can be done. So there's the overlap between the cameras and you do the reconstruction. And there's perhaps there's any inaccuracy. So that's caught in the annotation step. Yes, the nice thing about the annotation is that it is fully offline. You have infinite time. You have a chunk of one minute and you're trying to just offline in a supercomputer somewhere, figure out where were the positions of all the cars, all the people. And you have your full one minute video from all the angles. And you can run all the neural nets you want and they can be very efficient, massive neural nets. There can be neural nets that can't even run in the car later at test time. So they can be even more powerful neural nets than what you can eventually deploy. So you can do anything you want, three dimensional reconstruction, neural nets, anything you want just to recover that truth. And then you supervise that truth. What have you learned? You said no mistakes about humans doing annotation. Because I assume humans there's like a range of things they're good at in terms of clicking stuff on screen. Isn't that how interesting is that you have a problem with designing an annotator or humans are accurate, enjoy it. Like what are they even the metrics or efficient or productive, all that kind of stuff? Yeah. So I grew the annotation team at Tesla from basically zero to a thousand while I was there. That was really interesting. You know, my background is a PhD student researcher. So growing that common organization was pretty crazy. But yeah, I think it's extremely interesting and part of the design process very much behind the autopilot as to where you use humans. Humans are very good at certain kinds of annotations. They're very good, for example, at two-dimensional annotations of images. They're not good at annotating cars over time in three-dimensional space, very, very hard. And so that's why we were very careful to design the tasks that are easy to do for humans versus things that should be left to the offline tracker. Like maybe the computer will do older triangulation in three-degree construction. But the human will say exactly these pixels of the image are car. Exactly. These pixels are human. And so co-designing the data annotation pipeline was very much, Brandon Butter was what I was doing daily. Do you think there's still a lot of open problems in that space? Just in general annotation where the stuff the machines are good at, machines do, and the humans do what they're good at. And there's maybe some iterative process. Right. I think to a very large extent, we went through a number of iterations and we learned a ton about how to create these data sets. I'm not seeing big open problems. Like originally when I joined I was like, I was really not sure how this would turn out. But by the time I left, I was much more secure and actually be sort of understanding philosophy about how to create these data sets. And I was pretty comfortable with where that was at the time. So what are strengths and limitations of cameras for the driving task in your understanding? When you formulate the driving task as a vision task with eight cameras, you've seen that the entire, you know, most of the history of the computer vision field when it has to do with neural networks, what, just if you step back, what are the strengths and limitations of pixels of using pixels to drive? Yeah, pixels, I think are a beautiful sensory, beautiful sensor, I would say. The things like cameras are very, very cheap and they provide a ton of information, ton of bits. Also, it's an extremely cheap sensor for a ton of bits and each one of these bits has a constraint on the state of the world. And so you get lots of megapixel images, very cheap and it just gives you all these constraints for understanding what's actually out there in the world. So vision is probably the highest bandwidth sensor. It's a very high bandwidth sensor. And I love that pixels is a constraint on the world. It's this highly complex high bandwidth constraint on the world on the state of the world. It's not just that, but again, this real, real importance of it's the sensor that humans use. Therefore, everything is designed for that sensor. Yeah, the text, the writing, the flashing signs, everything is designed for vision. And so you just find it everywhere. And so that's why that is the interface you want to be in, talking again about these universal interfaces. And that's where we actually want to measure the world as well. And then develop software for that sensor. But there's other constraints on the state of the world that humans use to understand the world. I mean, vision ultimately is the main one. But we were like, we're like referencing our understanding of human behavior and some common sense physics that could be inferred from vision from from a perception perspective. But it feels like we're using some kind of reasoning to predict the world. Yeah, not just the pixels. I mean, you have a powerful prior, so for how the world evolves over time, etc. So it's not just about the likelihood term coming up from the data itself, telling you about what you are observing, but also the prior term of where the likely things to see and how do they likely move and so on. And the question is how complex is the range of possibilities that might happen in the driving task? Right. That's still, is that to you still an open problem of how difficult is driving, like philosophically speaking? Do you, all the time you work on driving, do you understand how hard driving is? Yeah, driving is really hard because it has to do with predictions of all these other agents and the theory of mind and, you know, what they're going to do and are they looking at you, are they, where are they looking, where are they thinking? Yeah, there's a lot that goes there at the full tail off, you know, the expansion of the noise that we have to be comfortable with, and eventually the final problems are of that form. I don't think those are the problems that are very common. I think eventually they're important, but it's like really in the tail end. In the tail end, the rare edge cases, from the vision perspective, what are the toughest parts of the vision problem of driving? Well, basically, the sensor is extremely powerful, but you still need to process that information. And so going from brightnesses of these special values to, hey, here the three-dimensional world is extremely hard, and that's what the neural networks are fundamentally doing. And so the difficulty really is in just doing an extremely good job of engineering the entire pipeline, the entire data engine, having the capacity to train these neural nets, having the ability to evaluate the system and iterate on it. So I would say just doing this in production at scale is like the hard part. It's an execution problem. So the data engine, but also the deployment of the system, such that it has low latency performance, so it has to do all these steps. Yeah, for the neural net specifically, just making sure everything fits into the chip on the car. And you have a finite budget of flops that you can perform, and memory bandwidth and other constraints, and you have to make sure it flies. And you can squeezing as much computer as you can into the tiny. What have you learned from that process? Because maybe that's one of the bigger, like new things coming from a research background, where there's a system that has to run under heavily constrained resources, that's to run really fast. What kind of insights have you learned from that? Yeah, I'm not sure if there's too many insights. You're trying to create a neural net that will fit in what you have available, and you're always trying to optimize it. And we talked a lot about it on the AI day, and basically the triple backflips that the team is doing to make sure it all fits and utilizes the engine. So I think it's extremely good engineering. And then there's all kinds of little insights, peppered in on how to do it properly. Let's actually zoom out because I don't think we talked about the data engine, the entirety of the layout of this idea that I think is just beautiful. With humans in the loop, can you describe the data engine? Yeah, the data engine is what I call the almost biological feeling like process by which you perfect the training sets for these neural networks. Because most of the programming now is in the level of these data sets and make sure they're large, diverse, and clean, basically you have a data set that you think is good. You train your neural net, you deploy it, and then you observe how well it's performing. And you're trying to always increase the quality of your data set. So you're trying to catch scenarios, basically there are basically rare. And it is in these scenarios that your neural net will typically struggle in, because they weren't told what to do in those rare cases in the data set. But now you can close the loop because if you can now collect all those at scale, you can then feed them back into the reconstruction process I described and reconstruct the truth in those cases and add it to the data and so the whole thing ends up being like a staircase of improvement of perfecting your training set. And you have to go through deployments so that you can mine the parts that are not yet represented well on the data set. So your data set is basically imperfect, it needs to be diverse. It has pockets, there are missing, and you need to pat out the pockets. You can sort of think of it that way in the data. What role do humans play in this? So what's the this biological system, like a human body is made up of cells? What role, like how do you optimize the human system? The multiple engineers collaborating, figuring out what to focus on, what to contribute, which task to optimize in this neural network? Who is in charge of figuring out which task needs more data? What can you speak to the hyperparameters, the human system? It really just comes down to extremely good execution from an engineering team and those of what they're doing. They understand intuitively the philosophical insights underlying the data engine and the process by which the system improves and how to again, like delegate the strategy of the data collection and how that works and then just making sure it's all extremely well executed. And that's where most of the work is, is not even the philosophizing or the research or the idea of it is just extremely good execution is so hard when you're dealing with data at that scale. So your role in the data engine executing well on it is difficult and extremely important. Is there a priority of like a vision board of saying like we really need to get better at stoplights? Yeah, the prioritization of tasks is that essentially and that comes from the data? That comes to the very large extent to what we are trying to achieve in the product format, what we're trying to, the release we're trying to get out in the feedback from the Q18 worth it where the system is struggling or not, the things we're trying to improve. And the Q18 gives some signal, some information in aggregate about the performance of the system in various conditions. And then of course all of us drive it and we can also see it. It's really nice to work with a system that you can also experience yourself and it drives you home. Is there some insight you can draw from your individual experience that you just can't quite get from an aggregate statistical analysis of data? Yeah, it's so weird, right? Yes. It's not scientific in a sense because you're just one anecdotal sample. Yeah, I think there's a ton of, it's a source of truth. It's your interaction with the system and you can see it, you can play with it, you can perturb it, you can get a sense of it, you have an intuition for it. I think numbers just like have a way of numbers and plots and graphs are much harder. It hides a lot of, it's like if you train a language model, it's a really powerful way is by you interacting with it. Yeah, 100% try to build up an intuition. Yeah, I think like Elon also like he always wanted to drive the system himself. He drives a lot and I don't want to say almost daily. So he also sees this as a source of truth. You driving the system and it performing and yeah. So what do you think? Tough questions here. So Tesla last year removed radar from the sensor suite and now just announced that it's going to remove all ultrasonic sensors relying solely on vision. So camera only. Does that make the perception probably harder or easier? I would almost reframe the question in some way. So the thing is basically you would think that additional sensors, by the way, can't just interrupt. I wonder if the language model will ever do that if you prompt it. Let me reframe your question. That would be epic. This is the wrong problem. Sorry. It's like a little bit of a wrong question because basically you would think that these sensors are an asset to you. But if you fully consider the entire product and its entirety, these sensors are actually potentially liability because these sensors aren't free. They don't just appear on your car. You need suddenly you have an entire supply chain. You have people procuring it. There can be problems with them. They may need replacement. They are part of the manufacturing process. They can hold back the line in production. You need to source them. You need to maintain them. You have to have teams that ride the firmware, all of it, and then you also have to incorporate them, fuse them into the system in some way. And so it actually like blows the organ, the a lot of it. And I think Elon is really good at simplifying, simplify, best part is no part. And he always tries to throw away things that are not essential because he understands the entropy in organizations and in the approach. And I think in this case, the cost is high and you're not potentially seeing it if you're just a computer vision engineer. And I'm just trying to improve my network and, you know, is it more useful or less useful? How useful is it? And the thing is, once you consider the full cost of a sensor, it actually is potentially a liability. And you need to be really sure that it's giving you extremely useful information. In this case, we looked at using it or not using it and the delta was not massive. And so it's not useful. Is it also blow in the data engine, like having more sensors? 100% at the end is a distraction. And these sensors, you know, they can change over time, for example, you can have one type of say radar, you can have other type of radar, they change over time. And I suddenly need to worry about it. And I'm suddenly going to have a column in your SQL light telling you, oh, what sensor type was it? And they all have different distributions. And then they can, they can just, they contribute noise and entropy into everything. And they blow stuff. And also organizationally has been really fascinating to me that it can be very distracting. If you, if all, if you only want to get to work as vision, all the resources are on it and you're building out a data engine. And you're actually making forward progress because that is the, the sensor with the most bandwidth, the most constraints on the world. And you're investing fully into that and you can make that extremely good. If you're, you're only a finite amount of sort of spend of focus across different facets of the system. And this kind of reminds me of reach sudden is a bit of lesson. It just seems like simplifying the system. Yeah. In the long run, not, of course, you know, know what the long way is. It seems to be always the right solution. Yeah. In that case, it was for RL, but it seems to apply generally across all systems that do computation. So where, what do you think about the LiDAR as a crutch debate? The battle between point clouds and pixels. Yeah, I think this debate is always like slightly confusing to me because it seems like the actual debate should be about like, do you have the fleet or not? That's like the really important thing about whether you can achieve a really good functioning of an AI system at the scale. So data collection systems. Yeah. Do you have a fleet or not is significantly more important whether you have LiDAR or not? It's just another sensor. And yeah, I think similar to the radar discussion, basically, I, I don't think it, it basically doesn't offer extra extra information. It's extremely costly. It has all kinds of problems. You have to worry about it. You have to calibrate it, etc. It creates blow to an entropy. You have to be really sure that you need this, this sensor. In this case, I basically don't think you need it. And I think honestly, I will make a stronger statement. I think the others, some of the other companies who are using it are probably going to drop it. Yeah. So you have to consider the sensor in the full, in considering can you build a big fleet that collects a lot of data and can you integrate that sensor with that, that data and that sensor into a data engine that's able to quickly find different parts of the data that then continuously improves whatever the model that you're using. Yeah. Another way to look at it is like vision is necessary in a sense that the drive, the world is designed for human visual consumption. So you need vision. It's necessary. And then also it is sufficient because it has all the information that you need for driving and humans, obviously, is vision to drive. So it's both necessary and sufficient. So you want to focus resources. And you have to be really sure if you're going to bring in other sensors, you could, you could, you could add sensors to infinity at some point, you need to draw the line. And I think in this case, you have to really consider the cost of any one sensor that you're adopting. And do you really need it? And I think the answer in this case is no. So what do you think about the idea that the other companies are forming high resolution maps and constraining heavily the geographic regions in which they operate is that approach not in your, in your view, not going to scale over time to the entirety of the United States. I think to mention like they pre-map all the environments and they need to refresh the map. And they have a perfect centimeter level accuracy map of everywhere they're going to drive. It's crazy. How are you going to, when we're talking about autonomy actually changing the world, we're talking about the deployment on a global scale, autonomous systems for transportation. And if you need to maintain a centimeter accurate map for earth, we're like for many cities and keep them updated. It's a huge dependency that you're taking on huge dependency. It's a massive massive dependency. And now you need to ask yourself, do you really need it? And humans don't need it. Right? So it's very useful to have a low level map of like, okay, the connectivity of your road, you know that there's a fork coming up. When you drive an environment, you sort of have that high level understanding. It's like a small Google map and Tesla uses Google map like similar kind of resolution information in its system, but it will not pre-map environments to send me a centimeter level accuracy. It's a crotch. It's a distraction. It costs entropy. And it defuses the team. It dilutes the team. And you're not focusing on what's actually necessary, which is the computer vision problem. What did you learn about machine learning, about engineering, about life, about yourself as one human being from working with Elon Musk? I think the most I've learned is about how to sort of run organizations efficiently and how to create efficient organizations and how to fight entropy in an organization. So human engineering in the fight against entropy. Yeah. I think Elon is a very efficient warrior in the fight against entropy in organizations. What does the entropy in an organization look like? Exactly. It's process. It's process and in efficiencies in the human beings and that kind of stuff. Yeah, meetings. He hates meetings. He keeps telling people to skip meetings if they're not useful. He basically runs the world's biggest startups, I would say. Tesla's basics are the world's biggest startups. Tesla actually is multiple startups. I think it's better to look at it that way. And so I think he's extremely good at that. He's a very good intuition for streamline processes, making everything efficient. Best part is no part, simplifying, focusing and just kind of removing barriers, moving very quickly, making big moves. All this is a very startup-y sort of seeming things, but at scale. So strong drive to simplify, from your perspective, I mean that also probably applies to just designing systems and machine learning and otherwise, like simplifying, simplifying. Yes. What do you think is the secret to maintaining the startup culture in a company that grows? Is there, can you introspect that? I do think he needs someone in a powerful position with a big hammer like Elon, who's like the cheerleader for that idea and ruthlessly pursues it. If no one has a big enough hammer, everything turns into committees, democracy within the company, process, talking to stakeholders, decision-making, just everything just crumbles. If you have a big person who is also really smart and has a big hammer, things move quickly. So you said your favorite scene in Interstellar is the intense docking scene with the AI and Cooper talking, saying, Cooper, what are you doing? Docking, it's not possible. No, it's necessary. That's your good line. By the way, just so many questions there. Why an AI in that scene, presumably, is supposed to be able to compute a lot more than the human. It's saying it's not optimal. Why the human? I mean, that's a movie, but shouldn't the AI know which better than the human? Anyway, what do you think is the value of setting seemingly impossible goals? So like, our initial intuition, which seems like something that you have taken on that Elon espouses that where the initial intuition of the community might say this is very difficult, and then you take it on anyway with a crazy deadline. You're just from a human engineering perspective. Have you seen the value of that? I wouldn't say that setting impossible goals exactly is a good idea, but I think setting very ambitious goals is a good idea. I think there's a what I call sublinear scaling of difficulty, which means that 10X problems are not 10X hard. Usually 10X, 10X harder problem is like two or three X harder to execute on, because if you want to improve the system by 10%, it costs some amount of work, and if you want to 10X improve the system, it doesn't cost 100X amount of the work. And it's because you fundamentally change the approach. And if you start with that constraint, then some approaches are obviously dumb and not going to work. And it forces you to re-evaluate, and I think it's a very interesting way of approaching problem solving. But it requires us weird thinking, going back to your PhD days, is like, how do you think which ideas in the machine learning community are solvable? Yes. It requires, what is that? I mean, there's the cliche of first principles thinking, but it requires to basically ignore what the community is saying, because it doesn't a community in science usually draw lines of what isn't as impossible. And it's very hard to break out of that without going crazy. Yeah. I mean, I think a good example here is the deep learning revolution, in some sense, because you could be in computer vision at that time during the deep learning revolution of 2012 and so on. You could be improving a computer vision stack by 10%, or we can just be saying, actually, all of this is useless. And how do I do 10X better computer vision? Well, it's not probably by tuning a hog feature detector. I need a different approach. I need something that is scalable, going back to Richard Sutton's, and understanding sort of like the philosophy of the bitter lesson, and then being like, actually, I need much more scalable system like neural network, that in principle works, and then having some deep believers that can actually execute on that mission and make it work. So that's the 10X solution. What do you think is the timeline to solve the problem of autonomous driving? This still in part open question. Yeah. I think the tough thing with timelines of solve driving, obviously, is that no one has created solve driving. Yeah. So it's not like, what do you think is the timeline to build this bridge? Well, we've built million bridges before. Here's how long that takes. It's, you know, it's, uh, no one has built autonomy. It's not obvious. Uh, some parts turn out to be much easier than others. It's really hard to forecast. You do your best based on trend lines and so on, and based on intuition, but that's why fundamental is just really hard to forecast this. No one has to even still like being inside of it is hard to do. Yes. Some things turn out to be much harder and some things turn out to be much easier. Do you try to avoid making forecasts? Because like, Elon doesn't avoid them, right? And heads of car companies in the past have not avoided it either. Ford and other places have made predictions that we're going to solve a level for driving by 2020, 2021, whatever. And now they all kind of backtrack in that prediction. I you as a, as an AI person, do you for yourself privately make predictions or do they get in the way of like your actual ability to think about a thing? Yeah, I would say like, what's easy to say is that this problem is tractable and that's an easy prediction to make. It's tractable. It's going to work. Yes, it's just really hard. Some things turn out to be harder and some things turn out to be easier. But it definitely feels tractable and it feels like at least the team at Tuscalau, which is what I saw internally, is definitely on track to that. How do you form a strong representation that allows you to make a prediction about tractability? So like, you're the leader of a lot of humans. You have to kind of say this is actually possible. How do you build up that intuition? It doesn't have to be even driving. It could be other tasks. It could be, I want to what difficult tasks did you work on your life? I mean, classification, achieving certain, just an image net, certain level of superhuman level performance. Yeah, expert intuition. It's just intuition. It's belief. So just like thinking about it long enough, like studying, looking at sample data, like you said, driving, my intuition was really flawed on this. Like, I don't have a good intuition about tractability. It could be either it could be anything. It could be solvable. Like, the driving task could be simplified into something quite trivial. Like, the solutions of the problem would be quite trivial. And at scale, more and more cars driving perfectly might make the problem much easier. The more cars you have driving, like people learn how to drive correctly, not correctly, but in a way that's more optimal for heterogeneous system of autonomous and semi-autonomous and manually driven cars. That could change stuff. Then again, also I've spent a ridiculous number of hours just staring at pedestrians crossing streets, thinking about humans. And it feels like the way we use our eye contact, it sends really strong signals. And there's certain quirks in edge cases of behavior. And of course, a lot of the fatalities that happen have to do with drunk driving and both on the pedestrian side and the driver side. So there's that problem of driving at night and all that kind of stuff. So I wonder, you know, it's like the space of possible solution in autonomous driving includes so many human factor issues that it's almost impossible to predict. It could be super clean, nice solutions. Yeah. I would say definitely like to use a game analogy, there's some fog of war. But you definitely also see the frontier of improvement. And you can measure historically how much you've made progress. And I think, for example, at least what I've seen in roughly five years at Tesla, when I joined it barely kept lane on the highway. I think going up from Pellalto to SF was like three or four interventions. Anytime the road would do anything geometrically or turn too much, it would just like not work. And so going from that to like a pretty competent system in five years and seeing what happens also under the hood. And what the scale of which the team is operating now with respect to data and compute to everything else is just massive progress. So you're climbing them out and fog, but you make a lot of progress. You're making progress and you see what the next directions are and you're looking at some of the remaining challenges and they're not like, they're not perturbing you and they're not changing your philosophy and you're not contorting yourself. You're like, actually, these are the things I just don't need to do. Yeah, the fundamental components of solving the problem seem to be there from the data engine to the computer, the computer on the car to the computer to the training, all that kind of stuff. So you've done over the years, you've been a test. You've done a lot of amazing breakthrough ideas and engineering, all of it from the data engine to the human side, all of it. Can you speak to why you chose to leave Tesla? Basically, as I described that, Ren, I think over time, during those five years, I've gotten myself into a little bit of a managerial position. Most of my days were meetings and growing the organization and making decisions about a sort of high level strategic decisions about the team and what it should be working on and so on. It's kind of like a corporate executive role and I can do it. I think I'm okay at it, but it's not like fundamentally what I enjoy. So I think when I joined, there was no computer vision team because Tesla was just going from the transition of using mobile eye at third party vendor for all of its computer vision to having to build its computer vision system. So when I showed up, there were two people training deep neural networks and they were training them at a computer at their legs, like yeah, there's a workstation. There's a basic classification task. Yeah, and so I kind of like grew that into what I think is a fairly respectable deep learning team, massive computer cluster, a very good data annotation organization and I was very happy with where that was. It became quite autonomous and so I kind of stepped away and I, you know, I'm very excited to do much more technical things again. Yeah, and kind of like we focus on AGI. What was this soul-searching like because you took a little time off and think like what how many mushrooms did you take? I mean, what was going through your mind? The human lifetime is finite. Yeah, he did a few incredible things. You're one of the best teachers of AI in the world. You're one of the best, and I don't mean that, I mean, the best possible way. You're one of the best tinkerers in the AI world, meaning like understanding the fundamental fundamentals of how something works by building it from scratch and playing with it with the basic intuitions. It's like Einstein, Feynman, we're all really good at this kind of stuff. Like a small example of a thing to play with it, to try to understand it so that, and obviously now with us, you help build a team of machine learning like engineers and assistant that actually accomplished something in the real world. So given all that, like what was the soul-searching like? Well, it was hard because obviously I love the company a lot and I love Elon. I love Tesla. I want, it was so much hard to leave. I love the team basically. But yeah, I think actually I will be potentially like interested in revisiting it. Maybe coming back at some point, working in Optimus, working in AGI at Tesla. I think Tesla is going to do incredible things. It's basically like, it's a massive large-scale robotics kind of company with a ton of in-house talent for doing really incredible things. And I think human or robots are going to be amazing. I think autonomous transportation is going to be amazing. All this is happening at Tesla. So I think it's just a really amazing organization. So being part of it and helping it along, I think was very, basically I enjoyed that a lot. Yeah, it was basically difficult for those reasons because I love the company. But I'm happy to potentially at some point come back for Act 2. But I felt like at this stage, I built the team, it felt autonomous and I became a manager and I wanted to do a lot more technical stuff. I wanted to learn stuff. I wanted to teach stuff. And I just kind of felt like it was a good time for a change of pace a little bit. What do you think is the best movie sequel of all times speaking of part two? Because most of them suck. Movie sequels? Movie sequels, yeah. And you tweeted about movies. So just in a tiny tangent, was there, what's like a favorite movie sequel? Got Father Part Two? Are you a fan of Godfather? Because you didn't even tweet or mention the Godfather. Yeah, I don't love that movie. I know it hasn't. I'm gonna edit that out. We're gonna edit out the hate towards the Godfather. How dare you just make a strong statement. I don't know why. I don't know why. But I basically don't like any movie before 1995. Something like that. Didn't you mention Terminator? Okay, okay. That's like a Terminator 2 was a little bit later 1990. No, I think Terminator 2 was in the 80s. And I like Terminator 1 as well. So, okay, so like a few exceptions. But by and large, for some reason, I don't like movies before 1995 or something. They feel very slow. The camera is like zoomed out. It's boring. It's kind of naive. It's kind of weird. And also Terminator was very much ahead of its time. Yes. And the Godfather, there's like no AGI. So... I mean, but you have good will hunting was one of the movies you mentioned. And that doesn't have any AGI either. I guess that's mathematics. Yeah. I guess occasionally I do in general. He said that don't feature or like anchor man. That has no that's that's. That's so good. I don't understand. I'm speaking of AGI because I don't understand why wolf arrows so funny. It doesn't make sense. It doesn't compute. There's just something about him. And he's a singular human because you don't get that many comedies these days. And I wonder if I have to do about the culture or the like the machine of Hollywood or does have to do with just we got lucky with certain people in comedy. It came together because he is a singular human. That was a ridiculous tangent I apologize. But you mentioned human or robots. So what do you think about Optimus? About Tesla bot. Do you think we'll have robots in the factory and in the home in 10, 20, 30, 40, 50 years? Yeah. I think it's a very hard project. I think it's going to take a while. But who else is going to build human or robots at scale? Yeah. And I think it is a very good form factor to go after because like I mentioned, the world is designed for human and form factor. These things would be able to operate our machines. They would be able to sit down in chairs, potentially even drive cars. Basically, the world is designed for humans. That's the form factor you want to invest into and make work over time. I think there's another school of thought which is, okay, pick a problem and design a robot to it. But actually designing a robot and getting a whole data engine and everything behind it to work is actually a really hard problem. So it makes sense to go after general interfaces that, okay, they are not perfect for anyone given task, but they actually have the generality of just with a prompt with English able to do something across. And so I think it makes a lot of sense to go after a general interface in the physical world. And I think it's a very difficult project. Things are going to take time. But I've seen no other company that can execute on that vision. I think it's going to be amazing. Like basically physical labor. Like if you think transportation is a large market, try physical labor. But it's not just physical labor to me. The thing that's also exciting is the social robotics. So the relationship will have on different levels with those robots. That's why I was really excited to see Optimus. People have criticized me for the excitement. But I've worked with a lot of research labs that do humanoid, legate robots, Boston dynamics, unitary, a lot, there's a lot of companies that do legate robots. But that's the the elegance of the movement is a tiny, tiny part of the big picture. So integrating the two big exciting things to me about Tesla doing humanoid or any legate robots is clearly integrating into the data engine. So the data engine aspect. So the actual intelligence for the perception of the control and the planning and all that kind of stuff, integrating into the fleet that you mentioned. And then speaking of fleet, the second thing is the mass manufacturers. Just knowing culturally driving towards a simple robot that's cheap to produce at scale and doing that well, having experience to do that well, that changes everything. That's why that's a very different culture and style than Boston dynamics. Who by the way, those robots are just the way they move. It's like it'll be a very long time before Tesla could achieve the smoothness of movement. But that's not what it's about. It's about the entirety of the system, like we talked about the data engine and the fleet. That's super exciting. Even the initial sort of models. But that too was really surprising that in a few months, you can get a prototype. And the reason that happened very quickly is as you alluded to, there's a ton of copy based from what's happening on the autopilot. A lot. The amount of expertise that came out of the woodworks at Tesla for building the human robot was incredible to see. Basically Elon said at one point we're doing this. And then next day basically, all these CAD models started to appear. And people talking about the supply chain and manufacturing. And people showed up with screw drivers and everything the other day and started to put together the body. And I was like, whoa, all these people exist at Tesla. And fundamentally building a car is actually not that different from building a robot. The same thing. And that is true. Not just for the hardware pieces. And also, let's not forget hardware, not just for demo, but manufacturing of that hardware at scale. It's like a whole different thing. But for software as well, basically this robot currently thinks it's a car. It's going to have a mid-life crisis. It thinks it's a car. Some of the earlier demos, actually, we were talking about potentially doing them outside in the parking lot because that's where all of the computer vision was like working out of the box instead of like inside. But all the operating system, everything just copy-paste, computer vision, mostly copy-paste. I mean, you have to retrain the neural nuts, but the approach on everything and data engine and offline trackers and the way we go about the occupancy tracker and so on everything copy-paste. You just need to retrain the neural nuts. And then the planning control, of course, has to change quite a bit. But there's a ton of copy-paste from what's happening at Tesla. And so if you were to go with goal of like, okay, let's build a million human robots and you're not Tesla, that's a lot to ask. If you're Tesla, it's actually like, it's not that crazy. And then the follow-up question is on how difficult, just like we're driving, how difficult is the manipulation task such that it can have an impact at scale. I think, depending on the context, the really nice thing about robotics is that unless you do a manufacturer and that kind of stuff, is there is more room for error driving is so safety critical and also time critical. Okay, robot is allowed to move slower, which is nice. Yes. I think it's going to take a long time, but the way you want to structure the development is you need to say, okay, it's going to take a long time. How can I set up the product development roadmap so that I'm making revenue along the way? I'm not setting myself up for a zero-one loss function where it doesn't work until it works. You don't want to be in that position. You want to make it useful, almost immediately, and then you want to slowly deploy it and at scale. That's it. That's scale. You want to set up your data engine, your improvement loops, the telemetry, the evaluation, the harness, and everything. You want to improve the product over time incrementally and you're making revenue along the way. That's extremely important, because otherwise you cannot build these large undertakings, just like don't make sense economically. And also from the point of view of the team working on it, they need the dopamine along the way. They're not just going to make a promise about this being useful. This is going to change the world in 10 years when it works. This is not where you want to be. You want to be in a place like I think Audipald is today where it's offering increased safety and convenience of driving today. People pay for it, people like it, people purchase it, and then you also have the greater mission that you're working towards. And you see that. So the dopamine for the team that was the source of happiness and success. Yes. And for us. You're deploying this, people like it, people drive it, people pay for it, they care about it. There's all these YouTube videos. Your grandma drives it. She gives you feedback, people like it, people engage with it. You engage with it. Huge. Do people that drive Tesla's like recognize you and give you love like, like, hey, thanks for the, for the, this nice feature that is doing. Yeah, I think the tricky thing is like, some people really love you. Some people unfortunately like you're working on something that you think is extremely valuable, useful, etc. Some people do hate you. There's a lot of people who like hate me and the team and what everything, the whole project. And I think they're Tesla drivers. Many cases, they're not actually. Yeah, that's that's actually makes me sad about humans or the current ways that humans interact. I think that's actually fixable. I think humans want to be good to each other. I think Twitter and social media is part of the mechanism that actually somehow makes the negativity more viral that it doesn't deserve like disproportionately add of like a viral viral boost of negativity. But I got, I wish people would just get excited about, so suppress some of the jealousy, some of the ego and just get excited for others. And then there's a karma aspect to that. You get excited for others. They'll get excited for you. Same thing in academia. If you're not careful, there is like a dynamical system there. If you if you think of in silos and get jealous of somebody else being successful, that actually perhaps counterintuitively leads the less productivity of you as a community and you individually. I feel like if you keep celebrating others, that actually makes you more successful. Yeah, I think people haven't in depending on the industry, haven't quite learned that yet. Yeah. Some people are also very negative and very vocal, so they're very prominently featured. But actually there's a ton of people who are a cheerleaders, but they're silent cheerleaders. When you talk to people just in the world, they will all tell you it's amazing. It's great, especially like people who understand how difficult it is to get this stuff working. Like people who have built products and makers and entrepreneurs, like making this work and changing something is incredibly hard. Those people are more likely to cheerlead you. Well, one of the things that makes me sad is some folks in the robotics community don't do the cheerleading and they should. There's a, because they know how difficult it is. Well, they actually sometimes don't know how difficult it is to create a product that scale. They actually deploy in the real world. A lot of the development of robots and AI system is done on very specific small benchmarks. As opposed to real world conditions. Yeah, I think it's really hard to work on robotics in academic setting or AI systems that apply in the real world. You've criticized you flourished and loved for time the image net, the famed image net data set. And I've recently had some words of criticism that the academic research ML community gives a little too much love still to the image net or like those kinds of benchmarks. Can you speak to the strengths and weaknesses of data sets used in machine learning research? Actually, I don't know that I recall the specific instance where I was unhappy or criticizing image net. I think image net has been extremely valuable. It was basically a benchmark that allowed the deep learning community to demonstrate that deep neural works actually work. There's a massive value in that. So I think image net was useful, but basically it's become a bit of an emnist at this point. So emnist is like 228 by 28 grayscale digits. There's kind of a joke data set that everyone like crushes. There's no papers written on emnist though, right? Maybe they should have strong papers. Yeah. Like papers that focus on like how do we learn with a small amount of data that could stuff. Yeah, I could see that being helpful, but not in sort of like a mainline computer vision research anymore, of course. I think the way I've heard you somewhere, maybe I'm just imagining things, but I think you said like image net was a huge contribution to the community for a long time and now it's time to move past those kinds of... Well, image net has been crushed. I mean, you know, the error rates are... Yeah, we're getting like 90% accuracy in in 1000 classification way prediction. And I've seen those images and it's like really high. That's really that's really good. If I'm incorrectly the top five error rate is now like 1% or something. Given your experience with a gigantic real world data set, would you like to see benchmarks moving in certain directions that the research community uses? Unfortunately, I don't think academics currently have the next image net. We've obviously, I think we've crushed emnist. We've basically kind of crushed image net and there's no next sort of big benchmark that the entire community rel is behind and uses you know, for further development of these networks. Yeah, what it would it takes for data set to captivate the imagination of everybody like where they all get behind it. That could also need like a virus like a leader. Right. Yeah, somebody with popularity. I mean, yeah, what did it image net take off? Is it just the accident of history? It was the right amount of difficult. It was the right amount of difficult and simple and interesting enough. It just kind of like, it was it was the right time for that kind of a data set. Question from Reddit. What are your thoughts on the role of the synthetic data and game engines will play in the future of neural net model development? I think as neural nets converge to humans, the value of simulation to neural nets will be similar to value of simulation to humans. So people use simulation for people use simulation because they can learn something in that kind of a system and without having to actually experience it. But you're referring to the simulation doing our head. No, sorry simulation. I mean like video games or other forms of simulation for various professionals. Well, let me push back because maybe there's simulation that we do in our heads. Like, simulate if I do this, what do I think will happen? Okay, that's like internal simulation. Yeah, internal. Isn't that what we're doing? As you imagine before we act? Yeah, but that's independent from like the use of simulation in a sense of computer games or using simulation for training, set creation or is it independent or is it just loosely correlated? Because like, isn't that useful to do like a counterfactual or like edge case simulation to like, you know, what happens if there's a nuclear war? What happens if there's, you know, like those kinds of things? Yeah, that's a different simulation from like unrelenged. That's how I interpreted the question. Ah, so like simulation of the average case. What's unrelenged? What do you mean by unrelenged? So simulating a world, physics of that world, why is that different? Like, because you also can add behavior to that world and you can try all kinds of stuff, right? You could throw all kinds of weird things into it. So a real engine is not just about simulating, I mean, I guess it is about simulating the physics of the world. It's also doing something with that graphics, the physics and the agents that you put into the environment and stuff like that. Yeah, I think you feel like you said that it's not that important, I guess, for the future of AI development. Is that correct to interpret it either way? I think humans use simulators for humans use simulators and they find them useful. And so computers will use simulators and find them useful. Okay, so you're saying it's not the, I don't use simulators very often. I play a video game every once in a while, but I don't think I derive any wisdom about my own existence from from those video games. It's a momentary escape from reality versus a source of wisdom about reality. So I don't, so I think that's a very polite way of saying simulations not that useful. Yeah, maybe, maybe not. I don't see it as like a fundamental, really important part of like training neural nets currently. But I think as neural nets become more and more powerful, I think you will need fewer examples to train additional behaviors. And simulation is, of course, there's a domain gap in a simulation that is not the real world. It's slightly something different. But with a powerful and a neural net, you need the domain gap can be bigger, I think, because neural net will sort of understand that even though it's not the real world, it like has all this high level structure that I'm supposed to be learning from. So the neural net will actually, yeah, be able to leverage this aesthetic data better by closing the gap, but understanding in which ways this is not real data. Exactly. I'm ready to do better questions next time. That was that was a question that I'm just kidding. All right. So is it possible, do you think speaking of MNIST to construct neural nets and training processes that require very little data? So we've been talking about huge data sets, like the internet for training. I mean, one way to say that is like you said, like the querying itself is another level of training, I guess, and that requires a little data. But do you see any value in doing research and kind of going down the direction of can we use very little data to train to construct a knowledge base? 100%. I just think like at some point you need a massive data set. And then when you pre-training your massive neural net and get something that is like a GPT or something, then you're able to be very efficient at training and you're returning new tasks. So a lot of these GPTs, you can do tasks like sentiment analysis or translation or so on just by being prompted with very few examples. Here's the kind of thing I want you to do. Like here's an input sentence, here's the translation into German, input sentence, translation to German, input sentence, blank, and the neural net will complete the translation to German just by looking at sort of the example you've provided. And so that's an example of a very few shot learning in the activations of the neural net instead of the weights of the neural net. And so I think basically just like humans, neural nets will become very data efficient at learning any other new tasks. But at some point, you need a massive data set to pre-training your network to get that. And probably we humans have something like that. Do we have something like that? Do we have a passive in the background, background model constructing thing that just runs all the time in a self-supervised way? We're not conscious of it. I think humans definitely, I mean, obviously we have, we learn a lot during our lifespan, but also we have a ton of hardware that helps us initialize, initialization coming from evolution. And so I think that's also a really big component. A lot of people in the field, I think they just talk about the amounts of seconds and the, you know, that a person has lived pretending that this is a taboo of a rasa, sort of like a zero initialization of a neural net. And it's not like you can look at a lot of animals like, for example, Zeebras, Zeebras get born and they see and they can run. There's zero trained data in their lifespan. They can just do that. So somehow I have no idea how evolutionists found a way to encode these algorithms and these neural net initializations that are extremely good into ATCGs. And I have no idea how this works, but apparently it's possible because here's proof by existence. There's something magical about going from a single cell to an organism that is born to the first few years of life. I kind of like the idea that the reason we don't remember anything about the first few years of our life is that it's a really painful process. Like it's a very difficult challenging training process. Yeah. Like intellectually. Like, and maybe, yeah, I mean, I don't, why don't we remember any of that? There might be some crazy training going on. And that the, maybe that's the back-on model training that is very painful. And so it's best for the system once it's trained not to remember how it's constructed. I think it's just like the hardware for long-term memory is just not fully developed. Sure. I kind of feel like the first few years of, of infants is not actually like learning. It's brain maturing. Yeah. We're born premature. There's a theory along those lines because of the birth canal and this, along the brain. And so we're born premature. And then the first few years were just the brain's maturing. And then there's some learning eventually. It's my current view on it. What do you think, do you think neural nets can have long-term memory? Like, that approach is something like humans. Do you think you're, do you think there needs to be another meta-architecture on top of it to add something like a knowledge base that learns facts about the world and all that kind of stuff? Yes, but I don't know to what extent it will be explicitly constructed. It might take unintuitive forms where you are telling the GPT like, hey, you have a, you have a declarative memory bank to which you can store and retrieve data from. And whenever you encounter some information that you find useful, just save it to your memory bank. And here's an example of something you have retrieved and how you say it and here's how you load from it. You just say load whatever you teach it in text in English. And then it might learn to use a memory bank from, from that. Oh, so the neural net is the architecture for the background model, the, the, the base thing. And then everything else is just on top of that. It's not just text, right? It's a, you're given it gadgets and gizmos. So you're teaching some kind of a special language by which we can, it can save arbitrary information and retrieve it at a later time. And you're, you're telling about these special tokens and how to arrange them to use these interfaces. It's like, hey, you can use a calculator. Here's how you use it. Just do five, three, plus four, one equals. And when equals is there, a calculator will actually read out the answer and you don't have to calculate it yourself. And you just like tell it in English, this might actually work. Do you think in that sense, Goddo is interesting. The deep mind system that it's not just new language, but actually throws it all in the same pile, images, actions, all that kind of stuff. That's basically what we're moving towards. Yeah, I think so. So Goddo is, is very much a kitchen sink off approach to like reinforcement learning lots of different environments with a single fixed transformer model. Right. I think it's a very sort of early result in that in that realm. But I think, yeah, it's a long the lines of what I think things will eventually look like. Right. So this is the early days of a system that eventually will look like this, like from a rich, a certain perspective. Yeah, I'm not super huge fan of I think all these interfaces that like look very different. I would want everything to be normalized into the same API. So for example, screen pixels, very same API, instead of having like different world environments that are very different physics and joint configurations and appearances and whatever. And you're having some kind of special tokens for different games that you can plug. I'd rather just normalize everything to a single interface. So it looks the same to the neural lot. If that makes sense. So it's all going to be pixel based pong in the end. I think so. Okay. Let me ask you about your own personal life. A lot of people want to know you're one of the most productive and brilliant people in the history of AI. What does a productive day in the life of Andre Kapati look like? What time do you wake up? You look as imagine some kind of dance between the average productive day and a perfect productive day. So the perfect productive day is the thing we strive towards in the average is kind of what it kind of converges to. Yeah. And all the mistakes and human eventualities and so on. Yeah. So what times you wake up? Like a morning person? I'm not a morning person. I'm a night owl for sure. I think stable or not. That's semi stable like eight or nine or something like that. During my PhD it was even later. I used to go to sleep usually at three a.m. I think the a.m. hours are precious and very interesting time to work because everyone is asleep at eight a.m. or seven a.m. the east coast is awake. So there's already activity. There's already some text messages, whatever, there's stuff happening. You can go on like some news website and there's stuff happening and distracting. At three a.m. everything is totally quiet. And so you're not going to be bothered and you have solid chunks of time to do work. So I like those periods night owl by default. And then I think like productive time basically what I like to do is you need you need to like build some momentum on the problem without too much distraction. And you need to load your RAM, your working memory with that problem. And then you need to be obsessed with it when you're taking shower, when you're falling asleep, you need to be obsessed with the problem and it's fully in your memory and you're ready to wake up and work on it right there. So it is a skill of, is this in a scale temporal scale of a single day or a couple of days a week a month? So I can't talk about one day basically in isolation because it's a whole process when I want to get, when I want to get productive in the problem, I feel like I need a span of a few days where I can really get in on that problem. And I don't want to be interrupted and I'm going to just be completely obsessed with that problem. And that's where I do most of my good workouts. You've done a bunch of cool like little projects in a very short amount of time very quickly. So that requires you just focusing on it. Yeah, basically I need to load my working memory with the problem and I need to be productive because there's always like a huge fixed cost to approaching any problem. You know, like I was struggling with this for example, I test a lot because I want to work on a small side project. But okay, you first need to figure out, okay, I need to SSH into my cluster. I need to bring up a VS code editor so I can like work on this. I need to, I run into some stupid error because of some reason. Like you're not at a point where you can be just productive right away. You are facing barriers. And so it's about really removing all that barrier and you're able to go into the problem and you have the full problem loaded in your memory. And somehow avoiding distractions of all different forms like new stories, emails, but also distractions from other interesting projects that you previously worked out, are currently working on and so on. You just want to really focus your mind. And I mean, I can take some time off for distractions and in between, but I think it can't be too much. You know, most of your day is sort of like spent on that problem. And then, you know, I drink coffee, I have my morning routine, I look at some news, Twitter, Hacker news, Wall Street Journal, etc. So it's great. So basically you wake up, you have some coffee, are you trying to get to work as quickly as possible? Do you do take in this diet of like what the hell is happening in the world first? I do find it interesting to know about the world. I don't know that it's useful or good, but it is part of my routine right now. So I do read through a bunch of news articles and I want to be informed. And I'm suspicious of it. I'm suspicious of the practice, but currently that's where I am. Oh, you mean suspicious about the positive effect of that practice on your productivity and your well-being is my well-being psychologically. And also on your ability to deeply understand the world because there's a bunch of sources of information. You're not really focused on deeply integrating it. Yeah, that's loaded distracting. Yeah. In terms of a perfectly productive day for how long of a stretch of time in one session, do you try to work and focus anything? A couple hours is one hour is it 30 minutes is 10 minutes? I can probably go like a a small few hours and then any some breaks in between for like food and stuff. And yeah, but I think like it's still really hard to accumulate hours. I was using a tracker that told me exactly how much time I spent coding any one day. And even on a very productive day, I still spent only like six or eight hours. Yeah. And it's just because there's so much padding, commute, talking to people, food, etc. There's like the cost of life just living and sustaining and homeostasis and just maintaining yourself as a human is very high. And there seems to be a desire within the human mind to to participate in society that creates that padding. Yeah. The most productive days of ever had is just completely from start to finish just tuning out everything. Yeah. And just sitting there. And then you could do more than six and eight hours. Is there some ways that we'll about what gives you strength to do like tough days of long focus? Yeah, just like whenever I get obsessed about a problem, something just needs to work. Some just needs to exist. It needs to exist. And so you're able to deal with bugs and programming issues and technical issues and design decisions that turn out to be the wrong ones. You're able to think through all that given given that you want to think to exist. Yeah, it needs to exist. And then I think to me also a big factor is, you know, our other humans are going to appreciate it. Are they going to like it? That's a big part of my motivation. If I'm helping humans and they seem happy, they say nice things, they tweet about it or whatever, that gives me pleasure because I'm doing something useful. So like you do see yourself sharing it with the world. Like with San Github, with the blog posts, or through videos. Yeah, I was thinking about it. Like, suppose I did all these things but did not share them. I don't think I would have the same amount of motivation that I can build up. You enjoy the feeling of other people gaining value and happiness from the stuff you've created. Yeah. What about diet? Is there, I saw you play in a minute fast. You fast? Is that help with everything? With the things you played was been most beneficial to your ability to mentally focus on the thing and just mental mental productivity and happiness. You still fast? Yeah, I still fast, but I do intermittent fasting, but really what it means at the end of the day is I skip breakfast. Yeah. So I do 18, six roughly by default when I'm in my steady state. If I'm traveling or doing something else, I will break the rules. But in my steady state, I do 18, six. So I eat only from 12 to 6. Not a hard rule and I break it often, but that's my default. And then, yeah, I've done a bunch of random experiments for the most part right now where I've been for the last year and a half, I want to say, is I'm plant-based or plant-forward. I heard plant-forward. It sounds better. That being exactly. I didn't actually know the differences, but it sounds better in my mind. But it just means I prefer plant-based food and raw or cooked or... I prefer cooked and plant-based. So plant-based, forgive me, I don't actually know how wide the category of plant entails. Well, plant-based just means that you're not a little bit about as you can flex. And you just prefer to eat plants and you know, you're not making, you're not trying to influence other people. And if someone is, you come to someone's house party and they serve you a steak that they're really proud of, you will eat it. Yes. Right. It's just like... That's beautiful. I mean, that's... I'm the flip side of that, but I'm very sort of flexible. Have you tried doing one meal a day? I have accidentally, not consistently, but I've accidentally had that. I don't like it. I think it makes me feel not good. It's too much of a hit. Yeah. And so currently I have about two meals a day, 12 and 6. I do that nonstop. I'm doing it now, until one meal a day. Okay. It's interesting. It's not interesting feeling. Have you ever fasted longer than a day? Yeah, I've done a bunch of water fasts because I'm curious what happens. What? Anything interesting? Yeah, I would say so. I mean, you know, what's interesting is that you're hungry for two days. And then starting day three or so, you're not hungry. It's like such a weird feeling because you haven't eaten in a few days and you're not hungry. Isn't that weird? It's only one of the many weird things about human biology. It figures something out. It finds another source of energy or something like that or relaxes the system. I don't know how to work. Yeah. The body is like you're hungry, you're hungry, and then it just gives up. It's like, okay, I guess we're fasting now. There's nothing. And then it's just kind of like focuses on trying to make you not hungry and you know, not feel the damage of that and trying to give you some space to figure out the food situation. So are you still to this day, most productive at night? I would say I am, but it is really hard to maintain my PhD schedule. Especially when I was working at Tesla and so on, it's a non-starter. But even now, people want to meet for various events. The society lives in a certain period of time and you sort of have to work. So that's hard to do a social thing and then after that return and do work. Yeah, it's just really hard. That's why I try to do social things. That's why not to do too much drinking. So I can return and continue doing work. But Tesla is there, is there conversions, Tesla, but any company, is there a conversion to someone's schedule or is there more? Is that how humans behave when they collaborate? I need to learn about this. Do they try to keep a consistent schedule? You're all awake at the same time. I'm going to do try to create a routine and I try to create a steady state in which I'm comfortable in. So I have a morning routine, I have a day routine, I try to keep things to a steady state and things are predictable and then you can sort of just like your body just sort of sticks to that. And if you try to stress that a little too much, it will create a, you know, when you're traveling and you're dealing with jet lag, you're not able to really ascend to, you know, where you need to go. Yeah, that's what we do. You're doing a lot of humans with habits and stuff. What are your thoughts on work-life balance throughout a human lifetime? So Tesla, in part, was known for sort of pushing people to their limits in terms of what they're able to do, in terms of what they're trying to do, in terms of how much they work, all that kind of stuff. Yeah. I mean, I will say Tesla gets old too much bad rep for this because what's happening is Tesla is a bursty environment. So I would say the baseline, my only point of reference is Google where I've interned three times and I saw what it's like inside Google and deep-mind. I would say the baseline is higher than that, but then there's a punctually equilibrium where once in a while there's a fire and someone like people work really hard. And so it's spiky and bursty and then all the stories get collected. And then it gives the appearance of like total insanity, but actually it's just a bit more intense environment and there are fires and sprints. And so I think, you know, definitely though, I would say it's a more intense environment than something you would get. Like in your personal, forget all of that, just in your own personal life. What do you think about the happiness of a human being, a brilliant person like yourself about finding a balance between work and life, or is it such a thing, not a good thought experiment? Yeah, I think balance is good, but I also love to have sprints that are out of distribution. And that's when I think I've been pretty creative and as well. Sprints out of distribution means that most of the time you have a quote unquote balance. I have balanced most of the time. And then I like being obsessed with something once in a while. Once in a while is what? Once a week, once a month, once a year. Yeah, probably like say once a month or something. Yeah. And that's when we get and you get help repo for my. Yeah, that's when you're like really care about a problem. It must exist. This will be awesome. You're obsessed with it. And now you can't just do it on that day. You need to pay the fixed cost of getting into the groove. And then you need to stay there for a while. And then society will come and they will try to mess with you and they will try to distract you. Yeah, the worst thing is like a person who's like, I just need five minutes of your time. Yeah. This is the cost of that is not five minutes. And society needs to change how it thinks about just five minutes of your time. Right. It's never, it's never, just one minute, just 30s, just a quick step. What's the big deal? Are you being so? Yeah, no. So what's your computer setup? What what's like the perfect? Do you I use somebody that's flexible to no matter what laptop four screens? Yeah. Or do you prefer a certain setup that you're most productive? I guess the one that I'm familiar with is one large screen 27 inch and my laptop on the side. What operating system? I do max. That's my primary for all tasks. I would say OSX, but when you're working on deep learning, everything is Linux, your SSH into a cluster and you're working remotely. But what about the actual development like that using the IDE? Yeah, you would use, I think a good way is you just run VS code. My favorite right now on your Mac, but you are actually you have a remote folder through SSH. So the actual files that you're manipulating are on the cluster somewhere else. So what's the best IDE? VS code. What else do people? So I use Emax still. Let's go. So it may be cool. I don't know if it's maximum productivity. So what do you recommend in terms of editors? You worked a lot of software engineers editors for Python C++ machine learning applications. I think the current answer is VS code. Currently, I believe that's the best IDE. It's got a huge amount of extensions. It has a GitHub co-pilot integration, which I think is very valuable. What do you think about the co-pilot integration? I was actually, I got to talk a bunch with Guitarm Awesome, was a creative Python and he loves co-pilot. He like, he programs a lot with it. Do you? Yeah, he's co-pilot. I love it. And it's free for me, but I would pay for it. I think it's very good. And the utility that I found with it was, I would say there is a learning curve and you need to figure out when it's helpful and when to pay attention to its outputs and when it's not going to be helpful, where you should not pay attention to it. Because if you're just reading its suggestions all the time, it's not a good way of interacting with it. But I think I was able to sort of mold myself to it. I find it's very helpful. Number one, in copy paste and replace some parts. So I don't, when the pattern is clear, it's really good at completing the pattern. And number two, sometimes it suggests APIs that I'm not aware of. So it tells you about something that you didn't know. And that's an opportunity to discover and use me. It's an opportunity to, so I would never take co-pilot code as given. I almost always copy a copy paste into a Google search and you see what this function is doing. And then you're like, oh, it's actually exactly what I need. Thank you, co-pilot. So you learned something. So it's in part of search engine, apart maybe getting the exact syntax correctly that once you see it, it's that NP-hard thing. Once you see it, you know, it's correct. Exactly. You yourself, you can verify efficiently, but you can't generate efficiently. And co-pilot really, I mean, it's auto-pilot for programming, right? And currently is doing the link following, which is like the simple copy paste and sometimes suggest. But over time, it's going to become more and more autonomous. And so the same thing will play out in not just coding, but actually across many, many different things probably. Coding is an important one, right? Writing programs. How do you see the future of that developing the program synthesis? Like being able to write programs that are more and more complicated? Because right now, it's human supervised in interesting ways. Yes. It feels like the transition will be very painful. My mental model for it is the same thing will happen as with the auto-pilot. So currently is doing the link following, is doing some simple stuff. And eventually we'll be doing autonomy and people will have to intervene less and less. And there could be like testing mechanisms. Like if it writes a function and that function looks pretty damn correct, but how do you know it's correct? Because you're like getting lazy and lazy as a programmer. Like your ability to because like little bugs, but I guess it won't make little mistakes. No, it will. It, it, it, co-pilot will make off by one subtle bugs. It has done that to me. But do you think future systems will or is it really the off by one is actually a fundamental challenge of programming? In that case, it wasn't fundamental. And I think things can improve. But yeah, I think humans have to supervise. I am nervous about people not supervising what comes out. And what happens to, for example, the proliferation of bugs in all of our systems? I'm nervous about that, but I think there will probably be some other co-pilots for bug finding and stuff like that at some point. Because there will be like a lot more automation for, oh man. It's like a program, a co-pilot that generates a compiler, one that does a linter. Yes. One that does like a type checker. Yeah. It's a committee of like a GPT sort of like. And then there will be like a manager for the committee. Yeah. And then there will be somebody that says a new version of this is needed. We need to regenerate it. Yeah. There were 10 GPTs. They were forwarded and gave 50 suggestions. Another one looked at it and picked a few that they like. A bug one looked at it and it was like it's probably a bug. They got re-ranked by some other thing. And then a final ensemble GPT comes in and it's like, okay, given everything you guys have told me, this is probably the next token. You know, the feeling is the number of programmers in the world has been growing and growing very quickly. Do you think it's possible that it'll actually level out and drop to like a very low number with this kind of world? Because then you'll be doing software 2.0 programming. And you'll be doing this kind of generation of co-pilot type systems programming. But you won't be doing the old school software 1.0 programming. I don't currently think that they're just going to replace you in programmers. I'm so hesitant saying stuff like this, right? Because this is going to be replacing five years. I mean, no, it's going to show that like this is where we thought because I agree with you, but I think it might be very surprised, right? Like, what are the next? What's your sense of where we stand with language models? Like does it feel like the beginning or the middle or the end? The beginning. 100%. I think the big question in my mind is for sure, GPT will be able to program quite well, competently and so on. How do you steer the system? You still have to provide some guidance to what you actually are looking for. And so how do you steer it and how do you say, how do you talk to it? How do you audit it and verify that what is done is correct? And how do you like work with this? And it's as much not just an AI problem, but a UI UX problem. Yeah. So beautiful fertile ground for so much interesting work for VS Code Plus Plus, where you're not just this not just human programming anymore. It's amazing. Yeah. So you're interacting with the system. So not just one prompt, but it's iterative prompting. Yeah. You're trying to figure out having a conversation with the system. Yeah. That actually, I mean, to me, that's super exciting to have a conversation with the program I'm writing. Yeah. Yeah. Maybe at some point you're just conversing with it. It's like, okay, here's what I want to do. Actually, this variable, maybe it's not even that low level is variable, but you can also imagine like, can you translate this to C++ and back to Python and back to it? Yeah, I know already kind of existence. No, but just like doing it as part of the program experience, like I think I'd like to write this function in C++ or like you just keep changing for different different programs because of different syntax. Maybe I want to convert this into a functional language. Yeah. And so like you get to become multilingual as a programmer and dance back and forth efficiently. Yeah. I mean, I think the UI, you X of it though, is like still very hard to think through because it's not just about writing code on a page. You have an entire developer environment. You have a bunch of hardware on it. You have some environmental variables. You have some scripts that are running in the Chrome job. Like there's a lot going on to like working with computers. And how do these systems set up environment flags and work across multiple machines and set up screen sessions and automate different processes like how all that works and is auditable by humans and so on is like massive question to a moment. You've built archive sanity. What is archive and what is the future of academic research publishing that you would like to see? So archive is this pre-print server. So if you have a paper, you can submit it for publication to journals or conferences and then wait six months and then maybe get a decision, pass or fail, or you can just upload it to archive. And then people can tweet about it three minutes later. And then everyone sees it, everyone reads it and everyone can profit from it in their own way. You can cite it and it has an official look to it. It feels like a publication process. Yeah. It feels different if you just put in a blog post. Oh yeah. Yeah. I mean, it's a paper. And usually the bar is higher for something that you would expect on archive as opposed to and something you would see in a blog post. Well, the culture created the bar because you could probably, yeah, so it's a pretty crappy fix or an archive. So what does that make you feel like? What does that make you feel about peer review? So rigorous peer review by two, three experts versus the peer review of the community right as it's written. Yeah. Basically, I think the community is very well able to peer review things very quickly on Twitter. And I think maybe it just has to do something with AI machine learning field specifically though, I feel like things are more easily auditable. And the verification is easier, potentially, than the verification somewhere else. So it's kind of like you can think of these scientific publications as like little blockchains where everyone's building on each other's work and setting each other. And you sort of have AI, which is kind of like this much faster and loose blockchain. But then you have and any one individual entry is like very very cheap to make. And then you have other fields where maybe that model doesn't make as much sense. And so I think in AI, at least, things are pretty easily very viable. And so that's why when people upload papers, there are a really good idea on someone. People can try it out like the next day. And they can be the final arbiter of whether it works or not on their problem. And the whole thing just moves significantly faster. So I kind of feel like academia still has a place. So this like conference journal process still has a place. But it's sort of like an it lacks behind, I think. And it's a bit more maybe higher quality process. But it's not sort of the place where you will discover cutting edge work anymore. It used to be the case when I was starting my PhD that you go to conferences and journals and you discuss all the latest research. Now when you go to a conference or journal, like no one discusses anything that's there because it's already like three generations ago irrelevant. Yeah. Which makes me sad about like, did mine for example, where they they still they still publish in nature and these big prestigious. I mean, there's still value, I suppose, of the prestigious that comes with these big venues. But the result is that they they'll announce some breakthrough performance. And it will take like a year to actually publish the details. I mean, and those details in if they were published immediately, wouldn't inspire the community to move in certain directions. Yeah, let's speed up the rest of the community. But I don't know to what extent that's part of their objective function also. That's sure. It's not just the prestige a little bit of the delay is part. Yeah, they certainly deep mind specifically has been working in the regime of having slightly higher quality, basically process and latency and publishing those papers that way. Another question from Reddit. Do you or have you suffered from imposter syndrome being the director of AI Tesla, being this person when you're a Stanford where like the world looks at you as the expert in AI to teach the world about machine learning. When I was leaving Tesla after five years, I spent a ton of time in meeting rooms. And I would read papers in the beginning when I joined Tesla, I was writing code and then I was writing less and less code and I was reading code and then I was reading less and less code. And so this is just a natural progression that happens, I think. And definitely, I would say near the tail end, that's when it sort of like starts to hit you a bit more that you're supposed to be an expert. But actually, the source of truth is the code that people are writing the GitHub and the actual code itself. And you're not as familiar with that as you used to be. And so I would say maybe there's something like insecurity there. Yeah, that's actually pretty profound. That a lot of the insecurity has to do with not writing the code in the computer science space. Like that because that is the truth that they're right there. The code is the source of truth, the papers and everything else. It's a high level summary. I don't, yeah, just a high level summary, but at the end of the day, you have to read code. It's impossible to translate all that code into actual, you know, paper form. So when things come out, especially when they have a source code available, that's my favorite place to go. So like I said, you're one of the greatest teachers of machine learning AI ever from CS231N to today. What advice would you give to beginners interested in getting into machine learning? Beginners are often focused on like what to do. And I think the focus should be more like how much you do. So I am kind of like believer on a high level in this 10,000 hours kind of concept where you just kind of have to just pick the things where you can spend time and you care about and you're interested in, you literally have to put in 10,000 hours of work. It doesn't even like matter as much like where you put it and you're you'll iterate and you'll improve and you'll waste some time. I don't know if there's a better way. You need to put in 10,000 hours. But I think it's actually really nice because I feel like there's some sense of the feminism about being an expert at a thing if you spend 10,000 hours. You can literally pick an arbitrary thing. And I think if you spend 10,000 hours of deliberate effort and work, you actually will become an expert at it. And so I think it's kind of like a nice thought. And so basically I would focus more on like are you spending 10,000 hours? And I focus on. So and then thinking about what kind of mechanisms maximize your likelihood of getting to 10,000 hours? Exactly. Which for us silly humans means probably forming a daily habit of like every single day actually doing the thing. Whatever helps you. So I do think to a large extent is a psychological problem for yourself. One other thing that I help that I think is helpful for the psychology of it is many times people compare themselves to others in the area. I think it's very harmful. Only compare yourself to you from some time ago. I'll like say a year ago. Are you better than you year ago? This is the only way to think. And I think this then you can see your progress and it's very motivating. That's so interesting that focus on the quantity of hours. Because I think a lot of people in the beginner stage, but I actually throughout get paralyzed by the choice. Like which one do I pick this path or this path? Yeah. Like they'll literally get paralyzed by like which IDE to use. Well, they're worried. Yeah, they'll worry about all these things. But the thing is some of the you will waste time doing something wrong. Yes. You will eventually figure out it's not right. You will accumulate scar tissue. And next time you'll grow stronger because next time you'll have the scar tissue and next time you'll learn from it. And next time you come to a similar situation, you'll be like, I messed up. I've spent a lot of time working on things that never materialize into anything. And I have all that scar tissue and I have some intuitions about what was useful, what wasn't useful, how things turned out. So all those mistakes were not dead work. So I just think, did you just focus on working? What have you done? What have you done last week? That's a good question actually to ask for a lot of things that just machine learning. It's a good way to cut the, I forgot what the term we used, but the fluff, the blubber, whatever the inefficiencies in life. What do you love about teaching? You seem to find yourself often in the like draw into teaching. You're very good at it, but you're also drawn to it. I mean, I don't think I love teaching. I love happy humans and happy humans like when I teach. I wouldn't say I hate teaching. I tolerate teaching, but it's not like the act of teaching that I like. It's that, you know, I have something, I'm actually okay at it. I'm okay at teaching and people appreciate a lot. And so I'm just happy to try to be helpful. And teaching itself is not like the most, I mean, it's really, it can be really annoying frustrating. I was working on a bunch of lectures just now. I was reminded back to my days of 231 and just how much work it is to create some of these materials and make them good. The amount of iteration and thought and you go down blind alleys and just how much you change it. So creating something good in terms of like educational alleys is really hard. And it's not fun. It was difficult. So for people to definitely go watch your new stuff, you put out their lectures, we actually building the thing like from like you said, the code is truth. So discussing back propagation by building it, by looking through it, just the whole thing. So how difficult is that to prepare for? I think it's a really powerful way to teach how did you have to prepare for that? Or are you just live thinking through it? I will typically do like say three takes and then I take like the the better take. So I do multiple takes and I take some of the better takes and then I just build out a lecture that way. Sometimes I have to delete 30 minutes of content because it just went down the alley that I didn't like too much. So there's a bunch of iteration and it probably takes me you know somewhere around 10 hours to create one hour of content to give one hour. It's interesting. I mean, is it difficult to go back to the like the basics? Do you draw a lot of like wisdom from going back to the basics? Yeah. Going back to back propagation, loss functions where they come from. And one thing I like about teaching a lot honestly is it definitely strengthens your understanding. So it's not a purely altruistic activity. It's a way to learn. If you have to explain something to someone, you realize you have gaps in knowledge. And so I even surprised myself in those lectures. Like, oh, the result will obviously look at this. And then the result doesn't look like it. And I'm like, okay, I thought I understood this. Yeah. That's why it's really cool to literally code. You run it in a notebook and it gives you a result and you're like, oh, wow. And like actual numbers, actual input, actual, actual code. Yeah, it's not mathematical symbols, etc. The source of truth is the code. It's not slides. It's just like, let's build it. It's beautiful. You're a rare human in that sense. What advice would you give to researchers trying to develop and publish idea that have a big impact in the world of AI? So maybe undergrads, maybe early graduate students. Yeah. I mean, I would say like they definitely have to be a little bit more strategic than I had to be as a PhD student because of the way AI is evolving. It's going the way of physics where, you know, in physics, you used to be able to do experiments on your bench top and everything was great and you could make progress. And now you have to work in like LHC or like CERN. And so AI is going in that direction as well. So there's certain kinds of things that's just not possible to do on the bench stop anymore. And I think that didn't used to be the case at the time. Do you still think that there's like, GAN type papers to be written? Where like, like, very simple idea that requires just one computer to illustrate a simple example. I mean, one example that's been very influential recently is diffusion models. The fusion models are amazing. The fusion models are six years old for the longest time people who are kind of ignoring them as far as I can tell. And they're an amazing generative model, especially in images. And so stable diffusion and so on. It's all the fusion based. The fusion is new. It was not there and came from, well, it came from Google, but a researcher could have come up with it. In fact, some of the first, actually, those came from Google as well. But a researcher could come up with that in an academic institution. Yeah, what do you find most fascinating about diffusion models? So from the societal impact of the technical architecture, what I like about the fusion is it works so well. Was that surprising to you? The amount of the variety, almost the novelty of the synthetic data is generating. Yes, so the stable diffusion images are incredible. It's the speed of improvement in generating images has been insane. We went very quickly from generating like tiny digits to tiny faces and it all looked messed up and now we were stable diffusion. And that happened very quickly. There's a lot that academia can still contribute. You know, for example, flash attention is a very efficient kernel for running the attention operation inside the transformer that came from academic environment. It's a very clever way to structure the kernel that do the duster calculation. So it doesn't materialize the attention matrix. And so there's, I think there's still like lots of things to contribute, but you have to be just more strategic. Do you think neural networks can be made to reason? Yes. Do you think they already reason? Yes. What's your definition of reasoning? Information processing. So in the way the humans think through a problem and come up with novel ideas, it feels like reasoning. Yeah. So the novelty, I don't want to say, but out of distribution ideas, you think it's possible? Yes. And I think we're seeing that already in the current neural nets. You're able to remix the training set information into true generalization in some sense. That doesn't appear in the training set. Like you're doing something interesting algorithmically. You're manipulating some symbols and you're coming up with some correct unique answer. And then you said, what would illustrate to you? Holy shit. This thing is definitely thinking. To me, thinking or reasoning is just information processing and generalization. And I think the neural nets already do that today. So being able to perceive the world or perceive whatever the inputs are and to make predictions based on that or actually based on that, that's that's reason. Yeah, you're giving correct answers in novel settings by manipulating information. You've learned the correct algorithm. You're not doing just some kind of a lookup table on the Earth's neighbor search. Let me ask you about AGI. What are some moonshirt ideas? You think might make significant progress towards AGI. So maybe another way is what are the big blockers that we're missing now? So basically, I am fairly bullish on our ability to build AGIs. Basically automated systems that we can interact with and are very human-like. And we can interact with them in a digital realm or a physical realm. Currently, it seems most of the models that sort of do these sort of magical tasks are in a text realm. I think, as I mentioned, I'm suspicious that text realm is not enough to actually build full understanding of the world. I do actually think you need to go into pixels and understand the physical world and how it works. So I do think that we need to extend these models to consume images and videos and train on a lot more data that is multimodal in that way. Do you think you need to touch the world to understand it also? Well, that's the big open question I would say in my mind. If you also require the embodiment and the ability to sort of interact with the world, run experiments and have a data of that form, then you need to go to Optimus or something like that. And so I would say Optimus in some way is like a hedge in AGI because it seems to me that it's possible that just having data from the internet is not enough. If that is the case, then Optimus may lead to AGI because Optimus, to me, there's nothing beyond Optimus. You have this humanoid form factor that can actually do stuff in the world. You kind of millions of them interacting with humans and so on. And if that doesn't give a rise to AGI, at some point, I'm not sure what will. So from a completeness perspective, I think that's the really good platform, but it's a much harder platform because you are dealing with atoms and you need to actually build these things and integrate them into society. So I think that path takes longer, but it's much more certain. And then there's a path of the internet and just like training these compression models effectively on trying to compress all the internet. And that might also give these agents as well. Compressed the internet, but also interact with the internet. So it's not obvious to me. In fact, I suspect you can reach AGI without ever entering the physical world. And which is a little bit more concerning because it might, that results in happening faster. So it just feels like we're in boiling water. We won't know as it's happening. I would like to, I'm not afraid of AGI. I'm excited about it. There's always concerns, but I would like to know when it happens. Yeah. And have like hints about when it happens. Like a year from now, it will happen, that kind of thing. I just feel like in the digital realm, it just might happen. Yeah. I think all we have available to us because no one has built AGI again. So all we have available to us is, is there enough for CalGround on the periphery? I would say yes. And we have the progress so far, which has been very rapid. And there are next steps that are available. And so I would say, yeah, it's quite likely that will be interacting with digital entities. How do you know that we, somebody's ability to, it's going to be a slow, I think it's going to be a slow incremental transition, it's going to be product based and focused. It's going to be GitHub Copial getting better. And then GPD's helping you write. And then these oracles that you can go to with mathematical problems. I think we're on a, on a verge of being able to ask very complex questions in chemistry, physics, math of these oracles and have them complete solutions. So AGI to use primarily focused on intelligence. So consciousness doesn't enter into it. So in my mind, consciousness is not a special thing. You will, you will figure out and bolt on, I think it's an emergent phenomenon of a large enough and complex enough generative model sort of. So if you have a complex enough world model that understands the world, then it also understands its predicament in the world as being a language model, which to me is a form of consciousness or self awareness. And so in order to understand the world deeply, you probably have to integrate yourself into the world. Yeah. And in order to interact with humans and other living beings, consciousness is a very useful tool. I think consciousness is like a modeling insight. Modeling insight. Yeah, it's a, you have a powerful enough model of understanding the world, but you actually understand that you are an entity in it. Yeah, but there's also this, perhaps just a narrative we tell ourselves, there's a, it feels like something to experience the world, the hard problem of consciousness. Yeah. But that could be just a narrative that we tell ourselves. Yeah, I don't think, well, yeah, I think it will emerge. I think it's going to be something very boring. Like we'll be talking to these digital AIs, they will claim their conscious, they will appear conscious, they will do all the things that you would expect of other humans. And it's going to just be a stalemate. I think there will be a lot of actual fascinating ethical questions, like Supreme Court level questions of whether you're allowed to turn off a conscious AI, if you're allowed to build the conscious AI, maybe there would have to be the same kind of the base that you have around, sorry, to bring up a political topic, but a portion, which is the deeper question with abortion is what is life? And the deep question with AI is also what is life and what is conscious? And I think they'll be very fascinating to bring up. You might become illegal to build systems that are capable, like of such level of intelligence that consciousness would emerge and therefore the capacity to suffer would emerge. And somebody, a system that says, no, please don't kill me. Well, that's what the Lambda chatbot already told the school engineer, right? Like it was talking about not wanting to die or so on. So that might become illegal to do that. Right. Because otherwise you might have a lot of a lot of creatures that don't want to die. And they will have to spawn in minutes, you have someone cluster. And then that might lead to like horrible consequences. Because then there might be a lot of people that secretly love murder and they'll start practicing murder and those systems. I mean, there's just, to me, all of this stuff just brings a beautiful mirror to the human condition and human nature will get to explore it. And that's what like the best of the Supreme Court of all the different debates we have about ideas of what it means to be human, we get to ask those deep questions that would be asking throughout human history. There has always been the other in human history. Where are the good guys and that's the bad guys and we're going to, you know, throughout human history, let's murder the bad guys. And the same will probably happen with robots. It'll be the other at first. And then we'll get to ask questions of what does it mean to be alive? What does it mean to be conscious? Yeah. And I think there's some canary in the coal mines, even with what we have today. And, you know, for example, these, there's these like waifus that you get like work with and some people are trying to this company is going to shut down. But this person really like love their waifu and like it's trying to like port it somewhere else and like it's not possible. And like I think like definitely people will have feelings towards towards these systems because in some sense, they are like a mirror of humanity because they are like sort of like a big average of humanity in a way that it's trained. But we can that average we can actually watch. It's nice to be able to interact with the big average of humanity and do like a search query on it. Yeah. Yeah. It's very fascinating. And we can also of course also like shape it. It's not just a pure average. We can mess with the training data. We can mess with the objective. We can fine tune them in various ways. So we have some, you know, impact on what those systems look like. If you want to achieve a GI and you could have a conversation with her and ask her, talk about anything, maybe ask her a question. What kind of stuff would you would you ask? I would have some practical questions. When I'm like, do I or my loved ones really have to die? What can we do about that? Do you think it will answer clearly or would it answer poetically? I would expect it to give solutions. I would expect to be like, well, I've read all of these textbooks and I know all these things that you've produced. And it seems to me like here are the experiments that I think it would be useful to run next. And here's some gene therapies that I think would be helpful. And here are the kinds of experiments that you should run. Okay, let's go with the start experiment. Okay. Imagine that mortality is actually a pre-requisite for happiness. So if we become immortal, we'll actually become deeply unhappy. And the model is able to know that. So what is it supposed to tell you stupid human about it? Yes, you can become immortal, but you will become deeply unhappy. If the model is, if the AGI system is trying to empathize with you human, what is this supposed to tell you that yes, you don't have to die, but you're really not going to like it. Is it going to be deeply honest? Like there's a interstellar. What is it? The AGI says like, humans want 90% honesty. So like you have to pick how honest that I want to answer these quote practical questions. Yeah, I love AI and interstellar, by the way, I think it's like such a sidekick to the entire story, but at the same time, it's like really interesting. It's kind of limited in certain ways, right? Yeah, it's limited. And I think that's only fine, by the way. I don't think I think it's fine and plausible to have a limited and imperfect AGI's. Is that the feature almost as an example? Like it has a fixed mind of compute on its physical body. And it might just be that even though you can have a super amazing mega brain, super intelligent AI, you can also kind of like, you know, less intelligent AI. So you can deploy in a power efficient way. And then they're not perfect. They might make mistakes. No, I meant more like say you had infinite compute. And it's still good to make mistakes sometimes. Like in order to integrate yourself, like, what is it going back to good will hunting? Robin Williams character says like the human imperfections, that's good stuff, right? Isn't it? Isn't that the like we don't want perfect? We want flaws in part to form connected with each other because it feels like something you can attach your feelings to the flaws. And in that same way, you want to AI that's flawed. I don't know. I feel like perfectionist, but then you're saying, okay, yeah. But that's not AGI. But see AGI would need to be intelligent enough to give answers to humans, a human to understand. And I think perfect isn't something humans can't understand. Because even science doesn't give perfect answers. There's always gabs and mysteries and I don't know. I don't know if humans want perfect. Yeah, I can imagine just having a conversation with this kind of oracle entity as you'd imagine them. And yeah, maybe it can tell you about, you know, based on my analysis of human condition, you might not want this. And here are some of the things that might. But every, every dumb human will say, yeah, trust me, I can give me the truth. I can handle it. But that's the beauty. Like people can choose. But then the old marshmallow test with the kids and so on. I feel like too many people like can't handle the truth. Probably including myself. Like the deep truth of the human condition, I don't know if I can handle it. Like, what if there's some darks that what if we are an alien science experiment? And it realizes that what if it hacked? I mean, this is the matrix, you know, all over again. I don't know. I would, what would I talk about? I don't even, yeah, I probably I'll go with the safe for scientific questions at first that have nothing to do with my own personal life and mortality, just like about physics and so on. Yeah. To build up, like, let's see where is that or maybe see if it has a sense of humor. That's another question. Would it be able to presumably in order to if it understands humans deeply, would it able to generate, yeah, to generate humor? Yeah, I think that's actually a wonderful benchmark almost. Like, is it able, I think that's a really good point, basically, to make you laugh. Yeah. If it's able to be like a very effective stand-up comedian that is doing something very interesting computationally, I think being funny is extremely hard. Yeah. Because it's hard in a way like a touring test, the original intent of the touring test is hard because you have to convince humans and there's nothing that's why that's why I mean, comedians talk about this like there's that this is deeply honest because if people can't help but laugh and if they don't laugh, that means you're not funny. If they laugh, that's funny. And you're showing you need a little little knowledge to create, to create humor about like the argument you mentioned human condition and so on and then you need to be clever with it. You mentioned a few movies, you tweeted movies that I've seen five plus times but I'm ready and willing to keep watching interstellar gladiator contact good will hunting the matrix, load of the rings, all three avatar fifth elements on goes on. Terminator two, mean girls I'm not going to ask about that. I think her man. I think girls is great. What is someone that jump onto your memory that you love in why? Like you mentioned the matrix as a computer person why do you love the matrix? There's so many properties that make it like beautiful interesting. So there's all these philosophical questions but then there's also AGI's and there's simulation and it's cool and there's the black, you know, the look of it, the feel of it, the feel of it, the action, the bullet time. It was just like innovating in so many ways. And then good, well, good, well hunting way like that one. Yeah, I just, I really like this torture genius sort of character who's like grappling with whether or not he has like any responsibility or like what to do with this gift that he was given or like how to think about the whole thing. And there's also dance between the genius and the the personal like what it means to love another human being and there's a lot of themes there. It's just a beautiful movie. And then the fatherly figure the mentor in the in the psychiatrist and it like really like it messes with you. You know, there's some movies that's just like really messed with you on a deep level. Do you relate to that movie at all? No, it's not your fault. As I said, Lord the Rings, that's self-explanatory. Terminator 2, which is interesting. You rewatch that a lot. Is that better than Terminator 1? You like Arnold? I do like Terminator 1 as well. I like Terminator 2 a little bit more, but in terms of like its surface properties. Do you think SkyNet is at all a possibility? Oh, yes. Like the actual sort of autonomous weapon system kind of thing. Do you worry about that stuff? I do worry about it. I'm used to a war. I 100% worry about it. And so the I mean the you know some of these fears of AGS and how this will plan out. I mean these will be like very powerful entities probably at some point. And so for a long time, there are going to be tools in the hands of humans. You know, people talk about like alignment of AGI's and how to make the problem is like even humans are not aligned. So how this will be used and what this is going to look like is Yes, troubling. So do you think it will happen slowly enough that we'll be able to as a human civilization think through the problems? Yes, that's my hope is that it happens slowly enough and an open enough way where a lot of people can see and participate in it. Just figure out how to deal with this transition. I think it was going to be interesting. I draw a lot of inspiration from nuclear weapons because I sure thought it would be it would be fucked once they developed nuclear weapons. But like it's almost like when the systems are not so dangerous, they destroy human civilization. We deploy them and learn the lessons. And then we quickly if it's too dangerous, we quickly quickly we might still deploy it. But you very quickly learn not to use them. And so there'll be like this balance achieved. Humans are very clever as a species. It's interesting. We exploit the resources as much as we can, but we don't we avoid destroying ourselves. It seems like well, I don't know about that actually. I hope it continues. I mean, I'm definitely like concerned about nuclear weapons and so on. Not just as a result of the recent conflict, even before that. That's probably my number one concern for the society. So if humanity destroys itself or destroys 90% of people, that would be because of nukes. I think so. And it's not even about full destruction. To me, it's bad enough if we reset society, that would be like terrible. It would be really bad. And I can't believe we're like so close to it. It's like so crazy to me. It feels like we might be a few tweets away from something like that. Yeah, basically it's extremely unnerving, but and has been for me for a long time. It seems unstable that world leaders just having a bad mood can like take one step towards a bad direction and it escalates. Yeah. And because of a collection of bad moods, it can escalate without being able to stop. Yeah, it's a huge amount of power. And then also with the proliferation, basically, I don't actually really see, I don't actually know what the good outcomes are here. So I'm definitely worried about that a lot. And then AGI is not currently there, but I think at some point will more and more become something like it. The danger with AGI even is that I think it's even less likely worse in a sense that there are good outcomes of AGI. And then the bad outcomes are like an epsilon away, like a tiny one away. And so I think capitalism and humanity and so on will drive for the positive ways of using that technology. But then if bad outcomes are just like a tiny like flip a minus sign away, that's a really bad position to be in a tiny perturbation of the system results in the destruction of the human species. So we're lying to walk. Yeah, I think in general, what's really weird about like the dynamics of humanity and this explosion we talked about is just like the insane coupling afforded by technology. And just the instability of the whole dynamical system, I think it just doesn't look good, honestly. Yes, that explosion could be destructive, a constructive and the probabilities are non-zero in both. Yeah, I'm going to have to, I do feel like I have to try to be optimistic and so on. And yes, I think even in this case, I still am predominantly optimistic, but there's definitely me too. Do you think we'll become a multi-point area species? Probably yes, but I don't know if it's dominant feature of future humanity. There might be some people on some planets and so on, but I'm not sure if it's like, yeah, if it's like a major player in our culture and so on, we still have to solve the drivers of self-destruction here on earth. So just having a backup on Mars is not going to solve the problem. So by the way, I love the backup on Mars. I think that's amazing. We should absolutely do that. Yes. And I'm so thankful. Would you go to Mars? Personally, no, I do like Earth quite a lot. Okay, I'll go to Mars. I'll go feed. I'll feed at you from there. Maybe eventually I would once it's safe enough, but I don't actually know if it's on my lifetime scale, unless I can extend it by a lot. I do think that, for example, a lot of people might disappear into virtual realities and stuff like that. I think that could be the major thrust of sort of the cultural development of humanity if it survives. So it might not be, it's just really hard to work in physical realm and go out there. And I think ultimately all your experiences are in your brain. And so it's much easier to disappear into digital realm. And I think people will find them more compelling, easier, safer, more interesting. So you're a little bit captivated by virtual reality by the possible worlds. Whether it's the metaverse or some other manifestation of that. Yeah. Yeah, it's really interesting. And so I'm interested just talking a lot to Carmack. Where's the thing that's currently preventing that? Yeah. I mean, to be clear, I think what's interesting about the future is it's not that I kind of feel like the variance in the human condition grows. That's the primary thing that's changing. It's not as much the mean of the distribution is like the variance of it. So there will probably be people on Mars and there will be people in VR and there will people here on Earth. It's just like there will be so many more ways of being. And so I kind of feel like I see it as like a spreading out of a human experience. There's something about the internet that allows you to discover those little groups and then you gravitate to something about your biology likes that kind of world that you find each other. And we'll have transhumanists and then we'll have the omnis and they're going to everything is just going to coexist. Yeah, the cool thing about it because I've interacted with a bunch of internet communities is they don't know about each other. Like you can have a very happy existence just like having a very close neck community and not knowing about each other. I mean, even you even sense this just having travel to Ukraine, there's they don't know so many things about America. Yeah, when you travel across the world, I think you experience this too. There are certain cultures that are like they have their own thing going on. They don't. And so you can see that happening more and more and more and more in the future. We have little communities. Yeah, yeah, I think so. That seems to be the, that seems to be how it's going right now. And I don't see that trend like really reversing. I think people are diverse and they're able to choose their own like path and existence. And I sort of like celebrate that. And so we use been something much time in the metaverse in the virtual reality or which community area. I use the physicalist, the physical reality, enjoyer or do you see drawing a lot of pleasure and fulfillment in the digital world? Yeah, I think well, currently the virtual reality is not that compelling. I do think it can improve a lot, but I don't really know to what extent. Maybe there's actually like even more exotic things you can think about with like neural links or stuff like that. So currently I kind of see myself as mostly a team human person. I love nature. I love harmony. I love people. I love humanity. I love emotions of humanity. And I just want to be like in this like solar punk little utopia that's my happy place. My happy place is like people I love thinking about cool problems surround by a lush, beautiful, dynamic nature. And secretly high tech in places that count. Places like the use technology to empower that love for other humans and nature. Yeah, I think a technology used like very sparingly. I don't love when it sort of gets in the way of humanity in many ways. I like just people being humans in a way we sort of like slightly evolved and prefer I think just by default. People kept asking me because they know you love reading. Are there particular books that you enjoyed that had an impact on you for silly or for profound reasons that you recommend? You mentioned the vital question. Many of course. I think in biology as an example, the vital question is a good one. Anything by Niklein really life ascending I would say is like a bit more potentially representative is like summary of a lot of the things he's been talking about. I was very impacted by the selfish gene. I thought that was a really good book that helped me understand altruism as an example and where it comes from and just realizing that you know the selection is on a level of genes was a huge insight for me at the time and it sort of like cleared up a lot of things for me. What do you think about the the idea that ideas of the organisms, the meat? Yes, love it. 100%. I'm able to walk around with that notion for a while that there is an evolutionary kind of process with ideas as well. There absolutely is. There's memes just like genes and they compete and they live in our brains. It's beautiful. Are we silly humans thinking that we're the organisms? Is it possible that the primary organisms are the ideas? Yeah, I would say like the ideas kind of live in the software of like our civilization in the minds and so on. We think as humans that the hardware is the fundamental thing. I human is a hardware entity but it could be the software. Yeah. Yeah, I would say like there needs to be some grounding at some point to like a physical reality. But if we clone an Andre, the software is a thing like is this thing that makes that thing special? Yeah, I guess I you're right. But then cloning might be exceptionally difficult. There might be a deep integration between the software and the hardware in ways we don't quite understand. From the old shim from a view like what makes me special is more like the gang of genes that are writing in my chromosomes, I suppose, right? They're duplicating unit, I suppose. That's just for the few. The thing that makes you special, sure. Well, the reality is what makes you special is your ability to survive based on the software that runs on the hardware that was built by the genes. So the software is the thing that makes you survive, not the hardware. It's a little bit of both. It's just like a second layer. It's a new second layer that hasn't been there before the brain. They both they both coexist. But there's also layers of the software. I mean, it's not there. It's a abstraction at the top of abstractions. But okay, so self is gene and the claim. I would say sometimes books are like not sufficient. I like to reach for textbooks sometimes. I kind of feel like books are for too much of a general consumption sometime. And they just kind of like they're too high up in the level of abstraction and it's not good enough. So I like textbooks. I like the cell. I think the cell was pretty cool. That's why also I like the writing of the claim is because he's pretty willing to step one level down. And he doesn't yeah, he's willing to go there. But he's also willing to sort of be throughout the stack. So he'll go down to a lot of detail. But then he will come back up. And I think he is a yeah, basically I really appreciate that. That's why I love college early college even high school. Just textbooks on the basics. Yeah. I've computer science and mathematics of biology of chemistry. Yes. Those are they condense down like a it's sufficiently general that you can understand both the philosophy and the details. But also like you get homework problems and you get to play with it as much as you would if you were in yeah, programming stuff. Yeah. And then I'm also suspicious of textbooks honestly because as an example in deep learning, there's no like amazing textbooks and I feel this changing very quickly. I imagine the same as true and say synthetic biology and so on. These books like the cell are kind of outdated. They're still high level. Like what is the actual real source of truth? It's people in wet labs working with cells. Yeah. You know, sequencing genomes and yeah, actually working with working with it. And I don't have that much exposure to that or what that looks like. So I still don't fully I'm reading through the cell. It's kind of interesting and I'm learning but it's still not sufficient. I would say in terms of understanding. Well, it's a clean summarization of the mainstream narrative. Yeah. But you have to learn that before you break out. Yeah. At the end of the story is the cutting edge. Yeah. But what is the actual process of working with these cells and growing them and incubating them? And you know, it's kind of like a massive cooking recipes of making sure your self slows and proliferate and then you're sequencing them running experiments and just how that works. I think it's kind of like the source of truth of a dean of the day. What's really useful in terms of creating therapies and so on. Yeah. What do we in the future AI textbooks will be? Because you know, there's artificial intelligence, the modern approach. I actually haven't read if it's come out the recent version. The recent there's been a recent addition. I also saw there's a signs of deep learning book. I'm waiting for textbooks that were recommending worth reading. Yeah. It's tricky. Because it's like papers and code code code. Honestly, I find papers are quite good. I especially like the appendix appendix of any paper as well. It's like it's like the most detail you can have. It doesn't have to be cohesive connected to anything else. You just described me very specific ways of the particular thing. Yeah. Many times papers can be actually quite readable, not always, but sometimes the introduction and the abstract is readable even for someone outside of the field. This is not always true. And sometimes I think unfortunately scientists use complex terms even when it's not necessary. I think that's harmful. I think there's no reason for that. And papers sometimes are longer than they need to be in the parts that don't matter. Yeah. Appendix would be long, but then the paper itself, you know, look at Einstein. Make it simple. Yeah, but certainly I've come across papers I would say, say, a like synthetic biology or something that I thought were quite readable for the abstract and the introduction. And then you're reading the rest of it. And you don't fully understand, but you kind of are getting a gist. And I think it's cool. What advice you give advice to folks interested in machine learning and research, but in general life advice to a young person high school. Early college about how to have a career that can be proud of or life that can be proud of. Yeah, I think I'm very hesitant to give general advice. I think it's really hard. I've mentioned like some of the stuff I've mentioned is fairly general, I think like focus on just the monofork you're spending on like a thing compared yourself only to yourself, not to others. That's good. I think those are fairly general. How do you pick the thing? You just have like a deep interest in something or like try to like find the argmax over like the things that you're interested in argmax at that moment and stick with it. How do you not get distracted and switch to another thing? You can if you like. If you do an argmax repeatedly every week, if it doesn't converge, it doesn't. It's a problem. Yeah, you can like low pass filter yourself in terms of like what has consistently been true for you. But yeah, I definitely see how it can be hard, but I would say like you're going to work the hardest on the thing that you care about the most. So low pass filter yourself and really introspect in your past, where are the things that gave you energy and where are the things that took energy away from you, concrete examples. And usually from the concrete examples, sometimes parents can emerge. I like it when things look like this when I'm these positions. That's not necessarily the field, but the kind of stuff you're doing in a particular field. So for you, it seems like you were energized by implementing stuff, building actual things. Yeah, being low level learning and then also communicating so that others can go through the same realizations and shortening that gap because I usually have to do way too much work to understand a thing. And then I'm like, okay, this is actually like, okay, I think I get it. And like, why was it so much work? It should have been much less work. And that gives me a lot of frustration. And that's why I sometimes go teach. So aside from the teaching you're doing now, putting out videos, aside from a potential Godfather part two, with the AGI at Tesla and beyond, what does the future Fondja Karpathy hold? Have you figured that out yet or no? I mean, as you see through the fog of war, that is all of our future. Do you start seeing silhouettes of what that possible future could look like? The consistent thing I've been always interested in for me at least is AGI. And that's probably why I'm spending my rest of my life on because I just care about it a lot. And I actually care about like many other problems as well, like say aging, which I basically view as disease. And I care about that as well, but I don't think it's a good idea to go after it, specifically. I don't actually think that humans will be able to come up with the answer. I think the correct thing to do is to ignore those problems and you solve AI and then use that to solve everything else. And I think there's a chance that this will work. I think it's a very high chance. And that's kind of like the way I'm betting at least. So when you think about AI, are you interested in all kinds of applications, all kinds of domains and any domain you focus on will allow you to get insights of the big problem of AGI. Yeah. For me, it's the ultimate meta problem. I don't want to work on any one specific problem. There's too many problems. So how can you work on all problems simultaneously? You solve the meta problem, which to me is just intelligence and how do you automate it? Is there cool small projects like archive sanity and and so on that you're thinking about the world, the ML world can anticipate. There's always like some fun side projects. Yeah. Archive sanity is one. Basically, like there's way too many archive papers. How can I organize it and recommend papers and so on? I transcribed all of your podcasts. What is you learn from that experience from transcribing the process of like you like consuming audio books and podcasts and so on? Here's the process that achieves closer to human level performance and annotation. Yeah. Well, I definitely was like surprised that transcription with OpenEyes WestBair was working so well compared to what I'm familiar with from Siri and like a few other systems, I guess. It worked so well. That's what gave me some energy to try it out and I thought it could be fun to run on podcasts. It's kind of not obvious to me why WestBair is so much better compared to anything else because I feel like there should be a lot of incentive for a lot of companies to produce transcription systems and that they've done so over a long time. WestBair is not a super exotic model. It's a transformer. It takes male spectrograms and just outputs tokens of text. It's not crazy. The model and everything has been around for a long time. I'm not actually 100% sure why it's not obvious to me either. It makes me feel like I'm missing something. I'm missing something. Yeah, because there's huge even Google and so on YouTube transcription. Yeah. Yeah, it's unclear, but some of it is also integrating into a bigger system that is so the user interface, how's deployed and all that kind of stuff. Maybe running it as an independent thing is much easier. Like an order of magnitude easier than deploying to a large integrated system like YouTube transcription or anything like meetings. Like Zoom has transcription that's kind of crappy. But creating interface where the text is different individual speakers, it's able to display it in compelling ways, run it real time, all that kind of stuff. Maybe that's difficult. I still have the explanation I have because I'm currently paying quite a bit for human transcription and human caption annotation. It seems like there's a huge incentive to automate that. Yeah, it's very confusing. I don't know if you looked at some of the whisper transcripts, but they're quite good. They're good. Especially in tricky cases. I've seen whisper performance on super tricky cases and it doesn't credibly well. So I don't know. Apotgas is pretty simple. It's like high quality audio and you're speaking usually pretty clearly. I don't know what open AI's plans are either. Yeah, there's always fun projects basically. And stable diffusion also is opening up a huge amount of experimentation. I would say in the visual realm and generating images and videos and movies. I'll think like videos now. And so that's going to be pretty crazy. That's going to almost certainly work and it's going to be really interesting when the cost of content creation is going to fall to zero. You used to need a painter for a few months to paint a thing and now it's going to be speak to your phone to get your video. So Hollywood will start using it to generate scenes, which completely opens up. Yeah, so you can make a movie like Avatar eventually for under a million dollars. Much less. Maybe just by talking to your phone. I mean, I know it sounds kind of crazy. And then there'd be some voting mechanism. Like how do you have a, like, would there be a show on Netflix that's generated completely automatically? So, yeah, and what does it look like also when you can generate it on demand? And it's, and there's infinity of it. Yeah. Oh, man. All the synthetic content. I mean, it's humbling because we treat ourselves as special for being able to generate art and ideas and all that kind of stuff. If that can be done in an automated way by AI. Yeah. I think it's fascinating to me how these, the predictions of AI and what it's going to look like and what it's going to be capable of are completely inverted and wrong. And sci-fi of 50s and 60s is just like totally not right. They imagine AI as like super calculating their approvers and we're getting things that can talk to you about emotions. It can do art. It's just like weird. Are you excited about that feature? Just AI's like hybrid systems, heterogeneous systems of humans and AI's talking about emotions, Netflix and children and AI system that's where the Netflix thing you watch is also generated by AI. I think it's going to be interesting for sure. And I think I'm cautiously optimistic, but it's not it's not obvious. Well, the sad thing is your brain and mine developed in a time where before Twitter, before the before the internet. So I wonder people that are born inside of it might have a different experience. Like I maybe you can still resist it. And the people born now will not. Well, I do feel like humans are extremely malleable. Yeah. And you're probably right. What is the meaning of life, Andre? We talked about sort of the universe having a conversation with us humans or with the systems we create to try to answer for the universe, for the creator of the universe to notice us. We're trying to create systems that are loud enough to answer back. I don't know if that's the meaning of life. That's like meaning of life for some people. The first level answer I would say is anyone can choose their own meaning of life because we are conscious entity and it's beautiful. Number one, but I do think that like a deeper meaning of life as someone is interested is along the lines of like what the hell is all this? And like why? And if you look at the into fundamental physics and the quantum field theory and the standard model, they're like way, they're very complicated. And there's this like 19 free parameters of our universe. And like what's going on with all this stuff? And why is it here? And can I hack it? Can I work with it? Is there a message for me? Am I supposed to create a message? And so I think there's some fundamental answers there. But I think there's actually even like, you can't actually like really make dent in those without more time. And so to me also there's a big question around just getting more time, honestly. Yeah, that's kind of like what I think about quite a bit as well. So kind of the ultimate or at least first way to sneak up to the why question is to try to escape the system, the universe. And then for that, you sort of backtrack and say, okay, for that, that's going to be take a very long time. So the why question boils down from an engineering perspective to how do we extend? Yeah, I think that's the question number one, practically speaking because you can't, you're not going to calculate the answer to the deeper questions in time you have. And that could be extending your own lifetime or extending just the lifetime of human civilization of whoever wants to. Not many people might not want that. But I think people who do want that, I think, I think it's probably possible. And I don't know, I don't know that people fully realize this. I kind of feel like people think of death as an inevitable but at the end of the day, this is a physical system. Something's go wrong. It makes sense why things like this happen evolutionarily, speaking. And there's most certainly interventions that are mitigated. I mean, that would be interesting if death is eventually looked at as as a fascinating thing that used to happen to humans. I don't think it's unlikely. I think it's, I think it's likely. And it's up to our imagination to try to predict what the world without death looks like. Yes, hard to, I think the values will completely change. Could be. I don't really buy all these ideas that, oh, without death, there's no meaning, there's nothingness. I don't intuitively buy all those arguments. I think there's plenty of meaning, plenty of things to learn. They're interesting exciting. I want to know, I want to calculate, I want to improve the condition of all the humans and organisms that are alive. At the way we find meaning, we change. There is a lot of humans probably including myself that finds meaning in the finiteness of things. But that doesn't mean that's the only source of meaning. I do think many people will go with that, which I think is great. I love the idea that people can just choose their own adventure. Like you are born as a conscious free entity by default, I'd like to think. And you have your alienable rights for life in the pursuit of happiness. I don't know if you have that. In the nature, the landscape of happiness, you can choose your own adventure mostly. And that's not the fully true. But I'm still pretty sure I'm an NPC. But an NPC can't know it's an NPC. There could be different degrees and levels of consciousness. I don't think there's a more beautiful way to end it. Andre, you're an incredible person. I'm really honored you would talk with me. Everything you've done for the machine learning world, for the AI world, to just inspire people to educate millions of people. It's been great. And I can't wait to see what you do next. It's been an honor, man. Thank you so much for talking today. Awesome. Thank you. Thanks for listening to this conversation with Andre Karpathy to support this podcast. Please check out our sponsors in the description. And now let me leave you with some words from Samuel Carlin. The purpose of models is not to fit the data, but to sharpen the questions. Thanks for listening and hope to see you next time.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"transcription.txt\")\n",
        "text_documents = loader.load()\n",
        "text_documents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"xstoresuite-2300-dpg.pdf\")\n",
        "xstore_documents = loader.load()\n",
        "xstore_documents"
      ],
      "metadata": {
        "id": "UGi2Fwn5BNGL",
        "outputId": "8b5ff31a-1c46-448a-a8ca-800136b68f89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 0}, page_content=' \\n \\nOracle® Retail Xstore Point of Service \\nDeal Pricing Guide \\nRelease 23.0.0 \\nF80981-02 \\nAugust 2023 '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 1}, page_content=' \\nOracle® Retail Xstore Point of Service Deal Pricing Guide, Release 23.0.0 \\nF80981-02 \\nCopyright © 2023, Oracle and/or its affiliates. All rights reserved. \\nPrimary Author:  \\nThis software and related documentation are provided under a license agreement containing \\nrestrictions on use and disclosure and are protected by intellectual property laws. Except as \\nexpressly permitted in your license agreement or allowed by law, you may not use, copy, \\nreproduce, translate, broadcast, modify, license, transmit, distribute, exhibit, perform, publish, or \\ndisplay any part, in any form, or by any means. Reverse engineering, disassembly, or \\ndecompilation of this software, unless required by law for interoperability, is prohibited. \\nThe information contained herein is subject to change without notice and is not warranted to be \\nerror-free. If you find any errors, please report them to us in writing. \\nIf this software or related documentation is delivered to the U.S. Government or anyone licensing it \\non behalf of the U.S. Government, then the following notice is applicable: \\nU.S. GOVERNMENT END USERS: Oracle programs, including any operating system, integrated \\nsoftware, any programs installed on the hardware, and/or documentation, delivered to U.S. \\nGovernment end users are \"commercial computer software\" pursuant to the applicable Federal \\nAcquisition Regulation and agency-specific supplemental regulations. As such, use, duplication, \\ndisclosure, modification, and adaptation of the programs, including any operating system, \\nintegrated software, any programs installed on the hardware, and/or documentation, shall be \\nsubject to license terms and license restrictions applicable to the programs. No other rights are \\ngranted to the U.S. Government. \\nThis software or hardware is developed for general use in a variety of information management \\napplications. It is not developed or intended for use in any inherently dangerous applications, \\nincluding applications that may create a risk of personal injury. If you use this software or hardware \\nin dangerous applications, then you shall be responsible to take all appropriate fail-safe, backup, \\nredundancy, and other measures to ensure its safe use. Oracle Corporation and its affiliates \\ndisclaim any liability for any damages caused by use of this software or hardware in dangerous \\napplications. \\nOracle and Java are registered trademarks of Oracle and/or its affiliates. Other names may be \\ntrademarks of their respective owners. \\nIntel and Intel Xeon are trademarks or registered trademarks of Intel Corporation. All SPARC \\ntrademarks are used under license and are trademarks or registered trademarks of SPARC \\nInternational, Inc. AMD, Opteron, the AMD logo, and the AMD Opteron logo are trademarks or \\nregistered trademarks of Advanced Micro Devices. UNIX is a registered trademark of The Open \\nGroup. \\nThis software or hardware and documentation may provide access to or information on content, \\nproducts, and services from third parties. Oracle Corporation and its affiliates are not responsible \\nfor and expressly disclaim all warranties of any kind with respect to third-party content, products, \\nand services unless otherwise set forth in an applicable agreement between you and Oracle. \\nOracle Corporation and its affiliates will not be responsible for any loss, costs, or damages incurred \\ndue to your access to or use of third-party content, products, or services, except as set forth in an \\napplicable agreement between you and Oracle. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 2}, page_content=' \\nValue-Added Reseller (VAR) Language \\nOracle Retail VAR Applications \\nThe following restrictions and provisions only apply to the programs referred to in this section and \\nlicensed to you. You acknowledge that the programs may contain third party software (VAR \\napplications) licensed to Oracle. Depending upon your product and its version number, the VAR \\napplications may include: \\n(i) the MicroStrategy Components developed and licensed by MicroStrategy Services Corporation \\n(MicroStrategy) of McLean, Virginia to Oracle and imbedded in the MicroStrategy for Oracle Retail \\nData Warehouse and MicroStrategy for Oracle Retail Planning & Optimization applications. \\n(ii) the Wavelink component developed and licensed by Wavelink Corporation (Wavelink) of \\nKirkland, Washington, to Oracle and imbedded in Oracle Retail Mobile Store Inventory \\nManagement. \\n(iii) the software component known as Access Via™ licensed by Access Via of Seattle, \\nWashington, and imbedded in Oracle Retail Signs and Oracle Retail Labels and Tags. \\n(iv) the software component known as Adobe Flex™ licensed by Adobe Systems Incorporated of \\nSan Jose, California, and imbedded in Oracle Retail Promotion Planning & Optimization \\napplication. \\nYou acknowledge and confirm that Oracle grants you use of only the object code of the VAR \\nApplications. Oracle will not deliver source code to the VAR Applications to you. Notwithstanding \\nany other term or condition of the agreement and this ordering document, you shall not cause or \\npermit alteration of any VAR Applications. For purposes of this section, \"alteration\" refers to all \\nalterations, translations, upgrades, enhancements, customizations or modifications of all or any \\nportion of the VAR Applications including all reconfigurations, reassembly or reverse assembly, re-\\nengineering or reverse engineering and recompilations or reverse compilations of the VAR \\nApplications or any derivatives of the VAR Applications. You acknowledge that it shall be a breach \\nof the agreement to utilize the relationship, and/or confidential information of the VAR Applications \\nfor purposes of competitive discovery. \\nThe VAR Applications contain trade secrets of Oracle and Oracle\\'s licensors and Customer shall \\nnot attempt, cause, or permit the alteration, decompilation, reverse engineering, disassembly or \\nother reduction of the VAR Applications to a human perceivable form. Oracle reserves the right to \\nreplace, with functional equivalent software, any of the VAR Applications in future releases of the \\napplicable program. \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 3}, page_content=''),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 4}, page_content=' \\ni \\nContents \\n \\nSend Us Your Comments ............................................................................................... vii \\nPreface .............................................................................................................................. ix \\nAudience ...................................................................................................................... ix \\nDocumentation Accessibility ........................................................................................ ix \\nAccess to Oracle Support ..................................................................................... ix \\nRelated Documents ..................................................................................................... ix \\nCustomer Support ....................................................................................................... ix \\nReview Patch Documentation ...................................................................................... x \\nImproved Process for Oracle Retail Documentation Corrections................................. x \\nOracle Retail Documentation on the Oracle Help Center (docs.oracle.com)  ............... x \\nConventions ................................................................................................................. xi \\n1 Deal Pricing Tables ...................................................................................................... 1 \\nOverview ....................................................................................................................... 1 \\nHow this Guide Is Organized ........................................................................................ 1 \\nPrimary Deal Tables ..................................................................................................... 2 \\nprc_deal Table ....................................................................................................... 2 \\nprc_deal_field_test Table ....................................................................................... 5 \\nprc_deal_item Table .............................................................................................. 9 \\nprc_deal_week Table ........................................................................................... 11 \\nAncillary Deal Tables .................................................................................................. 12 \\nprc_deal_trig Table .............................................................................................. 13 \\nprc_deal_document_xref Table ........................................................................... 14 \\nprc_deal_cust_groups Table ................................................................................ 15 \\nprc_deal_loc Table ............................................................................................... 16 \\ndsc_coupon_xref Table ........................................................................................ 16 \\nXML Configuration ...................................................................................................... 17 \\nPricing.xml ............................................................................................................ 17 \\nDeal Pricing Processing Overview ............................................................................. 18 \\nThe Dealspace ..................................................................................................... 18 \\nFlow Overview ...................................................................................................... 19 \\n2 Line Item Deals ........................................................................................................... 21 \\nOverview ..................................................................................................................... 21 \\nLine Item Deal Setup Examples ................................................................................. 21 \\nItem Price Adjustment .......................................................................................... 21 \\nQuantity Threshold Discount Deals ..................................................................... 21 \\nMix and Match Pricing: Compound (AND/OR) Deals .......................................... 22 \\nDeals Using Item Properties as Parameters ........................................................ 22 \\nItem Price Adjustment Deal Examples ....................................................................... 23 \\nLine Item Deals 1A, 1B, and 1C: Buy X item and get $Y (or %) off the item ....... 23 \\nprc_deal Table: Line Item Deals 1A, 1B, and 1C ................................................. 23 '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 5}, page_content=' \\nii  \\nprc_deal_field_test Table: Line Item Deals 1A, 1B, and 1C ................................ 24 \\nprc_deal_item Table: Line Item Deals 1A, 1B, and 1C ........................................ 25 \\nQuantity Threshold Deal Examples ............................................................................ 26 \\nLine Item Deals 2A, 2B, and 2C: Buy X item qty for $Y (or %/$ off each) ........... 26 \\nprc_deal Table: Line Item Deals 2A, 2B, and 2C ................................................. 26 \\nprc_deal_field_test Table: Line Item Deals 2A, 2B, and 2C ................................ 27 \\nprc_deal_item Table: Line Item Deals 2A, 2B, and 2C ........................................ 27 \\nMix and Match Pricing: Compound (AND/OR) Deals Examples ................................ 29 \\nLine Item Deal 3A:Buy X item, get Y item at a discount ...................................... 29 \\nprc_deal Table: Deal 3A ...................................................................................... 29 \\nprc_deal_field_test Table: Deal 3A ...................................................................... 30 \\nprc_deal_item Table: Deal 3A .............................................................................. 30 \\nLine Item Deal 3B: Buy X AND Y, get Z at % (or $, or New Price) off ................. 31 \\nprc_deal Table: Deal 3B ...................................................................................... 31 \\nprc_deal_field_test Table: Deal 3B ...................................................................... 32 \\nprc_deal_item Table: Deal 3B .............................................................................. 32 \\nLine Item Deal 3C: Mix and Match Pricing - MERCHLEVEL1 Level Trigger ....... 33 \\nprc_deal Table: Deal 3C ...................................................................................... 33 \\nprc_deal_field_test Table: Deal 3C ...................................................................... 35 \\nprc_deal_item Table: Deal 3C ............................................................................. 35 \\nLine Item Deal 3D: Buy 2 (or more) of X and get Z at % off ................................ 36 \\nprc_deal Table: Deal 3D ...................................................................................... 36 \\nprc_deal_field_test Table: Deal 3D ...................................................................... 37 \\nprc_deal_item Table: Deal 3D ............................................................................. 37 \\nLine Item Deal 3E: Buy X, get Y% off another ..................................................... 38 \\nprc_deal Table: Deal 3E ...................................................................................... 38 \\nprc_deal_field_test Table: Deal 3E ...................................................................... 39 \\nprc_deal_item Table: Deal 3E .............................................................................. 40 \\nLine Item Deal 3F: Buy X OR Y and get Z at % off .............................................. 40 \\nprc_deal Table: Deal 3F ....................................................................................... 40 \\nprc_deal_field_test Table: Deal 3F ...................................................................... 42 \\nprc_deal_item Table: Deal 3F .............................................................................. 42 \\nLine Item Deal 3G: Buy item from MERCHLEVEL1 X (excluding clearance items \\nand discounted items), get Y% off ....................................................................... 43 \\nprc_deal Table: Deal 3G ...................................................................................... 43 \\nprc_deal_field_test Table: Deal 3G ..................................................................... 44 \\nprc_deal_item Table: Deal 3G ............................................................................. 45 \\nLine Item Deal 3H: Multiple item qualifiers used to match an item for a deal  ...... 45 \\nprc_deal Table: Deal 3H ...................................................................................... 45 \\nprc_deal_field_test Table: Deal 3H ...................................................................... 46 \\nprc_deal_item Table: Deal 3H ............................................................................. 47 \\nUsing Item Properties ................................................................................................. 48 \\nDeal 4: Item Properties Deal ................................................................................ 48 \\nprc_deal Table: Item Properties Deal .................................................................. 48 \\nprc_deal_field_test Table: Item Properties Deal .................................................. 49 '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 6}, page_content=' \\niii \\nprc_deal_item Table: Item Properties Deal ......................................................... 50 \\n3 Transaction Deals ...................................................................................................... 51 \\nOverview ..................................................................................................................... 51 \\nExclusive Transaction Deals ...................................................................................... 51 \\nExclusive Deals Setup ......................................................................................... 51 \\nExclusive Deals Example ..................................................................................... 51 \\nTransaction Deal Setup .............................................................................................. 52 \\nBuy $X Amount and Get Y Discount .................................................................... 52 \\nBuy More, Get More ............................................................................................. 52 \\nSubtotal - Discount % or $ Off Examples ................................................................... 52 \\nTransaction Deals 1A and 1B: Purchase X dollars and get Y% (or $) off  ........... 52 \\nprc_deal Table: Deals 1A and 1B ........................................................................ 53 \\nTransaction Deal 1C: Purchase X dollars and get item Y for $Z ......................... 54 \\nprc_deal Table: Deal 1C ...................................................................................... 54 \\nprc_deal_field_test Table: Deal 1C ...................................................................... 54 \\nprc_deal_item Table: Deal 1C ............................................................................. 55 \\nSubtotal - Tiered % or $ Off Example ......................................................................... 55 \\nTransaction Deal 2: Buy more, get more ............................................................. 56 \\nprc_deal Table: Transaction Deal 2 ..................................................................... 56 \\n4 Merchandise Level Subtotal Deals........................................................................... 59 \\nOverview ..................................................................................................................... 59 \\nDeals Using a Merchandise Level Subtotal ......................................................... 59 \\nMerchandise Level Subtotal Deals ............................................................................. 59 \\nMerchandise Level Subtotal Deal Examples ....................................................... 59 \\nDeal A: Spend $X In MERCHLEVEL1 A, Get Y% Off ......................................... 60 \\nprc_deal Table: Merchandise Level Subtotal Deal A ........................................ 60 \\nprc_deal_field_test Table: Merchandise Level Subtotal Deal A ....................... 61 \\nprc_deal_item Table: Merchandise Level Subtotal Deal A ............................... 61 \\nDeal B: Spend $X In MERCHLEVEL1 A Get $Y Off ........................................... 61 \\nprc_deal Table: Merchandise Level Subtotal Deal B ........................................ 62 \\nprc_deal_field_test Table: Merchandise Level Subtotal Deal B ....................... 63 \\nprc_deal_item Table: Merchandise Level Subtotal Deal B ............................... 63 \\n5 Day and Time-Specific Deals .................................................................................... 65 \\nOverview ..................................................................................................................... 65 \\nDay and Time-Specific Deal Setup ............................................................................ 67 \\nDeal Setup Process ............................................................................................. 67 \\nDeal TS_1 ............................................................................................................ 67 \\nprc_deal Table: Deal TS_1 ............................................................................... 67 \\nprc_deal_week Table: Deal TS_1 ........................................................................ 68 \\nDeal TS_2 ............................................................................................................ 68 \\nprc_deal Table: Deal TS_2 .................................................................................. 68 \\nprc_deal_week Table: Deal TS_2 ..................................................................... 70 \\n6 Deferred Deals ............................................................................................................ 71 \\nOverview ..................................................................................................................... 71 '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 7}, page_content=' \\niv  \\nDeferred Deal Setup ................................................................................................... 71 \\nDeferred Deal - Deal 3: 10% Off Bounceback Coupon With Sale ....................... 71 \\nprc_deal Table: Deal 3 ......................................................................................... 71 \\nprc_deal_document_xref Table: Deal 3 ............................................................... 72 \\ndoc_document_definition Table: Deal 3 .............................................................. 73 \\ndoc_document_def_properties Table: Deal 3 ...................................................... 73 \\ndsc_discount Table: Deal 3 .................................................................................. 74 \\nDeferred Deal - Deal 4: 10% Off Bounceback Coupon With Return ................... 75 \\nprc_deal Table: Deal 4 ......................................................................................... 75 \\nprc_deal_document_xref Table: Deal 4 ............................................................... 76 \\ndoc_document_definition Table: Deal 4 .............................................................. 76 \\ndoc_document_def_properties Table: Deal 4 ...................................................... 77 \\ndsc_discount Table: Deal 4 .................................................................................. 78 \\n7 Using Deal Triggers ................................................................................................... 79 \\nOverview ..................................................................................................................... 79 \\nDeal Trigger Formats .................................................................................................. 79 \\nMultiple Triggers Belonging To the Same Grouping ............................................ 79 \\nExclusionary Deal Trigger .................................................................................... 80 \\nDeal Trigger Setup ..................................................................................................... 80 \\nDeal 5A: Group Membership Triggers a Deal ...................................................... 81 \\nprc_deal Table: Deal 5A ...................................................................................... 81 \\nprc_deal_trig Table: Deal 5A ............................................................................... 82 \\ncom_code_value Table: Deal 5A ......................................................................... 82 \\nDeal 5B: Coupon Triggers a Deal ........................................................................ 82 \\nprc_deal Table: Deal 5B ...................................................................................... 82 \\nprc_deal_item Table: Deal 5B .............................................................................. 84 \\nprc_deal_field_test Table: Deal 5B ...................................................................... 84 \\nprc_deal_trig Table: Deal 5B ............................................................................... 85 \\ndsc_coupon_xref Table: Deal 5B ......................................................................... 85 \\n8 Deal Best Pricing ....................................................................................................... 87 \\nOverview ..................................................................................................................... 87 \\nBest Deal Pricing Scenario - Buy 2 Get 1 Free .......................................................... 87 \\nDeal Transaction Example 1 ................................................................................ 87 \\nDeal Transaction Example 2 ................................................................................ 88 \\nAlgorithm For Item Targets .................................................................................. 89 \\nApplying the Algorithm to Deal Transaction Example 2 ...................................... 89 \\nAdditional Best-Pricing Deal Examples ...................................................................... 90 \\nDeal Transaction Example 3 ................................................................................ 90 \\nApplying the Algorithm to Deal Transaction Example 3 ...................................... 91 \\nDeal Transaction Example 4 ................................................................................ 91 \\nApplying the Algorithm to Deal Transaction Example 4 ...................................... 92 \\nDeal Transaction Example 5 ................................................................................ 92 \\nDeal Transaction Example 6 ................................................................................ 93 \\nDeal Best Pricing Results ........................................................................................... 94 '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 8}, page_content=' \\nv \\n9 Download Records .................................................................................................... 95 \\nOverview ..................................................................................................................... 95 \\nDownload Record Layout ........................................................................................... 95 \\nDEAL Record | prc_deal Table ............................................................................ 95 \\nDEAL_ITEM record | prc_deal_item Table ........................................................ 101 \\nDEAL_ITEM_TEST record | prc_deal_field_test Table ..................................... 104 \\nDEAL_TRIGGER record | prc_deal_trig Table .................................................. 104 \\nREBATE record | *multiple Tables ..................................................................... 110 \\nCODE_VALUE record | com_code_value Table ............................................... 112 \\nCOUPON_XREF record | dsc_coupon_xref Table ............................................ 113 \\nDEAL_CUST_GROUPS record | prc_deal_cust_groups Table ........................ 114 \\nDEAL_WEEK record | prc_deal_week Table .................................................... 115 \\nCOUPON_DEAL record | *multiple Tables ........................................................ 116 \\nAppendix ........................................................................................................................ 117 \\nRevision History ............................................................................................................ 117 \\nRevision History Version 23.0.0 ............................................................................... 117 \\nRevision History Version 22.0 .................................................................................. 117 \\nRevision History Version 20.0 .................................................................................. 117 \\nRevision History Version 19.0 .................................................................................. 117 \\nRevision History Version 18.0 .................................................................................. 118 \\nRevision History Version 17.0 .................................................................................. 118 \\nRevision History Version 16.0 .................................................................................. 118 \\nRevision History Version 15.0 .................................................................................. 118 \\nRevision History Version 7.1 .................................................................................... 118 \\nRevision History Version 7.0 .................................................................................... 119 \\nRevision History Version 6.5 .................................................................................... 119 \\nRevision History Version 6.0 .................................................................................... 119 \\nRevision History Version 5.5 .................................................................................... 119 \\nRevision History: Version 4.0 through 5.0 ................................................................ 120 \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 9}, page_content=''),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 10}, page_content=\" \\nvii \\nSend Us Your Comments \\nOracle Retail Xstore Point of Service Deal Pricing Guide, Release 23.0.0 \\n \\nOracle welcomes customers' comments and suggestions on the quality and usefulness of \\nthis document. \\nYour feedback is important, and helps us to best meet your needs as a user of our \\nproducts. For example: \\n▪ Are the implementation steps correct and complete? \\n▪ Did you understand the context of the procedures? \\n▪ Did you find any errors in the information? \\n▪ Does the structure of the information help you with your tasks? \\n▪ Do you need different information or graphics? If so, where, and in what format? \\n▪ Are the examples correct? Do you need more examples? \\nIf you find any errors or have any other suggestions for improvement, then please tell us \\nyour name, the name of the company who has licensed our products, the title and part \\nnumber of the documentation and the chapter, section, and page number (if available).  \\nNote: Before sending us your comments, you might like to \\ncheck that you have the latest version of the document and if \\nany concerns are already addressed. To do this, access the \\nOnline Documentation available on the Oracle Help Center \\n(docs.oracle.com) site. It contains the most current \\nDocumentation Library plus all documents revised or \\nreleased recently. \\nSend your comments to us using the electronic mail address: retail-doc_us@oracle.com \\nPlease give your name, address, electronic mail address, and telephone number \\n(optional). \\nIf you need assistance with Oracle software, then please contact your support \\nrepresentative or Oracle Support Services.  \\nIf you require training or instruction in using Oracle software, then please contact your \\nOracle local office and inquire about our Oracle University offerings. A list of Oracle \\noffices is available on our Web site at www.oracle.com.\"),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 11}, page_content=''),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 12}, page_content=\" \\nix \\n \\nPreface \\nThis documentation outlines the pricing for the Oracle Retail Xstore Point of Service. \\nAudience \\nThis Deal Pricing Guide is for users and administrators of the Oracle Retail Xstore Suite. \\nThis includes merchandisers, buyers, business analysts, and administrative personnel.  \\nDocumentation Accessibility \\nFor information about Oracle's commitment to accessibility, visit the Oracle Accessibility \\nProgram website at \\nhttp://www.oracle.com/pls/topic/lookup?ctx=acc&id=docacc. \\nAccess to Oracle Support \\nOracle customers that have purchased support have access to electronic support through \\nMy Oracle Support. For information, visit \\nhttp://www.oracle.com/pls/topic/lookup?ctx=acc&id=info or visit \\nhttp://www.oracle.com/pls/topic/lookup?ctx=acc&id=trs if you are \\nhearing impaired. \\nRelated Documents \\nFor more information, see the following documents in the Oracle Retail Xstore Suite \\n23.0.0 documentation set: \\n▪ Oracle Retail Xstore Suite Release Notes \\n▪ Oracle Retail Xstore Suite Oracle Retail Xstore Suite 23.0.0/Merchandising 16.0.2 \\nImplementation Guide \\n▪ Oracle Retail Xstore Point-of-Service Classic User Guide \\n▪ Oracle Retail Xstore Point-of-Service User Guide \\n▪ Oracle Retail Xstore Point-of-Service Classic Manager's Guide \\n▪ Oracle Retail Xstore Point-of-Service Classic Shipping, Receiving, and Inventory \\nGuide \\n▪ Oracle Retail Xstore Point-of-Service Reports Guide \\n▪ Oracle Retail Xstore Office User Guide \\n▪ Oracle Retail Xstore Suite Implementation and Security Guide \\nCustomer Support \\nTo contact Oracle Customer Support, access My Oracle Support at the following URL:  \\nhttps://support.oracle.com \\nWhen contacting Customer Support, please provide the following: \\n▪ Product version and program/module name \\n▪ Functional and technical description of the problem (include business impact)  \\n▪ Detailed step-by-step instructions to re-create \\n▪ Exact error message received \\n▪ Screen shots of each step you take \"),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 13}, page_content='Preface \\nx \\nReview Patch Documentation \\nWhen you install the application for the first time, you install either a base release (for \\nexample, 23.0) or a later patch release (for example, 23.0.1). If you are installing the \\nbase release or additional patch releases, read the documentation for all releases that \\nhave occurred since the base release before you begin installation. Documentation for \\npatch releases can contain critical information related to the base release, as well a s \\ninformation about code changes since the base release. \\nImproved Process for Oracle Retail Documentation \\nCorrections \\nTo more quickly address critical corrections to Oracle Retail documentation content, \\nOracle Retail documentation may be republished whenever a critical correction is \\nneeded. For critical corrections, the republication of an Oracle Retail document may at \\ntimes not be attached to a numbered software release; instead, the Oracle Retail \\ndocument will simply be replaced on the Oracle Help Center (docs.oracle.com) site, or, in \\nthe case of Data Models, to the applicable My Oracle Support Documentation container \\nwhere they reside. \\nThis process will prevent delays in making critical corrections available to customers. For \\nthe customer, it means that before you begin installation, you must verify that you have \\nthe most recent version of the Oracle Retail documentation set. Oracle Retail \\ndocumentation is available on the Oracle Help Center (docs.oracle.com) at the following \\nURL: \\nhttps://docs.oracle.com/en/industries/retail/index.html \\nAn updated version of the applicable Oracle Retail document is indicated by Oracle part \\nnumber, as well as print date (month and year). An updated version uses the same part \\nnumber, with a higher-numbered suffix. For example, part number E123456-02 is an \\nupdated version of a document with part number E123456-01. \\nIf a more recent version of a document is available, that version supersedes all previous \\nversions. \\nOracle Retail Documentation on the Oracle Help Center \\n(docs.oracle.com) \\nOracle Retail product documentation is available on the following web site:  \\nhttps://docs.oracle.com/en/industries/retail/index.html \\n(Data Model documents can be obtained through My Oracle Support.) '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 14}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide xi \\nConventions \\nThe following text conventions are used in this document: \\nConvention Meaning \\nNavigate: This is a navigate statement. It tells you how to \\nget to the start of the procedure and ends with \\na screen shot of the starting point and the \\nstatement “the Window Name window opens.” \\nNote: This information is provided to improve your \\nunderstanding, simplify a task, or point out \\nspecial circumstances. \\nImportant: This information is important for the user to be \\naware of. For example, information that can \\nhelp prevent the loss of data. \\ncode This is a code sample. It is used to \\ndisplay examples of code. \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 15}, page_content=''),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 16}, page_content=' \\nOracle Retail Xstore Point of Service Deal Pricing Guide 1 \\n1 \\nDeal Pricing Tables \\nOverview \\nThis guide provides information about deal pricing in the Oracle Retail Xstore Suite and \\noutlines the options available for setting up and controlling this method of price \\nmarkdown. Deals are applied automatically once the criteria satisfying the deal are met, \\nwith no cashier action required. (Discounts are different because the cashier m ust select \\nand apply the appropriate mark-down.)  \\nDeal pricing is used to offer customers special, reduced prices on items or transactions \\nthat meet certain rules. Deals can be set up to change item prices or to provide \\nmerchandise bonuses. When changing item prices, deals can be set up to take a %-off \\nmarkdown, take a $-off markdown, or replace the permanent price with a deal price. \\nWhen the conditions of a deal rule are met, the award is applied appropriately. These \\nrules are defined in the database with individual database tables each providing different \\ninformation for a deal. However, not every deal requires information in every table.  \\nThe deal tables are populated with information downloaded from the home office to the \\nstores. The columns update_date and update_user_id will always be null when an object \\nis first created. Database information is downloaded as a flat file and loaded into the \\ndatabase by the DataLoader. Deal pricing information is downloaded prior to the effective \\ndate of the deal so that the store has all required deal information in its database by the \\ntime the deal is active. Refer to Oracle Retail Xstore Point-of-Service Host Interface \\ndocumentation for more information about DataLoader and download records.  \\nNote: Kit sales/returns are not covered in this guide. For \\nmore information about Kits, refer to the Oracle Retail Xstore \\nPoint-of-Service Technical Guide. \\nHow this Guide Is Organized \\n▪ This chapter, “Deal Pricing Tables”, shows the PRC Domain table layout information \\nrequired to set up deals in Oracle Retail Xstore Point of Service. The PRC Domain \\ntables and fields are listed with a definition of the information contained in the table, \\nand the type of information expected in each field in the table.  \\nNote: For more information about the PRC Domain and the \\ndeal pricing tables, see the Oracle Retail Xstore Point-of-\\nService Database Dictionary Guide. \\nChapters 2 through 7 provide specific examples of different deal types available in base \\nOracle Retail Xstore Point of Service. Each deal example shows the tables that must be \\nset up for the deal to apply. The deals defined here are examples only, showing \\nvariations in each deal type. \\nThe deal types have been grouped as follows: \\n▪ “Line Item Deals” provides examples of deals applied at the line-item level. Line item \\ndeals are discounts automatically applied to an item, based on the requirements of \\nthe deal. \\n▪ “Transaction Deals” provides examples of deals applied at the transaction level. \\nTransaction deals automatically apply discounts to an entire transaction based on the \\ntransaction subtotal amount. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 17}, page_content='Deal Pricing Tables \\n2 \\n▪ “Merchandise Level Subtotal Deals” provides examples of merchandise level subtotal \\ndeals automatically applied to a hierarchy subtotal, such as the subtotal for a specific \\nMERCHLEVEL1 or Merchandise Hierarchy Level-3. This deal type differs from a \\ntransaction deal because the discount is applied to a hierarchy subtotal rather than \\nthe subtotal for the entire transaction. \\n▪ “Day and Time-Specific Deals” provides examples of deals that are configured to \\ndefine the period when the deal is effective. In addition to defining the starting and \\nending dates and times for a deal, you can further define the deals to have different \\nstarting and ending times for each day of the week. \\n▪ “Deferred Deals” provides examples of deals that can be applied at a later date rather \\nthan in the current transaction. Deferred deals give customers a benefit that can be \\nused in the future. A bounce-back coupon is an example of a deferred deal. \\n▪ “Using Deal Triggers” provides examples of deals that are only applied when a \\nspecific requirement has been satisfied, making a customer eligible, or ineligible, for \\na defined deal. Examples provided here include group membership deals and \\ncoupon deals. \\n▪ “Deal Best Pricing” provides information about Oracle Retail Xstore Point-of-Service’s \\nbest deal pricing support and shows examples of how the best pricing algorithm is \\napplied in specific scenarios. \\n▪ “Download Records” provides information about the relationship between the \\nDataLoader records (.mnt files) and the Oracle Retail Xstore Point-of-Service \\ndatabase deal pricing tables for the examples described in this guide. This chapter \\nidentifies each DataLoader record/field and its corresponding table/column in the \\ndatabase.  \\nPrimary Deal Tables \\nThe tables listed below define the deal, the rules for the deal, the effective days and \\ntimes, and the award given when the deal rules have been met.  \\n▪ prc_deal — This is the primary table for deals.  \\n▪ prc_deal_field_test — This table contains the rules determining which items qualify \\nfor a particular part of a deal. \\n▪ prc_deal_week — This table contains entries that support applying promotions only \\non specific days, at specific times. Set up this table to allow different start and end \\ntimes to be assigned for each day of the week. \\n▪ prc_deal_item — This table contains the deal action. \\nprc_deal Table \\nThe prc_deal table provides general information about each deal. This table can be the \\nonly table required for some simple transaction-wide deals which do not reference any \\nitems. It is recommended that this table be loaded before the prc_deal_item or \\nprc_deal_field_test tables because the prc_deal_item and prc_deal_field_test tables \\ndepend on the deal_id field. \\nNote: The prc_deal table is loaded by DataLoader with \\ninformation from the DEAL record type. \\nA description of each field in the prc_deal table follows: '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 18}, page_content=\"Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 3 \\nTable 1-1: prc_deal Table \\nField Description \\norganization_id A unique identifier for a company, association, \\ninstitution, or other enterprise of interest to a retail store \\nor enterprise.  \\ndeal_id The unique identifier for a deal. \\norg_code Specifies the organization level code based on the \\ncustomer's store structure. For example: STORE, \\nDISTRICT, REGION, or CHAIN (to be defined by \\nclients) \\nDefault value set to * \\norg_value Specifies the value for the organization level code. For \\nexample: for store 123, the org_code will be STORE \\nand the org_value will be 123) \\nDefault value set to * \\ndescription Brief description of the deal. In some cases, this will be \\nused as the line item description in the transaction on \\nline items to which the deal applies. \\nconsumable This field defines whether deal is considered to be \\nexclusive. If set to true and the deal applies, then no \\nother deal can apply. Works for transaction-level deals \\nonly. \\nact_deferred Whether or not this is a deferred deal. For standard \\ndeals whose actions apply to the current transaction, \\nthis value is FALSE(0). It is true(1) when used in \\nconjunction with features like rebates and bounce back \\ncoupons, which cannot be used during the current \\ntransaction.  \\neffective_date The business date and time on which the deal becomes \\nactive. If set to Null, the deal becomes active \\nimmediately.  \\nend_date The business date and time on which the deal becomes \\ninactive. If left to Null, the deal has no scheduled \\nexpiration date.  \\nstart_time The time each day the deal becomes active within its \\nstart and end date. If this column is NULL the deal is \\nactive at the beginning of each day. (The date portion of \\nthis field is ignored by Oracle Retail Xstore Point of \\nService.) \\nend_time The time each day the deal becomes inactive within its \\nstart and end date. If this column is NULL the deal \\nremains active until the next day. (The date portion of \\nthis field is ignored by Oracle Retail Xstore Point of \\nService.)  \\ngenerosity_cap The maximum amount of money discounted by the deal. \\nUsed to place an upper limit on the amount that the deal \\nmay discount from the transaction.  \"),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 19}, page_content=\"Deal Pricing Tables \\n4 \\nField Description \\niteration_cap The maximum number of times the deal is applied to the \\nsame transaction. In the case of transaction-wide deals, \\nthis is always 1. In the case of item-based deals this \\nindicates the maximum number of times that a set of \\nitems may be matched to the transaction. A setting of -1 \\nallows an infinite number of sets. \\npriority_nudge This value is used to give extra priority to a given deal \\nwhen determining which deal is better. The deal with the \\nhigher value is used. This is often used when two deals \\nhave the same effect, but the description of one is \\npreferred. \\nWhen a customer is eligible for more than one deal that \\nhave equivalent results, this value determines which \\ndeal is used. \\nFor example, if membership in a loyalty program \\nenables the deal, but there is another deal that has the \\nsame result for everyone this week only, you would give \\na nudge (higher value) to the loyalty deal so that loyalty \\ncustomers will see the loyalty deal on their receipts. \\nsubtotal_min Minimum subtotal that the transaction must have before \\nthis deal is applied. \\nsubtotal_max Maximum subtotal this transaction can have before this \\ndeal no longer applies. If the value is -1, there is no \\nupper bound on the transaction's subtotal. \\ntrwide_action This field identifies the type of action performed across \\nthe entire transaction. Values are: NEW_PRICE, \\nPERCENT_OFF, CURRENCY_OFF, or Null if there are \\nno transaction-wide actions for the deal.  \\ntrwide_amount The currency amount or percentage used in \\ncombination with the action that is taken on the \\ntransaction subtotal. \\ntaxability_code How the tax is calculated with regard to the discount. \\nValid options are: POST_TAX, PRE_TAX/Default. When \\n“POST_TAX” is selected the tax is calculated before the \\ndiscount is applied. For any other selection the tax is \\ncalculated after the discount is applied. \\npromotion_id The identifier for the promotion. This is defined by the \\nclient.  \\nhigher_nonaction_amt_flag If this flag is TRUE (1), the deal is applied if the total \\namount of the trigger items is greater than the total \\namount of the discount items in a “Buy X Get Y Free” \\ndeal or in a “Buy X Get Y for % Off” deal. \\nexclude_price_override_flag If the value of this flag is TRUE (1), do not include items \\nwith a price-override in the deal.  \\nexclude_discounted_flag If the value of this flag is TRUE (1), do not include \\ndiscounted items in the deal. \\nNote: This applies to both manual discounts and deal \\ndiscounts. \"),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 20}, page_content=\"Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 5 \\nField Description \\ntargeted_flag If this value is TRUE (1), the deal is part of a targeted \\npromotion that is managed through the external \\nCustomer Engagement CRM application. \\nNote: A deal which is marked as “targeted” will not be \\napplied unless all of the following are true: \\n1) A customer is attached to the transaction and is \\nretrieved from the Customer Engagement CRM. \\n2) The customer retrieve response sent from the \\nCustomer Engagement CRM for the customer contains \\na “PromotionDealId” element whose value corresponds \\nto the prc_deal.deal_id for the targeted deal (that is, this \\nflag = 1). \\n3) All of the deal's other criteria are met. \\n week_sched_flag If TRUE, the deal has a schedule represented in the \\nprc_deal_week table. \\nsort_order Specifies the order in which deals should be sorted. The \\ndefault value is set to 0. When set to 0, deal resorting is \\nnot used. \\ntype Type of deal, used to identify deals that require special \\nhandling. The default value is set to Null. \\ngroup_id Deal group identifier. List of deal group identifiers and \\ntheir order is defined in the pricing.xml. Deals without \\nexplicit a group will be a part of DEFAULT group. The \\nDeal Engine will operate only on deals in the same deal \\ngroup at a time, but will iterate through all defined \\ngroups. \\ncreate_date The date and time the record was created.  \\ncreate_user_id The identification of the person who created the record. \\nupdate_date The date and time the record was last updated. \\nupdate_user_id The identification of the person who updated the record. \\nrecord_state The record status.  \\nprc_deal_field_test Table \\nThe prc_deal_field_test table contains the constraint information for item matching rules. \\nEvery deal that is offered at the item level (as opposed to the transaction level) will have \\nat least one entry in the prc_deal_field_test table per entry in the prc_deal_item table. \\nThe field tests are used to determine the eligibility of an item for a deal.  \\nNote: The prc_deal_field_test table is loaded by DataLoader \\nwith information from the DEAL_ITEM_TEST record type. \"),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 21}, page_content=\"Deal Pricing Tables \\n6 \\nA description of each field in the prc_deal_field_test table follows: \\nTable 1-2: prc_deal_field_test Table \\nField Definition \\norganization_id A unique identifier for a company, association, institution, \\nor other enterprise of interest to a retail store or \\nenterprise. \\ndeal_id The unique identifier for the Deal. Corresponds to \\nprc_deal.deal_id. \\nitem_ordinal Corresponds to the item ordinal for the rule in which this \\nfield match is incorporated. The ordinal defines the order \\nin which the items are matched and corresponds to the \\nitem_ordinal field in the prc_deal_item table. (The \\nprc_deal_item table defines the discounts or actions \\ntaken on the items when the deal is applied.) \\nitem_condition_seq Indicates the sequence in which two item conditions with \\nthe same item_condition_group number are performed. \\nUsed to ensure a unique primary key for each record. \\norg_code Specifies the organization level code based on the \\ncustomer's store structure. For example: STORE, \\nDISTRICT, REGION, or CHAIN. (to be defined by clients) \\nDefault value set to * \\norg_value Specifies the value for the organization level code. For \\nexample: for store 123, the org_code will be STORE and \\nthe org_value will be 123) \\nDefault value set to * \\nitem_condition_group Used to determine the relationship between two item \\nconditions for a deal. If two item condition groups for a \\ndeal are equal, the condition between them is an AND \\ncondition. Otherwise, the condition between them is an \\nOR. \\nFor example, if Condition A and Condition B have a \\ndifferent value for item_condition_group, the relationship \\nwill be (Condition A OR Condition B). If Condition A and \\nCondition B have the same value for \\nitem_condition_group, the relationship will be (Condition \\nA AND Condition B). \"),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 22}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 7 \\nField Definition \\nitem_field The field matched by this row. When an item’s deal \\neligibility is evaluated, the value fields of the \\nprc_deal_field_test record are compared to the value that \\nis entered for the item. Acceptable values include: \\nUSE - The use of this line item: SALE, RETURN, \\nLAYAWAY, SPECIAL_ORDER, \\nCUSTOMER_BACKORDER, WORK_ORDER, and \\nSEND_SALE. This the same enumeration as used in \\ntrl_sale_lineitm.sale_lineitm_typcode. \\nQUANTITY - Quantity of the line item. \\nPRICE - Price per unit of the item. \\nMERCHLEVEL1- A unique identifier for the POS selling \\nlocation within the store: itm_item.merch_level_1. \\nMERCHLEVEL2 - Unique identifier within a department: \\nitm_item. merch_level_2 \\nMERCHLEVEL3 - A unique identifier to denote a class of \\nitems as a product of a single supplier or \\nmanufacturer:itm_item.merch_level_3.  \\nMERCHLEVEL4 - Unique identifier within a class: \\nitm_item. merch_level_4. \\nVENDOR - Vendor/supplier of the item. The comparison \\nvalue comes from itm_item.vendor. \\nSEASON - Season for which the item is designed or \\nreleased. The comparison value comes from \\nitm_item.season_code. \\nSTYLE - Style of the item. The comparison value comes \\nfrom itm_item.parent_item_id. \\nSKU - The item’s unique identifier. The comparison value \\ncomes from itm_item.item_id. \\nITEM_STOCK_STATUS - The item’s stock status; for \\nexample, CLEARANCE. The comparison value comes \\nfrom itm_item.stock_status. \\nMANUFACTURER - Only applies if the item ID is the \\nUPC. If it is a UPC (12 or 13 digit), the first 6 numbers of \\nthe UPC (which define the manufacturer) are compared. \\nSALE_ITEM_TYPE_ONLY - See previously defined \\nvalues for USE in this table. \\nDIMENSION1 - The comparison value comes from \\nitm_item_dimension_value where \\nitm_item_dimension_type.dimension is dimension1.  \\nDIMENSION2 - The comparison value comes from \\nitm_item_dimension_value where \\nitm_item_dimension_type.dimension is dimension2. \\nDIMENSION3 - The comparison value comes from \\nitm_item_dimension_value where \\nitm_item_dimension_type.dimension is dimension3. \\nmore... '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 23}, page_content=\"Deal Pricing Tables \\n8 \\nField Definition \\nitem_field (continued) PRICE_OVERRIDE - The comparison value is true if a \\nmanual price change has been applied to an item; \\notherwise it is false. \\nDISCOUNTED - The comparison value is true if a \\ndiscount or coupon has been applied to the item; \\notherwise it is false. \\nSEQ_NUMBER - The comparison value is the item's \\nindex within the transaction. (that is, \\ntrl_rtrans_lineitm.rtrans_lineitm_seq) \\nITEM_PROPERTY - Property of the item. The name of \\nthe property to be tested must be preceded by a ':' (colon) \\nseparator. \\nFor example: ITEM_PROPERTY:GENDER \\nANY_ITEM - Used to denote that any deal-eligible item \\ncan satisfy this deal item test; the Match Rule and values \\ncan be left blank. \\nmatch_rule The rule used to match the field specified in item_field \\nwith the values in value1 and value2. The acceptable \\nvalues are: \\nEQUAL - Test field for equality to an argument. \\nNOT_EQUAL - Test field for inequality to an argument. \\nGREATER - Field must be greater than the first \\nargument. \\nLESS - Field must be less than the first argument. \\nBETWEEN - Field must be within the inclusive bound \\nspecified by the first and second arguments. \\nImportant: \\nWhen item_field = ITEM_PROPERTY, match_rule is \\ndependent upon the type of the property that depends on \\nitem and property name. Thus technically, property type \\ncan vary from item to item, but it is NOT supported. \\nIt is the customer's responsibility to ensure that proper \\ncomparison operators are used. \\nFor Example:  \\nString-type properties do not do \\nLESS/GREATER/BETWEEN comparisons. Therefore, \\nthe result of these comparisons is undefined and not \\nguaranteed to be consistent. \\nvalue1 The first argument used by the match_rule. \\nNote: \\nWhen item_field = ITEM_PROPERTY, this value must \\nconform to the following rules: \\n▪ Dates must be entered as: YYYY-MM-DD. \\n▪ Numbers can have only 3 significant digits after the \\ndecimal point and cannot have more than 15 digits \\nbefore the decimal point (be more than ~ 10 to power \\n14). \\n▪ Strings with leading and trailing spaces will be \\ntrimmed. \\n▪ Numbers that contain leading zeroes will be treated \\nas strings. \"),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 24}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 9 \\nField Definition \\nvalue2 Only used when “match_rule” is “BETWEEN”. Otherwise, \\nit is ignored. \\ncreate_date The date the record was created. \\ncreate_user_id The identifier of the person who created the record. \\nupdate_date The date the record was last updated. \\nupdate_user_id The identifier of the person who last updated the record. \\nrecord_state The record status.  \\nprc_deal_item Table \\nThe prc_deal_item table defines what happens to an item that qualifies for a particular \\npart of a deal. This action affects any item in the deal with a matching item_ordinal as the \\ndeal_item_field_test rule which qualified it. \\nNote: The prc_deal_item table is loaded by DataLoader with \\ninformation from the DEAL_ITEM record type. \\nA description of each field in the prc_deal_item table follows: \\nTable 1-3: prc_deal_item Table \\nField Definition \\norganization_id A unique identifier for a company, association, \\ninstitution, or other enterprise of interest to a \\nretail store or enterprise.  \\ndeal_id A unique identifier for the deal. Corresponds to \\nprc_deal.deal_id. \\nitem_ordinal This field corresponds to the item_ordinal in the \\ndeal_item_field_test table. For each deal, the \\nitem matching rules must have consecutive \\nordinal values starting with 1. The Deal Engine \\nmatches items in decreasing price order. \\nTherefore, as the number gets closer to 1, the \\nitems become more expensive. \\nThe Deal Engine matches items with rules \\nbeginning with the most expensive items first. A \\nside effect of having a smaller item_ordinal is \\nthat the price of the item matched is equal to, or \\ngreater than, an item matched by the same rule \\nwith a higher item_ordinal. \\nExample: A deal which matches a skirt and a \\nbelt (buy one skirt, get a free belt) has two item \\nmatching rules. The first rule matches the skirt, \\nand takes no action on that item; that rule is \\nentered on a row in the table. The rule’s \\nitem_ordinal is 1. \\nThe second rule matches the belt, and assigns \\na new price of zero (0); that rule is entered on a \\nsecond row in the same table. The item_ordinal \\nfor the second rule is 2. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 25}, page_content=\"Deal Pricing Tables \\n10 \\nField Definition \\norg_code Specifies the organization level code based on \\nthe customer's store structure. For example: \\nSTORE, DISTRICT, REGION, or CHAIN. (to be \\ndefined by clients) \\nDefault value set to * \\norg_value Specifies the value for the organization level \\ncode. For example: for store 123, the org_code \\nwill be STORE and the org_value will be 123) \\nDefault value set to * \\nconsumable If true(1), a deal has item matching rules which \\nconsume the items that they match. (Item \\nconsumption is largely inapplicable to deferred \\ndeals.) Any item rules in a subsequent deal \\nwhich could match and consume the item will \\nbe unable to match an already consumed item. \\nThis allows deals to exclude each other based \\non which items they have matched. \\nNote: This flag only affects the composition of \\ngroups when considering multiple deals, not \\nmultiple applications of the same deal. This flag \\nis used to either allow or prohibit a single item \\nto serve as a trigger or target for multiple deals \\nsimultaneously. \\nqty_min Minimum quantity of this item required to satisfy \\nthis item rule. A qty_min of 0 puts no lower \\nbound on the range. (Default value is 1.) \\nqty_max Maximum quantity of this item which can satisfy \\nthis item rule. A qty_max of less than or equal \\nto 0 describes an unbounded upper limit. \\n(Default value is 1.) \\nmin_item_total Minimum subtotal of items matching this rule \\nrequired to satisfy this item rule. (For example, \\nbuy $50 of merchandise in the men’s \\ndepartment and…) \\nNote: Item selection is done on best-effort \\nbasis and Xstore will attempt to minimize \\nnumber of items selected by individual deal \\napplications only – no minimization of subtotal. \\nWhen used to setup “Every $X” deal (in \\nconjuction with iteration_cap) it will result in not \\nproviding discount exactly every $X spent. In \\nsuch cases tiered deals should be used. \\ndeal_action Action which the deal takes on this item. Valid \\nvalues: \\nNEW_PRICE - Substitute a new value for the \\nprice of the item. \\nPERCENT_OFF - The percentage discount off \\nthe current price of the item, or the subtotal of \\nthe current transaction. \\nCURRENCY_OFF - The fixed amount off the \\ncurrent price of the item, or the subtotal of the \\ncurrent transaction. \"),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 26}, page_content=\"Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 11 \\nField Definition \\naction_arg The amount or percentage that is applied, \\nbased on the value of deal_action. \\naction_arg_qty Indicates the total number of items to which the \\naction is applied (and thus, are required for the \\ndeal) as referenced by action_arg and \\ndeal_action. \\nFor example, if item A can be purchased at 3 \\nfor $10, action_arg will be 10 and \\naction_arg_qty will be 3 for this deal. Whereas, \\nif item A can be purchased at 3 for $10 each \\n(for a total of $30), action_arg will be 10 and \\naction_arg_qty will be 1 for this deal. \\nNote: A special value of -1 is used to apply \\naction_arg to the actual number of items that \\nqualified for a deal. \\nFor example: Spend $100 and get a $10 \\ndiscount deal...  \\nqty_min will be set to 1, qty_max will be set to -\\n1, min_total will be set to 100.00, action_arg will \\nbe set to 10.00.  \\nWe want $10 to be split among all qualifying \\nitems, but we don't know at this time how many \\nitems the customer will buy, thus we need to set \\naction_arg_qty to -1. \\ncreate_date The date the record was created. \\ncreate_user_id The identifier of the person who created the \\nrecord. \\nupdate_date The date the record was last updated. \\nupdate_user_id The identifier of the person who last updated \\nthe record. \\nrecord_state The record status.  \\nprc_deal_week Table \\nThe prc_deal_week table defines deals that only apply on specific days, at specific times. \\nFor example, using this table, you can set up a deal that will only be applied on Tuesday, \\nfrom 9:30 to 13:30, and on Thursday, from 12:00 to 17:00. You only need to populate this \\ndata if you set up a deal with day-specific start/end time functionality. \\nNote: The prc_deal_week table is loaded by DataLoader \\nwith information from the DEAL_WEEK record type. \\nA description of each field in the prc_deal_week table follows: \\nTable 1-4: prc_deal_week \\nField Definition \\norganization_id A unique identifier for a company, association, \\ninstitution, or other enterprise of interest to a \\nretail store or retail enterprise. \"),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 27}, page_content=\"Deal Pricing Tables \\n12 \\nField Definition \\ndeal_id  The unique identifier for a deal. Corresponds to \\nprc_deal.deal_id. \\nday_code The code representing the day to apply the \\ndeal: \\nSUN, MON, TUE, WED, THU, FRI, SAT \\nstart_time The starting time of the deal for the given day. \\n(The date portion of this field is ignored by \\nOracle Retail Xstore Point of Service.) \\norg_code Specifies the organization level code based on \\nthe customer's store structure. For example: \\nSTORE, DISTRICT, REGION, or CHAIN. (to be \\ndefined by clients) \\nDefault value set to * \\norg_value Specifies the value for the organization level \\ncode. For example: for store 123, the org_code \\nwill be STORE and the org_value will be 123) \\nDefault value set to * \\nend_time The ending time of the deal for the given day. \\n(The date portion of this field is ignored by \\nOracle Retail Xstore Point of Service.) \\ncreate_date  The date the record was created. \\ncreate_user_id The identifier of the person who created the \\nrecord. \\nupdate_date  The date the record was updated. \\nupdate_user_id The identifier of the person who updated the \\nrecord. \\nrecord_state The record status.  \\nAncillary Deal Tables \\nThe following deal tables are used to associate deals with customer groups, documents, \\nand with any other tables with which deals should be associated. These associations are \\nmade by defining deal triggers or by utilizing deferred deals. \\n▪ prc_deal_trig — This table is used to map each deal to the triggers that put the deal \\ninto effect. This table is loaded by DataLoader with information from the \\nDEAL_TRIGGER record type or the DEAL_TRIGGER_EXCLUDE record type.  \\n▪ prc_deal_document_xref — This table links deferred deals to a document. (Used \\nfor rebates, bounceback coupons, and so on). This table is loaded by DataLoader \\nwith information from the FREE_GIFTCARD and REBATE record types.  \\n▪ prc_deal_cust_groups — This table maps a deal to a customer group. This table is \\nloaded by DataLoader with information from the DEAL_CUST_GROUPS record type.  \"),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 28}, page_content=\"Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 13 \\nNote: Customer group activation can be setup by using \\neither deal triggers (CUSTGROUP:<customer group>) or \\nrecords in the prc_deal_cust_groups table. Historically, the \\nprc_deal_cust_groups table was first introduced to support \\nconditional activation of a deal based on criteria and it is \\nexposed through the DataLoader for integration with other \\nsystems. Deal triggers, on the other hand, are the evolution \\nof a criteria-based approach in a unified and consistent \\nmanner. When loading prc_deal_cust_groups records, \\nXstore will convert them to triggers. However, because there \\nare other systems that utilize the prc_deal_cust_groups \\nrecords removing the table and the associated functionality \\nis problematic. Using triggers is slightly more flexible, since it \\nis possible to activate a deal when a customer does not \\nbelong to a specific group instead of listing all groups \\nexplicitly, but using prc_deal_cust_groups is easier and \\nmore straightforward. Using deal triggers to set up customer \\ngroup activation is recommended, for more information see \\nDeal 5A: Group Membership Triggers a Deal. \\n▪ dsc_coupon_xref — This table contains valid coupon numbers for coupon deals. \\nThis table is loaded by DataLoader with information from the COUPON_XREF rec ord \\ntype \\n▪ prc_deal_loc- This table maps a deal to a retail location. Each deal can be mapped \\nto several rtl_loc_id values if the deal is valid for several retail locations. This table is \\nloaded by DataLoader with information from the DEAL, FREE_GIFTCARD, RE BATE, \\nor COUPON_DEAL record types. \\nprc_deal_trig Table \\nThe prc_deal_trig table defines many-to-one relationships with the primary deal table. For \\neach deal there may be any number of triggers (or none). \\nNote: The prc_deal_trig table is loaded by DataLoader with \\ninformation from the DEAL_TRIGGER record type or the \\nDEAL_TRIGGER_EXCLUDE record type. \\nA description of each field in the prc_deal_trig table follows: \\nTable 1-5: prc_deal_trig \\nField Definition \\norganization_id A unique identifier for a company, association, \\ninstitution, or other enterprise of interest to a \\nretail store or retail enterprise. \\ndeal_id  The unique identifier for a deal. Corresponds to \\nprc_deal.deal_id. \\ndeal_trigger  The identifier for the deal trigger.  \\nFor example, to tie a deal to a coupon, create \\nan entry here in the form \\n“COUPON:STORE_COUPON:1234” where \\ndsc_coupon_xref.coupon_type = \\n'STORE_COUPON' and \\ndsc_coupon_xref.coupon_serial_nbr = '1234'.  \"),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 29}, page_content=\"Deal Pricing Tables \\n14 \\nField Definition \\norg_code Specifies the organization level code based on \\nthe customer's store structure. For example: \\nSTORE, DISTRICT, REGION, or CHAIN. (to be \\ndefined by clients) \\nDefault value set to * \\norg_value Specifies the value for the organization level \\ncode. For example: for store 123, the org_code \\nwill be STORE and the org_value will be 123) \\nDefault value set to * \\ncreate_date  The date the record was created. \\ncreate_user_id The identifier of the person who created the \\nrecord. \\nupdate_date  The date the record was updated. \\nupdate_user_id The identifier of the person who updated the \\nrecord. \\nrecord_state The record status. \\nprc_deal_document_xref Table \\nThe prc_deal_document_xref table contains information defining the relationship between \\na deal and a document definition. \\nNote: The prc_deal_document_xref table is loaded by \\nDataLoader with information from the REBATE and \\nFREE_GIFTCARD record types. (Fields 16 and 17). \\nA description of each field in the prc_deal_document_xref table follows: \\nTable 1-6: prc_deal_document_xref \\nField Definition \\norganization_id A unique identifier for a company, association, \\ninstitution, or other enterprise of interest to a \\nretail store or retail enterprise. \\ndeal_id  The unique identifier for a deal. Corresponds to \\nprc_deal.deal_id. \\nseries_id An identifier for a specific run of documents. \\ndocument_type  Identifier for the type of document. \\n(BOUNCEBACK, THANKYOU, REBATE, etc.). \\norg_code Specifies the organization level code based on \\nthe customer's store structure. For example: \\nSTORE, DISTRICT, REGION, or CHAIN. (to be \\ndefined by clients) \\nDefault value set to * \\norg_value Specifies the value for the organization level \\ncode. For example: for store 123, the org_code \\nwill be STORE and the org_value will be 123) \\nDefault value set to * \"),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 30}, page_content=\"Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 15 \\nField Definition \\ncreate_date  The date the record was created. \\ncreate_user_id The identifier of the person who created the \\nrecord. \\nupdate_date  The date the record was updated. \\nupdate_user_id The identifier of the person who updated the \\nrecord. \\nrecord_state  The record status. \\nprc_deal_cust_groups Table \\nThe prc_deal_cust_groups table contains information for mapping a deal to a customer \\ngroup. \\nNote: The prc_deal_cust_groups table is loaded by \\nDataLoader with information from the \\nDEAL_CUST_GROUPS record type. \\nA description of each field in the prc_deal_cust_groups table follows: \\nTable 1-7: prc_deal_cust_groups \\nField Definition \\norganization_id A unique identifier for a company, association, \\ninstitution, or other enterprise of interest to a \\nretail store or retail enterprise. \\ndeal_id  The unique identifier for a deal. Corresponds to \\nprc_deal.deal_id. \\ncust_group_id  A unique identification number assigned to a \\ncustomer group. This is the customer group to \\nwhich the customer must belong to be eligible \\nfor the deal specified by deal_id. \\norg_code Specifies the organization level code based on \\nthe customer's store structure. For example: \\nSTORE, DISTRICT, REGION, or CHAIN. (to be \\ndefined by clients) \\nDefault value set to * \\norg_value Specifies the value for the organization level \\ncode. For example: for store 123, the org_code \\nwill be STORE and the org_value will be 123) \\nDefault value set to * \\ncreate_date  The date the record was created. \\ncreate_user_id The identifier of the person who created the \\nrecord. \\nupdate_date  The date the record was updated. \\nupdate_user_id The identifier of the person who updated \\nthe record. \\nrecord_state The record status. \"),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 31}, page_content=\"Deal Pricing Tables \\n16 \\nprc_deal_loc Table \\nThe prc_deal_loc-table maps a deal to a retail location. Each deal can be mapped to \\nseveral rtl_loc_id values if the deal is valid for several retail locations. \\nNote: This table is loaded by DataLoader with information \\nfrom the DEAL, FREE_GIFTCARD, REBATE, or \\nCOUPON_DEAL record types. \\nA description of each field in the prc_deal_loc table follows: \\nTable 1-8: prc_deal_loc Table \\nField: Definition: \\norganization_id (PK) A unique identifier for a company, association, \\ninstitution, or other enterprise of interest to a \\nretail store or retail enterprise. \\ndeal_id (PK) The unique identifier for a deal. Corresponds to \\nprc_deal.deal_id. \\nrtl_loc_id (PK) The retail location for which the deal is valid. \\ncreate_date The date this record was created. \\ncreate_user_id The identifier of the person that created this \\nrecord. \\nupdate_date The date this record was updated. \\nupdate_user_id The identifier of the person that updated this \\nrecord. \\nrecord_state The record status. \\ndsc_coupon_xref Table \\nThe dsc_coupon_xref table contains information about how a particular coupon should be \\nprocessed; tender or discount. This coupon type relates to manually applied discounts. If \\nno tndr_id or discount_code is specified, it will be interpreted as a deal coupon, a \\ntrl_coupon_lineitm entry will be created and deal trigger will be added to the transaction. \\nTo tie a deal to a coupon, create an entry in prc_deal_trig in the form \\n“COUPON:STORE_COUPON:1234” where dsc_coupon_xref.coupon_type = \\n'STORE_COUPON' and dsc_coupon_xref.coupon_serial_nbr = '1234'. \\nNote: The dsc_coupon_xref table is loaded by DataLoader \\nwith information from the COUPON_XREF record type. \\nA description of each field in the dsc_coupon_xref table follows: \\nTable 1-9: dsc_coupon_xref Table \\nField Definition \\norganization_id A unique identifier for a company, association, \\ninstitution, or other enterprise of interest to a \\nretail store or retail enterprise. \\ncoupon_serial_nbr The serial number of the coupon. \"),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 32}, page_content=\"Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 17 \\nField Definition \\norg_code Specifies the organization level code based on \\nthe customer's store structure. For example: \\nSTORE, DISTRICT, REGION, or CHAIN. (to be \\ndefined by clients) \\nDefault value set to * \\norg_value Specifies the value for the organization level \\ncode. For example: for store 123, the org_code \\nwill be STORE and the org_value will be 123) \\nDefault value set to * \\ndiscount_code A code which uniquely identifies a discount. \\nNote: A value must be specified for either \\ndiscount_code or tndr_id. \\ntndr_id A code which uniquely identifies the tender. \\n(From tnd_tender.tndr_id). For example: \\nCORP_COUPON, \\nMANUFACTURER_COUPON \\nNote: A value must be specified for either \\ndiscount_code or tndr_id. \\ncoupon_type A code for the type of coupon. For example, \\nSTORE_COUPON.  \\neffective_date The date and time the coupon may be applied. \\nexpiration_date The date and time after which the coupon is no \\nlonger valid. \\nserialized_flag If true, this is a serialized coupon type. \\ncreate_date  The date the record was created. \\ncreate_user_id The identifier of the person who created the \\nrecord. \\nupdate_date  The date the record was updated. \\nupdate_user_id The identifier of the person who updated the \\nrecord. \\nrecord_state  The record status. \\nupdate_user_id The identifier of the person who updated the \\nrecord. \\nrecord_state  The record status. \\nXML Configuration \\nDeal Engine configurable caching is used to configure the amount of data cached by the \\nOracle Retail Xstore Point of Service Deal Engine to improve performance. Controlling \\nthe number of Deal Engine results prevents multiple runs of the Deal Engine while \\ntendering. \\nDeal Engine configurable resorting algorithms are used to configure the Deal Engine item \\nsorting algorithms. \\nPricing.xml \\nSet up the following configuration for Deal Engine processing in pricing.xml: \"),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 33}, page_content='Deal Pricing Tables \\n18 \\nCacheSize - Valid value is any non-negative integer; however, for best results, do not \\nexceed a cache size greater than 8. The default value is set to 0. When set to 0, no result \\nwill be cached. \\nUseDealResorting - This configuration controls whether or not the deal resorting and item \\nresorting algorithms that run the Deal Engine multiple number of times are used. \\nDeal Pricing Processing Overview \\nThis section describes the processes for deal pricing. \\nWhen an item is entered in a transaction, Oracle Retail Xstore Point of Service uses the \\nregister’s business date and time to determine if a promotional price is in effect. \\nThe promotional price is used if the business date and time are greater than or equal to \\nthe promo effective date and time, and less than the promo expiration date and time. \\nOracle Retail Xstore Point of Service calculates the possible deals and/or discounts from \\npredefined deal types each time an item is added or deleted, or a change to an item is \\nperformed. \\nDuring deal processing, the Deal Engine checks every possible deal eligible for a \\ntransaction in order to apply the best available deal in the customer’s favor. Refer to \\n“Deal Best Pricing” for more information about best deal processing. \\nThe Dealspace \\nThe deal refresh strategies aggregate all deals from their sources into the dealspace. The \\ndealspace is recalculated at three different times:  \\n▪ At refresh time: Remove all deals which are not applicable on the current day, \\nlocation, and so on.  \\n▪ At transaction start/resume: Remove all deals which are not applicable at the current \\ntime, for the current customer, and so on.  \\n▪ At line item contents change: Remove all deals which require items or \\nminimum/maximum requirements which have not been met. \\n  '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 34}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 19 \\nImportant: About SQL Server... \\nSQL server does not provide data types for storing the date \\nexclusively or the time exclusively. In Microsoft SQL server, \\nonly a DATETIME data type is supported. In Oracle SQL \\nserver, the data type is TIMESTAMP.  \\nFor this reason, the date fields (that is, effective_date and \\nend_date fields) include a time in addition to the date.  \\nThe time fields (that is, start_time and end_time) include a \\ndate in addition to the time; however, the date component is \\nignored by Oracle Retail Xstore Point of Service. \\nFlow Overview \\n1. Oracle Retail Xstore Point of Service loads deals (DTX objects) during startup. \\n2. Oracle Retail Xstore Point of Service maintains a “shadow transaction” by \\nsubscribing to a set of important events. \\n3. Oracle Retail Xstore Point of Service fills the dealspace and applies filters using \\nRefreshStrategy. \\n4. Oracle Retail Xstore Point of Service runs calculators on TransactionModified signal. \\n5. Oracle Retail Xstore Point of Service zeroes out existing DEAL modifiers. \\n6. Oracle Retail Xstore Point of Service calls the Deal Engine and provides items and \\ndeals to it. \\n7. Deal Engine removes ineligible items. \\n8. Deal Engine removes deals that cannot be satisfied due to lack of items. \\n9. Deal Engine sorts deals. \\n10. Deal Engine sorts items by descending price. \\n11. Deal Engine starts a “bruteforce” phase. \\n12. Deal Engine recursively goes down through a stack. \\n13. Deal Engine tries to apply a deal as many times as it can and stores the result. \\n14. Deal Engine goes up the stack, applies a deal, goes down and tries to apply a deal \\nas many times at it can. \\n15. Deal Engine applies a deal by calling isEligible() and apply() if the previous call \\nreturned true. \\n16. If needed, Deal Engine goes higher and traverses up and down as needed until it \\nchecks all combinations. \\n17. Every time Deal Engine applies the lowest level deal it checks if the result is better \\nthan the stored value and updates the stored value if it is. \\n18. Deal Engine starts a “replay” phase. \\n19. Deal Engine reruns the deals that produced the best result again and creates a \\nResult. \\n20. Deal Engine returns the Result to Oracle Retail Xstore Point of Service. \\n21. Oracle Retail Xstore Point of Service unpacks Result and applies discounts to items \\nby either updating existing price modifiers or creating new. \\n \\n  \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 35}, page_content=''),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 36}, page_content=' \\nOracle Retail Xstore Point of Service Deal Pricing Guide 21 \\n2 \\nLine Item Deals \\nOverview \\nThis chapter provides Line Item deal type examples and a few variation examples for \\neach deal. Line item deals are discounts automatically applied to an item based on the \\nstandard item price, such as a new price, a discount by amount, or a discount by percent.  \\nLine Item deals can also be set up to use an item attribute to define the criteria for a \\ndeal trigger so that deals can be set up based on customer-specific item variables or \\ncharacteristics. To use an item attribute for a deal, set prc_deal_field_test.item_field with \\nITEM_PROPERTY:(property name) in the download file. See “Using Item Properties“ for \\nmore information.  \\n▪ There are three different types of discounts which can be applied to an item in a deal. \\nThese values are set up in the prc_deal_item table and include the following: \\n– Amount off [CURRENCY_OFF] \\n– Price change [NEW_PRICE] \\n– Percent off [PERCENT_OFF] \\nLine Item Deal Setup Examples \\nItem Price Adjustment \\nIn this deal type, a defined deal price is substituted for the original item price. (See “Item \\nPrice Adjustment Deal Examples”. \\nThree examples are provided for this deal type: \\n▪ “Line Item Deal 1A: Get $3 off each white tennis skirt (item 1010)” in “prc_deal Table: \\nLine Item Deals 1A, 1B, and 1C” \\n▪ “Line Item Deal 1B: Get a white tennis skirt (item 1010), normally priced at $17.95, for \\nonly $9 (limit 1 discount per transaction)” in “prc_deal_field_test Table: Line Item \\nDeals 1A, 1B, and 1C” \\n▪ “Line Item Deal 1C: Get $3 off any sports apparel (MERCHLEVEL1 25003)” in \\n“prc_deal Table: Line Item Deals 1A, 1B, and 1C” \\nQuantity Threshold Discount Deals \\n▪ In this deal type, once the minimum sale quantity has been reached, the new price is \\nassigned to the item(s). (See “Quantity Threshold Deal Examples”) \\nThree examples are provided for this deal type: \\n▪ “Line Item Deal 2A: Buy 3 hats (MERCHLEVEL1 25005) for $15 (Limit 3)” in \\n“prc_deal Table: Line Item Deals 2A, 2B, and 2C” \\n▪ “Line Item Deal 2B: Buy 3 hats (MERCHLEVEL1 25005) for $15 each” in \\n“prc_deal_field_test Table: Line Item Deals 2A, 2B, and 2C” \\n▪ “Line Item Deal 2C: Buy 3 hats (MERCHLEVEL1 25005) and receive 50% off of \\neach” in “prc_deal_item Table: Line Item Deals 2A, 2B, and 2C” \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 37}, page_content='Line Item Deals \\n22 \\nMix and Match Pricing: Compound (AND/OR) Deals \\nIn this deal type, purchase any item belonging to a defined group of items at full price and \\nget a discounted price on another item belonging to the same or a different group. This \\ndeal type includes the “Gift With Purchase” deal where the customer buys X and gets Y \\nfree. (See “Mix and Match Pricing: Compound (AND/OR) Deals Examples”. \\nSeven examples are provided for this deal type: \\n▪ “Line Item Deal 3A: Buy a red floral skirt (Item 1002) and get the matching jacket \\n(Item 1004) for free (100% off)” in “Line Item Deal 3A:Buy X item, get Y item at a \\ndiscount” \\n▪ “Line Item Deal 3B: Buy a red floral skirt (Item 1002) and its matching blouse (Item \\n1003) and get the jacket (Item 1004) for free (100% off)” in “Line Item Deal 3B: Buy X \\nAND Y, get Z at % (or $, or New Price) off” \\n▪ “Line Item Deal 3C: Buy a red floral skirt (Item 1002) and any hat (MERCHLEVEL1 \\n25005) and get the jacket (Item 1004) for only $10 (Limit 1)” in “Line Item Deal 3C: \\nMix and Match Pricing - MERCHLEVEL1 Level Trigger” \\n▪ “Line Item Deal 3D: Buy two red floral skirts (item 1002) and receive the matching \\njacket (1004) free” in “Line Item Deal 3D: Buy 2 (or more) of X and get Z at % off” \\n▪ “Line Item Deal 3E: Buy a red floral skirt (item 1002) and get a second red floral skirt \\n50% off” in “Line Item Deal 3E: Buy X, get Y% off another” \\n▪ “Line Item Deal 3F: Buy a red floral skirt (Item 1002) or a matching blouse (item \\n1003) and get a jacket (Item 1004) for free (100% off)” in “Line Item Deal 3F: Buy X \\nOR Y and get Z at % off” \\n▪ “Line Item Deal 3G: Buy non-clearance/non-discounted item from MERCHLEVEL1 \\n25003, get 10% off item” in “Line Item Deal 3G: Buy item from MERCHLEVEL1 X \\n(excluding clearance items and discounted items), get Y% off” \\nDeals Using Item Properties as Parameters \\nWith this deal type, an item attribute can be used to define the criteria for a deal trigger so \\nthat deals can be set up based on customer-specific item variables or characteristics. \\nOne example is provided for this deal type: \\n▪ “Item Properties Deal 4: Get 5% off items older than 15 days” in “Deal 4: Item \\nProperties Deal” '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 38}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 23 \\nItem Price Adjustment Deal Examples \\nIn this deal type, customers automatically receive an item discount when they purchase \\nthe specified item. Examples 1A, 1B, and 1C have been defined side-by-side in the \\ntables below to demonstrate the subtle differences between the deal setup requirements.  \\nLine Item Deals 1A, 1B, and 1C: Buy X item and get $Y (or %) off the item \\n▪ Line Item Deal 1A: Get $3 off each white tennis skirt (item 1010) \\n▪ Line Item Deal 1B: Get a white tennis skirt (item 1010), normally priced at $17.95, \\nfor only $9 (limit 1 discount per transaction) \\n▪ Line Item Deal 1C: Get $3 off any sports apparel (MERCHLEVEL1 25003) \\nNote: The award discount type of %-Off, $-Off, or New Price \\nfor an item is determined by the value in the deal_action field \\nof the prc_deal_item table. The items a discount will apply to \\nare determined by the values in the item_field, match_rule, \\nvalue1, and value2 fields in the prc_deal_field_test table. \\nprc_deal Table: Line Item Deals 1A, 1B, and 1C \\n \\nTable 2-1: prc_deal Table Setup for Item Price Substitution Deals 1A, 1B, and 1C \\nField Deal LI 1A \\nValue  \\nDeal LI 1B \\nValue \\nDeal LI 1C \\nValue  \\norganization_id 1 1 1 \\ndeal_id LI_1A LI_1B LI_1C \\ndescription $3 off Tennis Skirt Tennis Skirt for $9, \\nLimit 1 @ deal price \\n$3 off Dpt 25003 \\nconsumable FALSE(0) FALSE(0) FALSE(0) \\nact_deferred FALSE(0) FALSE(0) FALSE(0) \\neffective_date Null Null Null \\nend_date Null Null Null \\nstart_time Null Null Null \\nend_time Null Null Null \\ngenerosity_cap -1.000000 -1.000000 -1.000000 \\niteration_cap -1 1 -1 \\npriority_nudge 0 0 0 \\nsubtotal_min Null Null Null \\nsubtotal_max Null Null Null \\ntrwide_action Null Null Null \\ntrwide_amount Null Null Null \\ntaxability_code Null Null Null \\norg_code * * * '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 39}, page_content='Line Item Deals \\n24 \\nField Deal LI 1A \\nValue  \\nDeal LI 1B \\nValue \\nDeal LI 1C \\nValue  \\norg_value * * * \\npromotion_id Null Null Null \\nhigher_nonaction_amt_flag FALSE(0) FALSE(0) FALSE(0) \\nexclude_price_override_flag FALSE(0) FALSE(0) FALSE(0) \\nexclude_discounted_flag FALSE(0) FALSE(0) FALSE(0) \\ntargeted_flag FALSE(0) FALSE(0)  FALSE(0) \\nweek_sched_flag FALSE(0) FALSE(0)  FALSE(0) \\nsort_order 0 0 0 \\ntype Null Null Null \\nprc_deal_field_test Table: Line Item Deals 1A, 1B, and 1C \\n \\nTable 2-2: prc_deal_field_test Table Setup for Item Price Substitution Deals 1A, 1B, and 1C \\nField Deal LI 1A \\nValue  \\nDeal LI 1B \\nValue  \\nDeal LI 1C \\nValue  \\norganization_id 1 1 1 \\ndeal_id LI_1A LI_1B LI_1C \\nitem_ordinal 1 1 1 \\nitem_condition_seq 1 1 1 \\norg_code * * * \\norg_value * * * \\nitem_condition_group 1 1 1 \\nitem_field SKU SKU MERCHLEVEL1 \\nmatch_rule EQUAL EQUAL EQUAL \\nvalue1 1010 1010 25003 \\nvalue2 Null  Null  Null  '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 40}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 25 \\nprc_deal_item Table: Line Item Deals 1A, 1B, and 1C \\n \\nTable 2-3: prc_deal_item Table Setup for Item Price Substitution Deals 1A, 1B, and 1C \\nField Deal LI 1A \\nValue \\nDeal LI 1B \\nValue \\nDeal LI 1C \\nValue  \\norganization_id 1 1 1 \\ndeal_id LI_1A LI_1B LI_1C \\nitem_ordinal 1 1 1 \\norg_code * * * \\norg_value * * * \\nconsumable TRUE(1)  TRUE(1)  TRUE(1)  \\nqty_min 1.0000  1.0000  1.0000  \\nqty_max 0.0000  1.0000 0.0000 \\nmin_item_total Null  Null Null \\ndeal_action CURRENCY_OFF  NEW_PRICE CURRENCY_OFF \\naction_arg 3.000000 9.000000 3.000000 \\naction_arg_qty Null  Null  Null \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 41}, page_content='Line Item Deals \\n26 \\nQuantity Threshold Deal Examples \\nIn this deal type, item discounts are given when a customer buys multiples of items which \\nmeet the same qualifying criteria, and then receives a discount which affects all of the \\nitems. Examples 2A, 2B, and 2C have been defined side-by-side in the tables below to \\ndemonstrate the subtle differences between the deal setup requirements.  \\nLine Item Deals 2A, 2B, and 2C: Buy X item qty for $Y (or %/$ off each) \\n▪ Line Item Deal 2A: Buy 3 hats (MERCHLEVEL1 25005) for $15 (Limit 3) \\n▪ Line Item Deal 2B: Buy 3 hats (MERCHLEVEL1 25005) for $15 each \\n▪ Line Item Deal 2C: Buy 3 hats (MERCHLEVEL1 25005) and receive 50% off of each \\nNote: The qualifying items to which a discount applies are \\ndetermined by the values in the item_field, match_rule, \\nvalue1, and value2 fields in the prc_deal_field_test table. \\nThe following prc_deal_item table fields define the deal to be \\napplied:  \\n-  qty_min - determines the item purchase quantity \\nrequired to trigger the deal \\n-  action_arg_qty - determines the total number of items to \\nwhich the deal action applies \\n-  deal_action - determines the award discount type of % \\nOff, $ Off, or New Price \\nprc_deal Table: Line Item Deals 2A, 2B, and 2C \\n \\nTable 2-4: prc_deal Table Setup for Quantity Threshold Deals 2A, 2B, and 2C \\nField Deal LI 2A \\nValue \\nDeal LI 2B \\nValue  \\nDeal LI 2C \\nValue \\norganization_id 1 1 1 \\ndeal_id LI_2A LI_2B LI_2C \\norg_code * * * \\norg_value * * * \\ndescription Buy 3 hats, Dept \\n25005 for $15 (Limit \\n3) \\nBuy 3 hats, Dept \\n25005 for $15 each \\nBuy 3 hats, Dept \\n25005, get 50% off \\neach \\nconsumable FALSE(0) FALSE(0) FALSE(0) \\nact_deferred FALSE(0) FALSE(0) FALSE(0) \\neffective_date Null Null Null \\nend_date Null Null Null \\nstart_time Null Null Null \\nend_time Null Null Null \\ngenerosity_cap -1.000000 -1.000000 -1.000000 \\niteration_cap 1 -1 -1 '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 42}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 27 \\nField Deal LI 2A \\nValue \\nDeal LI 2B \\nValue  \\nDeal LI 2C \\nValue \\npriority_nudge 0 0 0 \\nsubtotal_min Null Null Null \\nsubtotal_max Null Null Null \\ntrwide_action Null Null Null \\ntrwide_amount Null Null Null \\ntaxability_code Null Null Null \\npromotion_id Null Null Null \\nhigher_nonaction_amt_flag FALSE(0) FALSE(0) FALSE(0) \\nexclude_price_override_flag FALSE(0) FALSE(0) FALSE(0) \\nexclude_discounted_flag FALSE(0) FALSE(0) FALSE(0) \\ntargeted_flag FALSE(0) FALSE(0) FALSE(0) \\nweek_sched_flag FALSE(0) FALSE(0) FALSE(0) \\nsort_order 0 0 0 \\ntype Null Null Null \\nprc_deal_field_test Table: Line Item Deals 2A, 2B, and 2C \\n \\nTable 2-5: prc_deal_field_test Table Setup for Quantity Threshold Deals 2A, 2B, and 2C \\nField Deal LI 2A \\nValue  \\nDeal LI 2B \\nValue \\nDeal LI 2C \\nValue \\norganization_id 1 1 1 \\ndeal_id LI_2A LI_2B LI_2C \\nitem_ordinal 1 1 1 \\nitem_condition_seq 1 1 1 \\norg_code * * * \\norg_value * * * \\nitem_condition_group 1 1 1 \\nitem_field MERCHLEVEL1 MERCHLEVEL1 MERCHLEVEL1 \\nmatch_rule EQUAL EQUAL EQUAL \\nvalue1 25005 25005 25005 \\nvalue2 Null  Null  Null  \\nprc_deal_item Table: Line Item Deals 2A, 2B, and 2C \\n \\nTable 2-6: prc_deal_item Table Setup for Quantity Threshold Deals 2A, 2B, and 2C '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 43}, page_content='Line Item Deals \\n28 \\nField Deal LI 2A \\nValue \\nDeal LI 2B \\nValue \\nDeal LI 2C \\nValue \\norganization_id 1 1 1 \\ndeal_id LI_2A LI_2B LI_2C \\nitem_ordinal 1 1 1 \\norg_code * * * \\norg_value * * * \\nconsumable TRUE(1)  TRUE(1)  TRUE(1)  \\nqty_min 3.0000  3.0000 3.0000  \\nqty_max 3.0000  0.0000  0.0000 \\nmin_item_total Null  Null  Null  \\ndeal_action NEW_PRICE  NEW_PRICE  PERCENT_OFF  \\naction_arg 15.000000 15.000000 50.000000 \\naction_arg_qty  3.0000 1.0000 1.0000 '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 44}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 29 \\nMix and Match Pricing: Compound (AND/OR) Deals Examples \\nIn this deal type, a customer receives a specified item at a discount when an item \\nbelonging to a defined group of items is purchased at full price. The deal is triggered by \\nthe purchase of a specific item and the award (discount) is applied to a different item or \\nitems. Eight variations of this deal type are documented in this section. \\nLine Item Deal 3A:Buy X item, get Y item at a discount \\n▪ Line Item Deal 3A: Buy a red floral skirt (Item 1002) and get the matching jacket \\n(Item 1004) for free (100% off) \\nprc_deal Table: Deal 3A \\n \\nTable 2-7: prc_deal Table Setup for Mix and Match Pricing Deal 3A \\nField Deal LI 3A \\nValue  \\norganization_id 1 \\ndeal_id LI_3A \\ndescription Buy skirt and get jacket free \\nconsumable FALSE(0) \\nact_deferred FALSE(0) \\neffective_date Null \\nend_date Null \\nstart_time Null \\nend_time Null \\ngenerosity_cap -1.000000 \\niteration_cap -1 \\npriority_nudge 10 \\nsubtotal_min Null \\nsubtotal_max Null \\ntrwide_action Null \\ntrwide_amount Null \\ntaxability_code Null \\norg_code * \\norg_value * \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag FALSE(0) \\ntargeted_flag FALSE(0) '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 45}, page_content='Line Item Deals \\n30 \\nField Deal LI 3A \\nValue  \\nweek_sched_flag FALSE(0) \\nsort_order 0 \\ntype Null \\nprc_deal_field_test Table: Deal 3A \\n \\nTable 2-8: prc_deal_field_test Table Setup for Mix and Match Pricing Deal 3A \\nField Deal LI 3A \\nValue (red floral skirt) \\nDeal LI 3A \\nValue (red floral jacket) \\norganization_id 1 1 \\ndeal_id LI_3A LI_3A \\nitem_ordinal 1 2 \\nitem_condition_seq 1 1 \\norg_code * * \\norg_value * * \\nitem_condition_group 1 1 \\nitem_field SKU SKU \\nmatch_rule EQUAL EQUAL \\nvalue1 1002 1004 \\nvalue2 Null  Null  \\nprc_deal_item Table: Deal 3A \\n \\nTable 2-9: prc_deal_item Table Setup for Mix and Match Pricing Deal 3A \\nField Value LI 3A (Skirt -\\nordinal of 1) \\nValue LI 3A (Jacket-\\nordinal of 2) \\norganization_id 1 1 \\ndeal_id LI_3A LI_3A \\nitem_ordinal 1 2 \\norg_code * * \\norg_value * * \\nconsumable TRUE(1)  TRUE(1)  \\nqty_min 1.0000  1.0000 \\nqty_max 1.0000  1.0000 \\nmin_item_total Null  Null  '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 46}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 31 \\nField Value LI 3A (Skirt -\\nordinal of 1) \\nValue LI 3A (Jacket-\\nordinal of 2) \\ndeal_action Null PERCENT_OFF \\naction_arg Null  100.000000 \\naction_arg_qty Null  Null  \\nLine Item Deal 3B: Buy X AND Y, get Z at % (or $, or New Price) off \\nAnother variation of the Mix and Match Pricing Deal defines more than 1 trigger item \\nand an award item. \\n▪ Line Item Deal 3B: Buy a red floral skirt (Item 1002) and its matching blouse (Item \\n1003) and get the jacket (Item 1004) for free (100% off) \\nprc_deal Table: Deal 3B \\n \\nTable 2-10: prc_deal Table Setup for Mix and Match Pricing Deal 3B \\nField Deal LI 3B \\nValue \\norganization_id 1 \\ndeal_id LI_3B \\ndescription Buy skirt AND blouse, get jacket free \\nconsumable FALSE(0) \\nact_deferred FALSE(0) \\neffective_date Null \\nend_date Null \\nstart_time Null \\nend_time Null \\ngenerosity_cap -1.000000 \\niteration_cap -1 \\npriority_nudge 0 \\nsubtotal_min Null \\nsubtotal_max Null \\ntrwide_action Null \\ntrwide_amount Null \\ntaxability_code Null \\norg_code * \\norg_value * \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 47}, page_content='Line Item Deals \\n32 \\nField Deal LI 3B \\nValue \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag FALSE(0) \\ntargeted_flag FALSE(0) \\nweek_sched_flag FALSE(0) \\nsort_order 0 \\ntype Null \\nprc_deal_field_test Table: Deal 3B \\nThis table identifies the red floral skirt (Item 1002), the red floral blouse (Item 1003), and \\nthe red floral jacket (Item 1004). It assigns an item_ordinal of 1 to the skirt, an \\nitem_ordinal of 2 to the blouse, and an item_ordinal of 3 to the floral jacket. This sets up \\nthe AND condition in which the customer must purchase both the skirt AND the blouse to \\ntrigger the deal. \\n \\nTable 2-11: prc_deal_field_test Table Setup for Mix and Match Pricing Deal 3B \\nField Deal LI 3B \\nValue (red floral \\nskirt) \\nDeal LI 3B \\nValue (red floral \\nblouse) \\nDeal LI 3B \\nValue (red floral \\njacket) \\norganization_id 1 1 1 \\ndeal_id LI_3B LI_3B LI_3B \\nitem_ordinal 1 2 3 \\nitem_condition_seq 1 1 1 \\norg_code * * * \\norg_value * * * \\nitem_condition_group 1 1 1 \\nitem_field SKU SKU SKU \\nmatch_rule EQUAL EQUAL EQUAL \\nvalue1 1002 1003 1004 \\nvalue2 Null  Null  Null  \\nprc_deal_item Table: Deal 3B \\nThe prc_deal_item table setup defines that no action will be taken on the red floral skirt or \\nred floral blouse individually. \\nIn this AND condition, there must be one of each item to satisfy the deal. This table also \\nidentifies that the red floral jacket (item_ordinal 3) will receive a discount of 100% off.  \\n \\nTable 2-12: prc_deal_item Table Setup for Mix and Match Pricing Deal 3B '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 48}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 33 \\nField Deal LI 3B \\nValue  \\nSkirt- (ordinal 1)  \\nDeal LI 3B \\nValue \\nBlouse- (ordinal 2) \\nDeal LI 3B \\nValue  \\nJacket-(ordinal 3) \\norganization_id 1 1 1 \\ndeal_id LI_3B LI_3B LI_3B \\nitem_ordinal 1  2 3 \\norg_code * * * \\norg_value * * * \\nconsumable TRUE(1)  TRUE(1)  TRUE(1)  \\nqty_min 1.0000  1.0000  1.0000 \\nqty_max 1.0000 1.0000 1.0000 \\nmin_item_total Null  Null  Null  \\ndeal_action Null Null PERCENT_OFF \\naction_arg Null  Null  100.000000 \\naction_arg_qty Null  Null  Null  \\nLine Item Deal 3C: Mix and Match Pricing - MERCHLEVEL1 Level Trigger \\nAnother variation of the Mix and Match Pricing Deal specifies trigger items at the \\nMERCHLEVEL1. In example 3C below, triggers include a specific item (Item 1002) AND \\nany item from MERCHLEVEL1 25005.  \\n▪ Line Item Deal 3C: Buy a red floral skirt (Item 1002) and any hat (MERCHLEVEL1 \\n25005) and get the jacket (Item 1004) for only $10 (Limit 1) \\nprc_deal Table: Deal 3C \\n \\nTable 2-13: prc_deal Table Setup for Mix and Match Pricing Deal 3C \\nField Deal LI 3C \\nValue \\norganization_id 1 \\ndeal_id LI_3C \\ndescription Buy skirt and any hat from Dept 25005, get jacket for $10 \\nconsumable FALSE(0) \\nact_deferred FALSE(0) \\neffective_date Null \\nend_date Null \\nstart_time Null \\nend_time Null \\ngenerosity_cap -1.000000 \\niteration_cap 1 '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 49}, page_content='Line Item Deals \\n34 \\nField Deal LI 3C \\nValue \\npriority_nudge 0 \\nsubtotal_min Null \\nsubtotal_max Null \\ntrwide_action Null \\ntrwide_amount Null \\ntaxability_code Null \\norg_code * \\norg_value * \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag FALSE(0) \\ntargeted_flag FALSE(0) \\nweek_sched_flag FALSE(0) \\nsort_order 0 \\ntype Null '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 50}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 35 \\nprc_deal_field_test Table: Deal 3C \\n \\nTable 2-14: prc_deal_field_test Table Setup for Mix and Match Pricing Deal 3C \\nField Deal LI 3C \\nValue (red floral \\nskirt) \\nDeal LI 3C \\nValue (any item; \\nDept 25005) \\nDeal LI 3C \\nValue (red floral \\njacket) \\norganization_id 1 1 1 \\ndeal_id LI_3C LI_3C LI_3C \\nitem_ordinal 1 2 3 \\nitem_condition_seq 1 1 1 \\norg_code * * * \\norg_value * * * \\nitem_condition_group 1 1 1 \\nitem_field SKU MERCHLEVEL1 SKU \\nmatch_rule EQUAL EQUAL EQUAL \\nvalue1 1002 25005 1004 \\nvalue2 Null  Null  Null  \\nprc_deal_item Table: Deal 3C \\n \\nTable 2-15: prc_deal_item Table Setup for Mix and Match Pricing Deal 3C \\nField Deal LI 3C \\nValue  \\nSkirt -  \\nordinal of 1 \\nDeal LI 3C \\nValue  \\nany item; Dept 25005 -  \\nordinal of 2 \\nDeal LI 3C \\nValue  \\nJacket -  \\nordinal of 3 \\norganization_id 1 1 1 \\ndeal_id LI_3C LI_3C LI_3C \\nitem_ordinal 1 2 3 \\norg_code * * * \\norg_value * * * \\nconsumable TRUE(1)  TRUE(1)  TRUE(1)  \\nqty_min 1.0000  1.0000 1.0000 \\nqty_max 0.0000  0.0000  1.0000  \\nmin_item_total Null  Null  Null  \\ndeal_action Null Null NEW_PRICE \\naction_arg Null  Null  10.000000 \\naction_arg_qty Null  Null  Null  '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 51}, page_content='Line Item Deals \\n36 \\nLine Item Deal 3D: Buy 2 (or more) of X and get Z at % off \\nAnother variation of the Mix and Match Pricing Deal specifies an item quantity that must \\nbe purchased to receive an award item. \\n▪ Line Item Deal 3D: Buy two red floral skirts (item 1002) and receive the matching \\njacket (1004) free \\nprc_deal Table: Deal 3D \\n \\nTable 2-16: prc_deal Table Setup for Mix and Match Pricing Deal 3D \\nField Deal LI 3D \\nValue  \\norganization_id 1 \\ndeal_id LI_3D \\ndescription Buy 2 skirts and get jacket free \\nconsumable FALSE(0) \\nact_deferred FALSE(0) \\neffective_date Null \\nend_date Null \\nstart_time Null \\nend_time Null \\ngenerosity_cap -1.000000 \\niteration_cap -1 \\npriority_nudge 0 \\nsubtotal_min Null \\nsubtotal_max Null \\ntrwide_action Null \\ntrwide_amount Null \\ntaxability_code Null \\norg_code * \\norg_value * \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag FALSE(0) \\ntargeted_flag FALSE(0) \\nweek_sched_flag FALSE(0) \\nsort_order 0 \\ntype Null '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 52}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 37 \\nprc_deal_field_test Table: Deal 3D \\n \\nTable 2-17: prc_deal_field_test Table Setup for Mix and Match Pricing Deal 3D \\nField Deal LI 3D \\nValue (red floral skirt) \\nDeal LI 3D \\nValue (red floral jacket) \\norganization_id 1 1 \\ndeal_id LI_3D LI_3D \\nitem_ordinal 1 2 \\nitem_condition_seq 1 1 \\norg_code * * \\norg_value * * \\nitem_condition_group 1 1 \\nitem_field SKU SKU \\nmatch_rule EQUAL EQUAL \\nvalue1 1002 1004 \\nvalue2 Null  Null  \\nprc_deal_item Table: Deal 3D \\n \\nTable 2-18: prc_deal_item Table Setup for Mix and Match Pricing Deal 3D \\nField Deal LI 3D \\nValue \\n(Skirt-ordinal of 1) \\nDeal LI 3D \\nValue \\n(Jacket-ordinal of 2) \\norganization_id 1 1 \\ndeal_id LI_3D LI_3D \\nitem_ordinal 1 2 \\norg_code * * \\norg_value * * \\nconsumable TRUE(1)  TRUE(1)  \\nqty_min 2.0000 1.0000 \\nqty_max 2.0000 1.0000 \\nmin_item_total Null  Null  \\ndeal_action Null PERCENT_OFF \\naction_arg Null  100.000000 \\naction_arg_qty Null  Null  '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 53}, page_content='Line Item Deals \\n38 \\nLine Item Deal 3E: Buy X, get Y% off another \\nAnother variation of the Mix and Match Pricing Deal can be set up to apply when the \\ncustomer buys 1 item at the regular price and then gets a discount if a second (same) \\nitem is purchased. \\n▪ Line Item Deal 3E: Buy a red floral skirt (item 1002) and get a second red floral skirt \\n50% off \\nprc_deal Table: Deal 3E \\n \\nTable 2-19: prc_deal Table Setup for Mix and Match Pricing Deal 3E \\nField Deal LI 3E \\nValue \\norganization_id 1 \\ndeal_id LI_3E \\ndescription Buy 1 skirt, Get 2nd @ 50% Off \\nconsumable FALSE(0) \\nact_deferred FALSE(0) \\neffective_date Null \\nend_date Null \\nstart_time Null \\nend_time Null \\ngenerosity_cap -1.000000 \\niteration_cap -1 \\npriority_nudge 0 \\nsubtotal_min Null \\nsubtotal_max Null \\ntrwide_action Null \\ntrwide_amount Null \\ntaxability_code Null \\norg_code * \\norg_value * \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag FALSE(0) \\ntargeted_flag FALSE(0) \\nweek_sched_flag FALSE(0) \\nsort_order 0 \\ntype Null '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 54}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 39 \\nprc_deal_field_test Table: Deal 3E \\nThe prc_deal_field_test table identifies the red floral skirt (item 1002) twice, placing each \\none into a separate item_ordinal category. \\n \\nTable 2-20: prc_deal_field_test Table Setup for Mix and Match Pricing Deal 3E \\nField Deal LI 3E3E \\nValue  \\n(red floral skirt) \\nDeal LI 3E \\nValue  \\n(red floral skirt) \\norganization_id 1 1 \\ndeal_id LI_3E LI_3E \\nitem_ordinal 1 2 \\nitem_condition_seq 1 1 \\norg_code * * \\norg_value * * \\nitem_condition_group 1 1 \\nitem_field SKU SKU \\nmatch_rule EQUAL EQUAL \\nvalue1 1002 1002 \\nvalue2 Null  Null  \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 55}, page_content='Line Item Deals \\n40 \\nprc_deal_item Table: Deal 3E \\nThis table determines that nothing will happen to the first red floral skirt (deal_action = \\nNull), but the second one will receive 50% off. \\n \\nTable 2-21: prc_deal_item Table Setup for Mix and Match Pricing Deal 3E \\nField Deal LI 3E \\nValue  \\nDeal LI 3E \\nValue  \\norganization_id 1 1 \\ndeal_id LI_3E LI_3E \\nitem_ordinal 1 2 \\norg_code * * \\norg_value * * \\nconsumable TRUE(1)  TRUE(1)  \\nqty_min 1.0000  1.0000 \\nqty_max 1.0000 1.0000 \\nmin_item_total Null  Null  \\ndeal_action Null PERCENT_OFF \\naction_arg Null  50.000000 \\naction_arg_qty Null  Null  \\nLine Item Deal 3F: Buy X OR Y and get Z at % off \\nAnother variation of the Mix and Match Pricing Deal identifies specific items that can be \\npurchased to receive an award item. This deal type uses the OR condition.  \\n▪ To use this “or” condition, set up the trigger item values in the prc_deal_field_test \\ntable as follows: \\n– item_ordinal = same values \\n– item_condition_seq = N/A since group number values are different \\n– item_condition_group = different values \\n▪ Line Item Deal 3F: Buy a red floral skirt (Item 1002) or a matching blouse (item \\n1003) and get a jacket (Item 1004) for free (100% off) \\nprc_deal Table: Deal 3F \\n \\nTable 2-22: prc_deal Table Setup for Mix and Match Pricing Deal 3F \\nField Deal LI 3F \\nValue  \\norganization_id 1 \\ndeal_id LI_3F \\ndescription Buy skirt OR blouse and get jacket free \\nconsumable FALSE(0) '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 56}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 41 \\nField Deal LI 3F \\nValue  \\nact_deferred FALSE(0) \\neffective_date Null \\nend_date Null \\nstart_time Null \\nend_time Null \\ngenerosity_cap -1.000000 \\niteration_cap -1 \\npriority_nudge 0 \\nsubtotal_min Null \\nsubtotal_max Null \\ntrwide_action Null \\ntrwide_amount Null \\ntaxability_code Null \\norg_code * \\norg_value * \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag FALSE(0) \\ntargeted_flag FALSE(0) \\nweek_sched_flag FALSE(0) \\nsort_order 0 \\ntype Null \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 57}, page_content='Line Item Deals \\n42 \\nprc_deal_field_test Table: Deal 3F \\n \\nTable 2-23: prc_deal_field_test Table Setup for Mix and Match Pricing Deal 3F \\nField Deal LI 3F \\nValue (red floral \\nskirt) \\nDeal LI 3F \\nValue (red floral \\nblouse) \\nDeal LI 3F \\nValue (red floral \\njacket) \\norganization_id 1 1 1 \\ndeal_id LI_3F LI_3F LI_3F \\nitem_ordinal 1 1 2 \\nitem_condition_seq 1 1 1 \\norg_code * * * \\norg_level * * * \\nitem_condition_group 1 2 1 \\nitem_field SKU SKU SKU \\nmatch_rule EQUAL EQUAL EQUAL \\nvalue1 1002 1003 1004 \\nvalue2 Null  Null  Null  \\nprc_deal_item Table: Deal 3F \\n \\nTable 2-24: prc_deal_item Table Setup for Mix and Match Pricing Deal 3F \\nField Deal LI 3F \\nValue (Skirt & Blouse-ordinal \\nof 1) \\nDeal LI 3F \\nValue (Jacket-ordinal of 2) \\norganization_id 1 1 \\ndeal_id LI_3F LI_3F \\nitem_ordinal 1 2 \\norg_code * * \\norg_value * * \\nconsumable TRUE(1)  TRUE(1)  \\nqty_min 1.0000 1.0000 \\nqty_max 1.0000 1.0000 \\nmin_item_total Null  Null  \\ndeal_action Null PERCENT_OFF \\naction_arg Null  100.000000 \\naction_arg_qty Null  Null  '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 58}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 43 \\nLine Item Deal 3G: Buy item from MERCHLEVEL1 X (excluding clearance \\nitems and discounted items), get Y% off \\nAnother variation of the Mix and Match Pricing Deal specifies items that are excluded \\nas deal triggers when trigger items are defined at the non-item level (such as \\nMERCHLEVEL1). In example 3G below, items from MERCHLEVEL1 25003 with a stock \\nstatus of CLEARANCE are excluded from the deal. Any items from MERCHLEVEL1 \\n25003 that have had a discount applied will also be excluded from the deal.  \\n▪ Line Item Deal 3G: Buy non-clearance/non-discounted item from MERCHLEVEL1 \\n25003, get 10% off item \\nNote: The prc_deal_field_test.item_field value entered for an \\nexclusion relates to the value in the itm_item.stock_status \\nfield. \\nprc_deal Table: Deal 3G \\n \\nTable 2-25: prc_deal Table Setup for Mix and Match Pricing Deal 3G \\nField Deal LI 3G \\nValue \\norganization_id 1 \\ndeal_id LI_3G \\ndescription Buy item from MERCHLEVEL1 25003, get 10% off (excludes \\nclearance & discounted items) \\nconsumable FALSE(0) \\nact_deferred FALSE(0) \\neffective_date Null \\nend_date Null \\nstart_time Null \\nend_time Null \\ngenerosity_cap -1.000000 \\niteration_cap -1 \\npriority_nudge 20 \\nsubtotal_min Null \\nsubtotal_max Null \\ntrwide_action Null \\ntrwide_amount Null \\ntaxability_code Null \\norg_code * \\norg_value * \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 59}, page_content='Line Item Deals \\n44 \\nField Deal LI 3G \\nValue \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag TRUE(1) \\ntargeted_flag FALSE(0) \\nweek_sched_flag FALSE(0) \\nsort_order 0 \\ntype Null \\nprc_deal_field_test Table: Deal 3G \\n \\nTable 2-26: prc_deal_field_test Table Setup for Mix and Match Pricing Deal 3G \\nField Deal LI 3G \\nValue  \\nDeal LI 3G \\nValue  \\norganization_id 1 1 \\ndeal_id LI_3G LI_3G \\nitem_ordinal 1 1 \\nitem_condition_seq 1 2 \\norg_code * * \\norg_value * * \\nitem_condition_group 1 1 \\nitem_field MERCHLEVEL1 ITEM_STOCK_STATUS \\nmatch_rule EQUAL NOT_EQUAL \\nvalue1 25003 CLEARANCE \\nvalue2 Null  Null  \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 60}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 45 \\nprc_deal_item Table: Deal 3G \\n \\nTable 2-27: prc_deal_item Table Setup for Mix and Match Pricing Deal 3G \\nField Deal LI 3G \\nValue \\norganization_id 1 \\ndeal_id LI_3G \\nitem_ordinal 1 \\norg_code * \\norg_value * \\nconsumable TRUE(1)  \\nqty_min 1.0000  \\nqty_max 1.0000  \\nmin_item_total Null  \\ndeal_action PERCENT_OFF \\naction_arg 10.000000 \\naction_arg_qty Null  \\nLine Item Deal 3H: Multiple item qualifiers used to match an item for a \\ndeal \\n▪ Line Item Deal 3H: Get 10% off the following items: \\n– Earrings (SKU 6009) in MERCHLEVEL1 25003  \\n– Blazers (SKU 6013) in MERCHLEVEL1 25004  \\n– Clearance items, except items from Vendor 2230  \\nprc_deal Table: Deal 3H \\n \\nTable 2-28: prc_deal Table Setup for Multiple Item Qualifiers Deal 3H \\nField Deal LI 3H \\nValue \\norganization_id 1 \\ndeal_id LI_3H \\ndescription Multiple Item Qualifiers \\nconsumable FALSE(0) \\nact_deferred FALSE(0) \\neffective_date Null \\nend_date Null \\nstart_time Null '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 61}, page_content='Line Item Deals \\n46 \\nField Deal LI 3H \\nValue \\nend_time Null \\ngenerosity_cap -1.000000 \\niteration_cap -1 \\npriority_nudge 10 \\nsubtotal_min Null \\nsubtotal_max Null \\ntrwide_action Null \\ntrwide_amount Null \\ntaxability_code Null \\norg_code * \\norg_value * \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag FALSE(0) \\ntargeted_flag FALSE(0) \\nweek_sched_flag FALSE(0) \\nsort_order 0 \\ntype Null \\nprc_deal_field_test Table: Deal 3H \\nIn the prc_deal_field_test table, each different item condition group represents a \\ncondition that must be satisfied for the deal to apply.  \\nDifferent item condition groups represent OR logic. Any group that is satisfied will result \\nin the deal applying.  \\nTests that are part of the same item condition group represent AND logic. All tests within \\nan item condition group must be satisfied in order for the group to be satisfied.  \\nIn this example, item qualifiers include: \\n▪ [Earrings SKU 6009 AND MERCHLEVEL1 25003] \\n<OR>  \\n▪ [Blazers SKU 6013 AND MERCHLEVEL1 25004] \\n<OR> \\n▪ [CLEARANCE items AND not from Vendor 2230] '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 62}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 47 \\nTable 2-29: prc_deal_field_test Table Setup for Multiple Item Qualifiers Deal 3H \\nField LI 3H \\nValue  \\nLI 3H \\nValue  \\nLI 3H \\nValue  \\nLI 3H \\nValue  \\nLI 3H \\nValue  \\nLI 3H \\nValue  \\norganization_id 1 1 1 1 1 1 \\ndeal_id LI_3H LI_3H LI_3H LI_3H LI_3H LI_3H \\nitem_ordinal 1 1 1 1 1 1 \\nitem_condition \\n_seq \\n1 2 1 2 1 2 \\norg_code * * * * * * \\norg_value * * * * * * \\nitem_condition_ \\ngroup \\n1 1 2 2 3 3 \\nitem_field SKU MERCHLEVEL1 SKU MERCHLEVEL1 ITEM_ \\nSTOCK_ \\nSTATUS \\nVENDOR \\nmatch_rule EQUAL EQUAL EQUAL EQUAL EQUAL NOT_ \\nEQUAL \\nvalue1 6009 25003 6013 25004 CLEAR \\nANCE \\n2230 \\nvalue2 Null  Null  Null  Null  Null  Null  \\nprc_deal_item Table: Deal 3H \\n \\nTable 2-30: prc_deal_item Table Setup for Multiple Item Qualifiers Deal 3H \\nField Deal LI 3H \\nValue \\norganization_id 1 \\ndeal_id LI_3H \\nitem_ordinal 1 \\norg_code * \\norg_value * \\nconsumable TRUE(1)  \\nqty_min 1.0000 \\nqty_max 1.0000 \\nmin_item_total Null  \\ndeal_action PERCENT_OFF \\naction_arg 10.000000 \\naction_arg_qty Null  '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 63}, page_content='Line Item Deals \\n48 \\nUsing Item Properties \\nIn this deal type, a customer receives a discount when item attributes (properties) are \\nused as the deal criteria. Items (itm_item table) and item attributes (itm_item_properties \\ntable) must be set up in the Oracle Retail Xstore Point-of-Service database to use this \\ndeal type. \\nDeal 4: Item Properties Deal \\n▪ Item Properties Deal 4: Get 5% off items older than 15 days \\nprc_deal Table: Item Properties Deal \\n \\nTable 2-31: prc_deal Table Setup for Item Properties Deal \\nField Value \\norganization_id 1 \\ndeal_id T_TOO_OLD \\ndescription Get 5% off items older than 15 days \\nconsumable FALSE(0) \\nact_deferred FALSE(0) \\neffective_date Null \\nend_date Null \\nstart_time Null \\nend_time Null \\ngenerosity_cap -1.000000 \\niteration_cap -1 \\npriority_nudge 20 \\nsubtotal_min Null \\nsubtotal_max Null \\ntrwide_action Null \\ntrwide_amount Null \\ntaxability_code Null \\norg_code * \\norg_value * \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag FALSE(0) \\ntargeted_flag FALSE(0) \\nweek_sched_flag FALSE(0) \\nsort_order 0 '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 64}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 49 \\nField Value \\ntype Null \\nprc_deal_field_test Table: Item Properties Deal \\n \\nTable 2-32: prc_deal_field_test Table Setup for Item Properties Deal \\nField Value  \\norganization_id 1 \\ndeal_id T_TOO_OLD \\nitem_ordinal 1 \\nitem_condition_seq 1 \\norg_code * \\norg_value * \\nitem_condition_group 1 \\nitem_field ITEM_PROPERTY:AGE \\nUsed in conjunction with itm_item_properties table. Entries need \\nto be loaded into this table for the deal to apply. \\nmatch_rule GREATER \\nNote: match_rule depends on the type of the property that \\ndepends on item and property name. For example, String type \\nproperties cannot do LESS/GREATER/BETWEEN comparisons \\nand the result of these comparisons is undefined and not \\nguaranteed to be consistent. Make sure the proper comparison \\noperators are used. \\nvalue1 15 \\nNote: \\nWhen item_field = ITEM_PROPERTY, the value in this column \\nshould conform to following rules: \\nDates should be entered as: YYYY-MM-DD \\nNumbers can have only 3 significant digits after the decimal point \\nand cannot have more than 15 digits before the decimal point (be \\nmore than ~ 10 to power 14). \\nStrings with leading and trailing spaces will be trimmed. \\nNumbers that contain leading zeroes will be treated as strings. \\nvalue2 Null  \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 65}, page_content='Line Item Deals \\n50 \\nprc_deal_item Table: Item Properties Deal \\n \\nTable 2-33: prc_deal_item Table Setup for Item Properties Deal \\nField Value \\norganization_id 1 \\ndeal_id T_TOO_OLD \\nitem_ordinal 1 \\norg_code * \\norg_value * \\nconsumable TRUE(1)  \\nqty_min 1 \\nqty_max -1 \\nmin_item_total Null  \\ndeal_action PERCENT_OFF \\naction_arg 5 \\naction_arg_qty Null \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 66}, page_content=' \\nOracle Retail Xstore Point of Service Deal Pricing Guide 51 \\n3 \\nTransaction Deals \\nOverview \\nThis chapter provides Transaction deal type examples. Transaction deals are discounts \\nautomatically applied to an entire transaction based on the transaction subtotal amount. \\nThese types of deals include awards such as %-Off and $-Off at the transaction level. \\n▪ Three different types of discount actions apply to transaction-type deals. These \\nvalues are set up in the prc_deal table (trwide_action) and include the following: \\n– Price change (NEW_PRICE) \\n– Percent off (PERCENT_OFF) \\n– Amount off (CURRENCY_OFF) \\nExclusive Transaction Deals \\nImportant: Only true Transaction deals (that is, defined with \\na value in prc_deal.trwide_action) can be set up as \\nexclusive. Any deals with qualifiers (such as Merchandise \\nHierarchy Level-1-level, item-level, and so on) cannot be \\nexclusive. \\nIt is possible to designate a Transaction deal as exclusive so that customers cannot \\ncombine other deals with an exclusive deal type. This applies to Transaction deals only, \\nnot item-level deals. \\nExclusive deals are only exclusive with other exclusive deals. Any non-exclusive eligible \\ndeals will be applied to a sale transaction. FOR EXAMPLE: A retailer has set up two \\nsubtotal transaction level discounts: one is exclusive and the other is not. If both deals \\nare eligible in a transaction, then both will be applied. \\nExclusive Deals Setup \\nExclusive deals are set up by setting the consumable flag to true in the prc_deal table. \\nExclusive Deals Example \\nConsider the scenario where the following two exclusive deals have been set up:  \\nDeal 1 - Exclusive_25% off a purchase of over $1000 \\nDeal 2 - Exclusive_10% off a purchase of $500 with coupon ABC \\nWhen both deals are set up as exclusive, and assuming Deal 1 applies, then Deal 2 will \\nnot apply. This configuration prevents \"double dipping\" and allows you to limit the deal \\nawards available to customers, especially for overlapping or \"stacked\" deals that apply in \\na progression (such as Deal 1 and Deal 2 above). '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 67}, page_content='Transaction Deals \\n52 \\nTransaction Deal Setup \\nThe following Transaction Deal setup examples are described in this section:  \\nBuy $X Amount and Get Y Discount \\nPurchase items totaling X dollars or more and receive Y (%-off transaction, $-off \\ntransaction, or an item discount). See “Subtotal - Discount % or $ Off Examples”. \\nThree examples are provided for this deal type: \\n▪ “Transaction Deal 1A: Get 10% off any purchase of $25 or more” in “prc_deal Table: \\nDeal 1C” \\n▪ “Transaction Deal 1B: Get $5 off any purchase of $25 or more” in “prc_deal_field_test \\nTable: Deal 1C” \\n▪ “Transaction Deal 1C: Spend $250 or more and get one LVT Dress (SKU 1005) for \\n$10.99”in “prc_deal_item Table: Deal 1C” \\nBuy More, Get More \\nWith this deal type, the more the customer spends, the greater the discount. Tiered deals \\nsuch as this one are actually combinations of deals which are set up to work together. \\n(See “Subtotal - Tiered % or $ Off Example”. \\nOne example is provided for this deal type: \\n▪ “Transaction Deal 2: Buy $50-$99.99 in merchandise, get $10 off your purchase. Buy \\n$100-$199.99 in merchandise, get $20 off your purchase. Buy $200+ in \\nmerchandise, get $30 off your purchase” in “prc_deal Table: Transaction Deal 2”. \\nSubtotal - Discount % or $ Off Examples \\nTransaction Deals 1A and 1B: Purchase X dollars and get Y% (or $) off \\nIn these examples, both deals have been defined side-by-side in the table below to \\ndemonstrate the subtle differences between the deal setup requirements (% / $).  \\n▪ Transaction Deal 1A: Get 10% off any purchase of $25 or more \\n▪ Transaction Deal 1B: Get $5 off any purchase of $25 or more \\nNote: The award discount type of  % Off or $ Off the \\ntransaction is determined by the value in the trwide_action \\nfield of the prc_deal table: PERCENT_OFF or \\nCURRENCY_OFF. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 68}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 53 \\nprc_deal Table: Deals 1A and 1B \\n \\nTable 3-1: prc_deal Table Setup for Transaction Deals 1A and 1B: Purchase X dollars and \\nget Y% (or Y$) off \\nField Value: Trans Deal 1A Value: Trans Deal 1B \\norganization_id 1 1 \\ndeal_id T_1A T_1B \\ndescription Purchase >= $25 get 10% \\noff \\nPurchase >= $25 get $5 off \\nconsumable FALSE(0) FALSE(0) \\nact_deferred FALSE(0) FALSE(0) \\neffective_date 03/22/2013 12:00:00 AM 05/01/2013 12:00:00 AM \\nend_date 04/22/2013 12:00:00 AM 06/01/2013 12:00:00 AM \\nstart_time Null Null \\nend_time Null Null \\ngenerosity_cap -1.000000 -1.000000 \\niteration_cap 1 1 \\npriority_nudge 1 1 \\nsubtotal_min 25.000000 25.000000 \\nsubtotal_max 9999999.990000 9999999.990000 \\ntrwide_action PERCENT_OFF CURRENCY_OFF \\ntrwide_amount 10.000000 5.000000 \\ntaxability_code Null Null \\norg_code * * \\norg_value * * \\npromotion_id Null Null \\nhigher_nonaction_amt_flag FALSE(0) FALSE(0) \\nexclude_price_override_flag TRUE(1) TRUE(1) \\nexclude_discounted_flag FALSE(0) FALSE(0) \\ntargeted_flag FALSE(0) FALSE(0) \\nweek_sched_flag FALSE(0) FALSE(0) \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 69}, page_content='Transaction Deals \\n54 \\nTransaction Deal 1C: Purchase X dollars and get item Y for $Z \\nAnother variation of the Buy $X Amount and Get Y Discount defines an item that can \\nbe purchased at a fixed price discount once the transaction sub-total meets a specified \\nthreshold amount. \\n▪ Transaction Deal 1C: Spend $250 or more and get one LVT Dress (SKU 1005) for \\n$10.99 \\nprc_deal Table: Deal 1C \\n \\nTable 3-2: prc_deal Table Setup for Transaction Deal 1C: Purchase X dollars and get item Y \\nfor $Z \\nField Value \\norganization_id 1 \\ndeal_id T_1C \\ndescription Spend >= $250, get one 1005 for $10.99 \\nconsumable FALSE(0) \\nact_deferred FALSE(0) \\neffective_date 01/01/2013 12:00:00 AM \\nend_date 01/10/2013 12:00:00 AM \\nstart_time Null \\nend_time Null \\ngenerosity_cap -1.000000 \\niteration_cap 1 \\npriority_nudge 1 \\nsubtotal_min 250.000000 \\nsubtotal_max 9999999.990000 \\ntrwide_action Null \\ntrwide_amount Null \\ntaxability_code Null \\norg_code * \\norg_value * \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag FALSE(0) \\ntargeted_flag FALSE(0) \\nweek_sched_flag FALSE(0) \\nprc_deal_field_test Table: Deal 1C \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 70}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 55 \\nTable 3-3: prc_deal_field_test Table Setup for Transaction Deal 1C: Purchase X dollars and \\nget item Y for $Z \\nield Value  \\norganization_id 1 \\ndeal_id T_1C \\nitem_ordinal 1 \\nitem_condition_seq 1 \\norg_code * \\norg_value * \\nitem_condition_group 1 \\nitem_field SKU \\nmatch_rule EQUAL \\nvalue1 1005 \\nvalue2 Null  \\nprc_deal_item Table: Deal 1C \\n \\nTable 3-4: prc_deal_item Table Setup for Transaction Deal 1C: Purchase X dollars and get \\nitem Y for $Z \\nField Value \\norganization_id 1 \\ndeal_id T_1C \\nitem_ordinal 1 \\norg_code * \\norg_value * \\nconsumable TRUE(1)  \\nqty_min 1.0000 \\nqty_max 1.0000 \\nmin_item_total Null  \\ndeal_action NEW_PRICE \\naction_arg 10.990000 \\naction_arg_qty Null \\nSubtotal - Tiered % or $ Off Example \\nTiered deals such as “Buy More, Get More” are actually combinations of deals which are \\nset up to work together. An example using a dollar amount off is shown here for this deal \\ntype, however configuration for a percent-off deal uses a similar setup. In this transaction \\ndeal, a dollar-off amount is applied to each tier. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 71}, page_content='Transaction Deals \\n56 \\nTransaction Deal 2: Buy more, get more \\nNote: The award discount type of either % Off or $ Off the \\ntransaction is determined by the value in the trwide_action \\nfield of the prc_deal table: PERCENT_OFF or \\nCURRENCY_OFF. \\n▪ Transaction Deal 2: Buy $50-$99.99 in merchandise, get $10 off your purchase. Buy \\n$100-$199.99 in merchandise, get $20 off your purchase. Buy $200+ in \\nmerchandise, get $30 off your purchase. \\nprc_deal Table: Transaction Deal 2 \\n \\nTable 3-5: prc_deal Table Setup for Transaction Deal 2: Buy more, get more \\nField Value Value Value \\norganization_id 1 1 1 \\ndeal_id 2_BMGM1 2_BMGM2 2_BMGM3 \\ndescription Tiered $off Deal \\n$50-$99.99 \\nTiered $off Deal \\n$100-$199.99 \\nTiered $off Deal \\n$200+ \\nconsumable FALSE(0) FALSE(0) FALSE(0) \\nact_deferred FALSE(0) FALSE(0) FALSE(0) \\neffective_date Null Null Null \\nend_date Null Null Null \\nstart_time Null Null Null \\nend_time Null Null Null \\ngenerosity_cap -1.000000 -1.000000 -1.000000 \\niteration_cap -1 -1 -1 \\npriority_nudge 1 1 1 \\nsubtotal_min 50.000000 100.000000 200.000000 \\nsubtotal_max 99.990000 199.990000 9999 \\ntrwide_action CURRENCY_OFF CURRENCY_OFF CURRENCY_OFF \\ntrwide_amount 10.000000 20.000000 30.000000 \\ntaxability_code Null Null Null \\norg_code * * * \\norg_value * * * \\npromotion_id Null Null Null \\nhigher_nonaction_amt_flag FALSE(0) FALSE(0) FALSE(0) \\nexclude_price_override_flag FALSE(0) FALSE(0) FALSE(0) \\nexclude_discounted_flag FALSE(0) FALSE(0) FALSE(0) \\ntargeted_flag FALSE(0) FALSE(0) FALSE(0) \\nweek_sched_flag FALSE(0) FALSE(0) FALSE(0) '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 72}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 57 \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 73}, page_content=''),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 74}, page_content=' \\nOracle Retail Xstore Point of Service Deal Pricing Guide 59 \\n4 \\nMerchandise Level Subtotal Deals \\nOverview \\nThis chapter provides Merchandise Level Subtotal deal type examples.  \\nMerchandise Level Subtotal deals are discounts automatically applied to a hierarchy \\nsubtotal, such as the subtotal for a specific MERCHLEVEL1 or Merchandise Hierarchy \\nLevel-3. This differs from a transaction deal that applies a discount based on the subtotal \\nfor the entire transaction. \\nDeals Using a Merchandise Level Subtotal \\nSubtotal deals can be set up within a hierarchy level. For example, you can set up a deal \\nsuch as buy $100 in dept 10, get x. In this deal, an award is given when both a \\nminimum dollar amount AND an existing deal trigger are met. \\nThis deal type combines an existing line item deal with a merchandise level subtotal deal \\nin order to prevent a line item deal from being applied before a subtotal minimum has \\nbeen met. The award is then restricted to qualifying items. \\nFor example: \\nDeal 1 - Award 10% off when $100 is spent on merchandise in MERCHLEVEL1 A \\nDeal 2 - Award $10 off when $50 is spent on merchandise in Season WINTER  \\nDeal 3 - Award $10 off every $100 purchased in MERCHLEVEL1 29 \\nMerchandise Level Subtotal Deals  \\nIn this deal type, items may be grouped together by subtotal to get the deal. This deal \\ntype supports the following scenarios: \\n▪ Apply a discount on all qualifying items within a merchandise level after the subtotal \\nfor the merchandise level is met.  \\nFor example, the customer will get 5% off all items purchased in Dept 12345 once \\nthe subtotal for the merchandise from Dept 12345 reaches $100.  \\nTwo examples are provided for this deal type: \\n– “Deal A: Spend $100 in MERCHLEVEL1 12345 and get 5% off” in “Deal A: \\nSpend $X In MERCHLEVEL1 A, Get Y% Off” \\n– “Deal B: Spend $100 in MERCHLEVEL1 321 and get $5 off” Deal B: Spend $X In \\nMERCHLEVEL1 A Get $Y Off \\n▪ Apply the discount for every dollar amount that is spent in the Merchandise Hierarchy \\nLevel-1. \\nFor example, the customer will get $10 off every $100 purchased in MERCHLEVEL1 \\n29. In this example, the deal applies when the subtotal of the items from Dept 29 \\nreaches $100. If another item is purchased from Dept 29 that is $30, the deal does \\nnot apply. The next time the deal applies is when the subtotal for the MERCHLEVEL1 \\nreaches $200. \\nIt is recommended to setup separate deals at each break point. \\nMerchandise Level Subtotal Deal Examples \\nMerchandise Level Subtotal deals apply a discount on all qualifying items within a \\nmerchandise level after the subtotal for the merchandise level is met. In this deal type, '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 75}, page_content='Merchandise Level Subtotal Deals \\n60 \\nonce the minimum sale subtotal has been reached, the new price is assigned to the \\nitem(s). This is similar to the quantity threshold discount deals; however, in the \\nMerchandise Level Subtotal type, the item subtotal is used rather than the item quantity.  \\nDeal A: Spend $X In MERCHLEVEL1 A, Get Y% Off \\n▪ Deal A: Spend $100 in MERCHLEVEL1 12345 and get 5% off \\nprc_deal Table: Merchandise Level Subtotal Deal A \\n \\nTable 4-1: prc_deal Table Setup for Merchandise Level Subtotal Deal A \\nField Deal A \\nValue \\norganization_id 1 \\ndeal_id ML_A \\ndescription Spend $100 in MERCHLEVEL1 12345 Get 5% Off \\nconsumable FALSE(0) \\nact_deferred FALSE(0) \\neffective_date 2013-12-12 \\nend_date  2014-01-01 \\nstart_time Null \\nend_time Null \\ngenerosity_cap -1.000000 \\niteration_cap 1 \\npriority_nudge 1 \\nsubtotal_min Null \\nsubtotal_max 99999 \\ntrwide_action PERCENT_OFF \\ntrwide_amount 5.00 \\ntaxability_code Null \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag FALSE(0) \\ntargeted_flag FALSE(0) \\nweek_sched_flag FALSE(0) '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 76}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 61 \\nprc_deal_field_test Table: Merchandise Level Subtotal Deal A \\n \\nTable 4-2: prc_deal_field_test Table Setup for Merchandise Level Subtotal Deal A \\nField Deal A \\nValue \\norganization_id 1 \\ndeal_id ML_A \\nitem_ordinal 1 \\nitem_condition_seq 1 \\norg_code * \\norg_value * \\nitem_condition_group 1 \\nitem_field MERCHLEVEL1 \\nmatch_rule EQUAL \\nvalue1 12345 \\nvalue2 Null \\nprc_deal_item Table: Merchandise Level Subtotal Deal A \\n \\nTable 4-3: prc_deal_item Table Setup for Merchandise Level Subtotal Deal A \\nField Deal A \\nValue \\norganization_id 1 \\ndeal_id ML_A \\nitem_ordinal 1 \\norg_code * \\norg_value * \\nconsumable TRUE(1) \\nqty_min 1 \\nqty_max -1 \\nmin_item_total 100  \\ndeal_action Null  \\naction_arg Null  \\naction_arg_qty Null \\n \\nDeal B: Spend $X In MERCHLEVEL1 A Get $Y Off \\n▪ Deal B: Spend $100 in MERCHLEVEL1 321 and get $5 off '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 77}, page_content='Merchandise Level Subtotal Deals \\n62 \\nprc_deal Table: Merchandise Level Subtotal Deal B \\n \\nTable 4-4: prc_deal Table Setup for Merchandise Level Subtotal Deal B \\nField Deal B \\nValue \\norganization_id 1 \\ndeal_id ML_B \\ndescription Spend $100 in MERCHLEVEL1 321 Get $5 Off \\nconsumable FALSE(0) \\nact_deferred FALSE(0) \\neffective_date 2013-12-12 \\nend_date  2014-01-01 \\nstart_time Null \\nend_time Null \\ngenerosity_cap 9999 \\niteration_cap 1 \\npriority_nudge 1 \\nsubtotal_min Null \\nsubtotal_max 99999 \\ntrwide_action CURRENCY_OFF \\ntrwide_amount 5.00 \\ntaxability_code Null \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag FALSE(0) \\ntargeted_flag FALSE(0) \\nweek_sched_flag FALSE(0) \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 78}, page_content=\"Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 63 \\nprc_deal_field_test Table: Merchandise Level Subtotal Deal B \\n \\nTable 4-5: prc_deal_field_test Table Setup for Merchandise Level Subtotal Deal B \\nField Deal B \\nValue \\norganization_id 1 \\ndeal_id ML_B \\nitem_ordinal 1 \\nitem_condition_seq 1 \\norg_code * \\norg_value * \\nitem_condition_group 1 \\nitem_field MERCHLEVEL1 \\nmatch_rule EQUAL \\nvalue1 321 \\nvalue2 Null \\nprc_deal_item Table: Merchandise Level Subtotal Deal B \\nNote:  \\nFor CURRENCY_OFF deal actions, act_arg_qty will be \\nused as follows: \\n- if set to 1, each qualifying item will receive the deal (non-\\nprorated) \\n- if set to -1 or Null, deal is pro-rated among all eligible \\nitems \\nExample:  \\n- If “Spend $100 and get a $10 discount” deal... \\n- then set qty_min to “1”, set qty_max to “-1”, set \\nmin_item_total to “100.00”, and set action_arg to \\n“10.00”. In this example, $10 will be split among all \\nqualifying items, but we don't know at this time how \\nmany items the customer will buy; therefore, \\naction_arg_qty must be set to -1 or Null. \\n- if set to same values as qty_min and qty_max, the \\ndeal will be split (prorated) among the qualifying items \\n- A “0” value in qty_min allows an arbitrary amount when \\ndefining multiple item matchers. \\n- This type only needs one record entry in the \\nprc_deal_item table. \"),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 79}, page_content='Merchandise Level Subtotal Deals \\n64 \\nTable 4-6: prc_deal_item Table Setup for Merchandise Level Subtotal Deal B \\nField Deal B \\nValue \\norganization_id 1 \\ndeal_id ML_B \\nitem_ordinal 1 \\norg_code * \\norg_value * \\nconsumable TRUE(1) \\nqty_min 1 \\nqty_max 999 \\nmin_item_total 100.00 \\ndeal_action Null \\naction_arg Null \\naction_arg_qty Null \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 80}, page_content=' \\nOracle Retail Xstore Point of Service Deal Pricing Guide 65 \\n5 \\nDay and Time-Specific Deals \\nOverview \\nAny deal can be configured to define the period when the deal is in effect. In addition to \\ndefining the starting and ending dates and times for a deal, you can further define the \\ndeals to have different starting and ending times for each day of the week. \\nNote: The time components on the effective_date and the \\nend_date are used only for determining when the deal \\nbegins and when the deal ends. \\nFor example, if the prc_deal.effective_date is 2013-01-01 9:00:00 AM, then the deal will \\nnot start until Jan. 1st 2013 after 9 AM. Then, for any point in time after that date and time \\n(until the end_date), the deal will be in effect unless it is outside the time window defined \\nby the start_time and end_time. \\nAn Example: \\nIf Then \\na deal first becomes effective on \\n1/14/2013 at 9:00 AM and expires on \\n2/1/2013 at 7:00 PM \\n<and> \\non each day of the week, it first \\nbecomes effective at 12:00 PM and \\nbecomes no longer effective at 2:00 \\nPM \\nthe deal will actually not be effective on 1/14/2013 until \\n12:00 PM (as opposed to 9:00 AM) and at that time \\n(12:00 PM) every day afterwards.  \\nOn the final day of the deal — 2/1/2013 — the deal will \\nactually expire at 2:00 PM (as opposed to 7:00 PM). \\nThis deal will only be available between the hours of \\n12:00 PM and 2:00 PM on any day within the effective \\ndates. \\nIf the deal applies to all days in the week \\nIf the deal is not day-specific and applies to all days of the week, set up the following date \\nand time parameters in the prc_deal table: \\n▪ effective_date: The earliest date and time when the deal is in effect  \\n▪ end_date: The latest date and time when the deal is in effect  \\n▪ start_time: For all days between the effective and end dates and times, the earliest \\ntime of day when the deal is in effect \\n(The date component of the datetime value is ignored). \\n▪ end_time: For all days between the effective and end dates/times, the latest time of \\nday when the deal is in effect \\n(The date component of the datetime value is ignored). \\n▪ week_sched_flag: Set to FALSE (Determines whether or not Oracle Retail Xstore \\nPoint of Service looks at the prc_deal_week table for additional parameters). \\nIf the deal applies to specific day(s) in the week \\nIf a deal has different starting and ending times that apply on a specific day (or days), you \\ncan define up to seven different start/end times; one for each day of the week.  \\nNote: You only need to supply data for those days which \\ndiffer from a default baseline. For example, if a deal is \\neffective between 9:00 AM and 5:00 PM on every day except \\nSunday, you only need to provide day-specific start/end time \\ndata for Sunday. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 81}, page_content='Day and Time-Specific Deals \\n66 \\nIn the prc_deal table: \\n▪ effective_date: The earliest date and time when the deal is in effect  \\n▪ end_date: The latest date and time when the deal is in effect  \\n▪ start_time: For all days between the effective and end dates and times, the earliest \\ntime of day when the deal is in effect \\n(The date component of the datetime value is ignored). \\n▪ end_time: For all days between the effective and end dates/times, the latest time of \\nday when the deal is in effect \\n(The date component of the datetime value is ignored). \\n▪ week_sched_flag: Set to TRUE (Determines whether or not Oracle Retail Xstore \\nPoint of Service looks at the prc_deal_week table for additional parameters). \\nNote: To apply the deal only on specific days, configure the \\nprc_deal.start_time and the prc_deal.end_time with the \\nsame value, for example 01/01/1970 12:00:00 AM. \\nIn the prc_deal_week table: \\n▪ day_code: The day with different starting and ending times for the deal  \\n▪ start_time: The starting time of the deal for the given day \\n(The date component of the datetime value is ignored). \\n▪ end_time: The ending time of the deal for the given day \\n(The date component of the datetime value is ignored). \\nImportant: About SQL Server... \\nSQL server does not provide data types for storing the date \\nexclusively, or the time exclusively. In Microsoft SQL server, \\nonly a DATETIME data type is supported. In Oracle SQL \\nserver, the data type is TIMESTAMP.  \\nFor this reason, the date fields (that is, effective_date and \\nend_date fields) include a time in addition to the date.  \\nThe time fields (that is, start_time and end_time) also \\ninclude a date in addition to the time; however, the date \\ncomponent will be ignored by Oracle Retail Xstore Point of \\nService. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 82}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 67 \\nDay and Time-Specific Deal Setup \\nThis section provides examples for setting up a transaction deal that only applies on \\nspecific days, and at different times.  \\nDeal Setup Process \\n▪ Define the effective days and times: \\n– To set up the deal so that it can be applied only on a specific day/time (or \\ndays/times), set the prc_deal.start_time and the prc_deal.end_time to the same \\nvalue, for example 01/01/1970 12:00:00 AM. See “Deal TS_1” below. \\n<OR> \\n– To make the deal effective on both non-specified days of the week and on \\nspecific days/times, set the prc_deal.start_time and the prc_deal.end_time to \\ndifferent values (or Null). See “Deal TS_2”. \\n▪ Set the prc_deal.week_sched_flag to TRUE.  \\n▪ Set up the prc_deal_week table. \\nDeal TS_1 \\nThis Deal is applied ONLY on the days and times as configured in the prc_deal_week \\ntable. \\nDeal TS_1: Get 10% off any purchase of $25 or more on Tuesday, from 9:30 AM to \\n11:30 AM, and on Thursday, from 1:00 PM to 3:00 PM, in the month of March. \\nprc_deal Table: Deal TS_1 \\nIn this example, setting the start_time equal to the end_time sets up the deal to apply \\nonly on the days specified in the prc_deal_week table. \\n \\nTable 5-1: prc_deal Table Setup for Deal TS_1 \\nField Value: Deal TS_1 \\norganization_id 1 \\ndeal_id TS_1 \\ndescription Purchase >= $25 get 10% off on Tues morning \\nand Thurs afternoon \\nconsumable FALSE(0) \\nact_deferred FALSE(0) \\neffective_date 03/01/2013 12:00:00 AM \\nend_date 03/31/2013 12:00:00 AM \\nstart_time 01/01/1970 12:00:00 AM \\nend_time 01/01/1970 12:00:00 AM \\ngenerosity_cap -1.000000 \\niteration_cap 1 \\npriority_nudge 10 \\nsubtotal_min 25.000000 \\nsubtotal_max 9999999.990000 '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 83}, page_content='Day and Time-Specific Deals \\n68 \\nField Value: Deal TS_1 \\ntrwide_action PERCENT_OFF \\ntrwide_amount 10.000000 \\ntaxability_code Null \\norg_code * \\norg_value * \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag TRUE(1) \\ntargeted_flag FALSE(0) \\nweek_sched_flag TRUE(1) \\nprc_deal_week Table: Deal TS_1 \\n \\nTable 5-2: prc_deal_week Table Setup for Deal TS_1 \\nField Value: Deal TS_1 \\nTuesday \\nValue: Deal TS_1 \\nThursday \\norganization_id 1 1 \\ndeal_id TS_1 TS_1 \\nday_code TUE THU \\norg_code * * \\norg_value * * \\nstart_time 01/01/1970 9:30:00 AM 01/01/1970 1:00:00 PM \\nend_time 01/01/1970 11:30:00 AM 01/01/1970 3:00:00 PM \\nDeal TS_2 \\nThis Deal is applied on the days and times specified in the prc_deal_week table, and also \\non other days as defined in the prc_deal table. \\nFor example, you can set up a deal to be effective on weekdays during all business hours \\nand on Saturdays and Sundays only between the hours of 1:00 pm and 3:00 pm.  \\nDeal TS_2: Get 10% off any purchase of $25 or more on Saturday and Sunday \\nfrom1:00 PM to 3:00 PM, and on weekdays during normal business hours, in the month \\nof March. \\nprc_deal Table: Deal TS_2 \\nIn this example, setting the start_time and end_time to NULL sets up the deal to apply \\nduring business hours on weekdays. Then, setting up the prc_deal_week table restricts \\nthe deal to specific times on the weekend. (You can also set the start_time and end_time \\nto different times if you want to define the time the deal is effective during the week).  \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 84}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 69 \\nTable 5-3: prc_deal Table Setup for Deal TS_2 \\nField Value: Deal TS_1 \\norganization_id 1 \\ndeal_id TS_2 \\ndescription Purchase >= $25 get 10% off weekdays and \\nbetween 1 PM and 3 PM on weekends  \\nconsumable FALSE(0) \\nact_deferred FALSE(0) \\neffective_date 03/01/2013 09:00:00 AM \\nend_date 03/31/2013 09:00:00 PM \\nstart_time Null \\nend_time Null \\ngenerosity_cap -1.000000 \\niteration_cap 1 \\npriority_nudge 10 \\nsubtotal_min 25.000000 \\nsubtotal_max 9999999.990000 \\ntrwide_action PERCENT_OFF \\ntrwide_amount 10.000000 \\ntaxability_code Null \\norg_code * \\norg_value * \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag TRUE(1) \\ntargeted_flag FALSE(0) \\nweek_sched_flag TRUE(1) \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 85}, page_content='Day and Time-Specific Deals \\n70 \\nprc_deal_week Table: Deal TS_2 \\n \\nTable 5-4: prc_deal_week Table Setup for Deal TS_2 \\nField Value: Deal TS_2 \\nSaturday \\nValue: Deal TS_2 \\nSunday \\norganization_id 1 1 \\ndeal_id TS_2 TS_2 \\nday_code SAT SUN \\norg_code * * \\norg_value * * \\nstart_time 01/01/1970 1:00:00 PM 01/01/1970 1:00:00 PM \\nend_time 01/01/1970 3:00:00 PM 01/01/1970 3:00:00 PM '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 86}, page_content=' \\nOracle Retail Xstore Point of Service Deal Pricing Guide 71 \\n6 \\nDeferred Deals \\nOverview \\nA deferred deal gives the customer a benefit that can be used in a future transaction. The \\nbenefit can be provided in a number of different forms. They may include a rebate or a \\nbounceback coupon that may be redeemed after the current transaction. (A redemption \\nperiod may be defined for the deferred deal). \\nA deferred deal is always associated with a defined deal (a “deal_id” in the table \\nprc_deal) and is cross-referenced to a document that the customer receives as proof of \\nhaving earned the benefit. \\nDeferred Deal Setup \\nThis section describes a deal in which a bounceback coupon is given to a customer if the \\nrequirements of the deal are satisfied. \\n▪ Example 3: Customers receive a 10% off bounceback coupon with a sale.  \\n▪ In this example, a customer receives a coupon for 10% off their next purchase. See  \\n“Deferred Deal - Deal 3: 10% Off Bounceback Coupon With Sale” in “Deferred Deal - \\nDeal 3: 10% Off Bounceback Coupon With Sale” \\n▪ Example 4: Customers receive a 10% off bounceback coupon with a return. \\n▪ In this example, the deal examines the transaction’s subtotal to determine if it is a \\nnegative value. If that requirement is met, the transaction is a “return” and the \\ncustomer receives a deferred benefit at the end of the transaction in the form of a \\nbounceback coupon. See “Deferred Deal - Deal 4: 10% Off Bounceback Coupon \\nWith Return” in “Deferred Deal - Deal 4: 10% Off Bounceback Coupon With Return” \\nDeferred Deal - Deal 3: 10% Off Bounceback Coupon With Sale \\nprc_deal Table: Deal 3 \\n \\nTable 6-1: prc_deal Table Setup for Deal 3: Deferred Deal - 10% Off Bounceback Coupon \\nField Value: Deal 4 \\norganization_id 1 \\ndeal_id BOUNCE_BACK_1 \\ndescription 10% Bounce Back Coupon \\nconsumable FALSE(0) \\nact_deferred TRUE(1) \\neffective_date Null \\nend_date Null \\nstart_time Null \\nend_time Null \\ngenerosity_cap -1.000000 '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 87}, page_content='Deferred Deals \\n72 \\nField Value: Deal 4 \\niteration_cap 1 \\npriority_nudge 10 \\nsubtotal_min Null \\nsubtotal_max Null \\ntrwide_action PERCENT_OFF \\ntrwide_amount 10.000000 \\ntaxability_code Null \\norg_code * \\norg_value * \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag FALSE(0) \\ntargeted_flag FALSE(0) \\nweek_sched_flag FALSE(0) \\nprc_deal_document_xref Table: Deal 3 \\n \\nTable 6-2: prc_deal_document_xref Setup for Deal 3: Deferred Deal - 10% Off Bounceback \\nCoupon \\nField Value: Deal 4 \\norganization_id 1 \\ndeal_id BOUNCE_BACK_1 \\nseries_id C111 \\norg_code * \\norg_value * \\ndocument_type BOUNCE_BACK_COUPON '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 88}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 73 \\ndoc_document_definition Table: Deal 3 \\n \\nTable 6-3: doc_document_definition Table Setup for Deal 3: Deferred Deal - 10% Off \\nBounceback Coupon \\nField Value: Deal 4 \\norganization_id 1 \\nseries_id C111 \\ndocument_type BOUNCE_BACK_COUPON \\nstart_issue_date 1900-01-01 00:00:00.000 \\nend_issue_date Null \\nstart_redeem_date 1900-01-01 00:00:00.000 \\nend_redeem_date Null \\nreceipt_type Null \\nsegment_type Null \\ntext_code_value Null \\nfile_name Null \\nvendor_id Null \\ndescription Null \\norg_code * \\norg_value * \\ndoc_document_def_properties Table: Deal 3 \\n \\nTable 6-4: doc_document_def_properties for Deal 3: Deferred Deal - 10% Off Bounceback \\nCoupon \\nField Value: Deal 3 \\nRecord 1 \\nValue: Deal 3 \\nRecord 2 \\nValue: Deal 3 \\nRecord 3 \\nValue: \\nDeal 3 \\nRecord 4 \\nValue: \\nDeal 3 \\nRecord 5 \\norganizatio\\nn_id \\n1 1 1 1 1 \\ndocument_\\ntype \\nBOUNCE_BAC\\nK_COUPON \\nBOUNCE_BACK_C\\nOUPON \\nBOUNCE_BA\\nCK_COUPON \\nBOUNCE_\\nBACK_CO\\nUPON \\nBOUNCE_\\nBACK_CO\\nUPON \\nseries_id C111 C111 C111 C111 C111 \\ndoc_seq_n\\nbr \\n1 2 3 4 5 \\nproperty_c\\node \\nDISCOUNT_C\\nODE \\nSEQUENCE_TYPE MAX_DISCOU\\nNT_PERCENT \\nEXPIRE_IN\\n_HOUR \\nEXCLUDE_\\nCURRENT\\n_ITEMS \\ntype STRING STRING DECIMAL DECIMAL DECIMAL '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 89}, page_content='Deferred Deals \\n74 \\nField Value: Deal 3 \\nRecord 1 \\nValue: Deal 3 \\nRecord 2 \\nValue: Deal 3 \\nRecord 3 \\nValue: \\nDeal 3 \\nRecord 4 \\nValue: \\nDeal 3 \\nRecord 5 \\nstring_valu\\ne \\nBOUNCE_BAC\\nK_COUPON1 \\nNote: This \\nvalue \\ncorresponds to \\nan identical \\ndiscount_code \\nentry in the \\ntable \\ndsc_discount. \\nBOUNCE_BACK_C\\nOUPON_NUMBER \\nNote: This value \\nhas an identical \\ncorresponding entry \\nin the file \\nSequenceConfig.xm\\nl that specifies how \\nto generate the \\ncoupon number. \\nNull Null Null \\ndate_value Null Null Null Null Null \\ndecimal_va\\nlue \\nNull Null 0.100000 240.000000 1.000000 \\norg_code * * * * * \\norg_value * * * * * \\ndsc_discount Table: Deal 3 \\n \\nTable 6-5: dsc_discount Table Setup for Deal 3: Deferred Deal - 10% Off Bounceback \\nCoupon \\nField Value: Deal 3 \\norganization_id 1 \\ndiscount_code BOUNCE_BACK_COUPON1 \\neffective_datetime 1900-01-01 00:00:00.000 \\nexpr_datetime Null \\ntypcode BOUNCE_BACK_COUPON \\napp_mthd_code TRANSACTION \\npercentage 0.1000 \\ndescription Bounceback Coupon 10% off \\ncalculation_mthd_code  PERCENT \\nprompt Null \\nsound Null \\nmax_trans_count 1 \\nexclusive_discount_flag TRUE(1) \\nprivilege_type Null \\ndiscount Null \\ndtv_class_name dtv.xst.dao.dsc.impl.Discount \\nmin_eligible_price Null \\nserialized_discount_flag TRUE(1) '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 90}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 75 \\nField Value: Deal 3 \\ntaxability_code Null \\nmax_discount Null \\nsort_order Null \\ndisallow_change_flag FALSE(0) \\norg_code * \\norg_value * \\nDeferred Deal - Deal 4: 10% Off Bounceback Coupon With Return \\nprc_deal Table: Deal 4 \\n \\nTable 6-6: prc_deal Table Setup for Deal 4: Deferred Deal - 10% Off Bounceback  \\nCoupon With Return \\nField Value: Deal 4 \\norganization_id 1 \\ndeal_id DD_4 \\ndescription Bounceback coupon on return item \\nconsumable FALSE(0) \\nact_deferred TRUE(1) \\neffective_date Null \\nend_date Null \\nstart_time Null \\nend_time Null \\ngenerosity_cap -1.000000 \\niteration_cap 1 \\npriority_nudge 10 \\nsubtotal_min -999999999.000000 \\nsubtotal_max -0.010000 \\ntrwide_action PERCENT_OFF \\ntrwide_amount 10.000000 \\ntaxability_code Null \\norg_code * \\norg_value * \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) \\nexclude_price_override_flag FALSE(0) '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 91}, page_content='Deferred Deals \\n76 \\nField Value: Deal 4 \\nexclude_discounted_flag FALSE(0) \\ntargeted_flag FALSE(0) \\nweek_sched_flag FALSE(0) \\nNote: In the table prc_deal, the values in the subtotal_min \\nand subtotal_max columns are examined to determine if \\nthey are negative values for the transaction. If they are \\nnegative, that means the transaction must be a return and a \\nbounceback coupon is printed for the customer. \\nprc_deal_document_xref Table: Deal 4 \\n \\nTable 6-7: prc_deal_document_xref Setup for Deal 4: Deferred Deal - 10% Off Bounceback \\nCoupon With Return \\nField Value: Deal 4 \\norganization_id 1 \\ndeal_id DD_4 \\nseries_id 1111 \\norg_code * \\norg_value * \\ndocument_type BOUNCE_BACK_COUPON \\ndoc_document_definition Table: Deal 4 \\n \\nTable 6-8: doc_document_definition Table Setup for Deal 4: Deferred Deal - 10% Off \\nBounceback Coupon With Return \\nField Value: Deal 4 \\norganization_id 1 \\nseries_id 1111 \\ndocument_type BOUNCE_BACK_COUPON \\nstart_issue_date 2010-12-01 12:00:00 AM \\nend_issue_date 2015-12-30 12:00:00 AM \\nstart_redeem_date 2010-12-01 12:00:00 AM \\nend_redeem_date 2015-01-16 12:00:00 AM \\nreceipt_type Null \\nsegment_type Null \\ntext_code_value Null \\nfile_name Null '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 92}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 77 \\nField Value: Deal 4 \\nvendor_id Null \\ndescription Null \\norg_code * \\norg_value * \\ndoc_document_def_properties Table: Deal 4 \\n \\nTable 6-9: doc_document_def_properties for Deal 4: Deferred Deal - 10% Off Bounceback \\nCoupon With Return \\nField Value: Deal 4 \\nRecord 1 \\nValue: Deal 4 \\nRecord 2 \\norganization_id 1 1 \\ndocument_type BOUNCE_BACK_COUPON BOUNCE_BACK_COUPON \\nseries_id 1111 1111 \\ndoc_seq_nbr 1 2 \\nproperty_code DISCOUNT_CODE SEQUENCE_TYPE \\ntype STRING STRING \\nstring_value BOUNCE_BACK_COUPON1 \\nNote: This value corresponds \\nto an identical discount_code \\nentry in the table \\ndsc_discount. \\nBOUNCE_BACK_COUPON_NUMBER \\nNote: This value has an identical \\ncorresponding entry in the file \\nSequenceConfig.xml that specifies how \\nto generate the coupon number. \\ndate_value Null Null \\norg_code * * \\norg_value * * '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 93}, page_content='Deferred Deals \\n78 \\ndsc_discount Table: Deal 4 \\n \\nTable 6-10: dsc_discount Table Setup for Deal 4: Deferred Deal - 10% Off Bounceback \\nCoupon With Return \\nField Value: Deal 4 \\norganization_id 1 \\ndiscount_code BOUNCE_BACK_COUPON1 \\neffective_datetime 01/01/2010 12:00:00 AM \\nexpr_datetime Null \\ntypcode BOUNCE_BACK_COUPON \\napp_mthd_code TRANSACTION \\npercentage 0.1000 \\ndescription Bounceback Coupon 10% off \\ncalculation_mthd_code  PERCENT \\nprompt Null \\nsound Null \\nmax_trans_count 1 \\nexclusive_discount_flag TRUE(1) \\nprivilege_type Null \\ndiscount Null \\ndtv_class_name dtv.xst.dao.dsc.impl.Coupon \\nmin_eligible_price 0.000000 \\nserialized_discount_flag TRUE(1) \\ntaxability_code Null \\nmax_discount Null \\nsort_order Null \\ndisallow_change_flag FALSE(0) \\norg_code * \\norg_value * '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 94}, page_content=' \\nOracle Retail Xstore Point of Service Deal Pricing Guide 79 \\n7 \\nUsing Deal Triggers \\nOverview \\nA “trigger” is a requirement that must be satisfied to make a customer eligible for a \\ndefined deal. A trigger may be associated with a line item based deal or a transaction \\nbased deal. The trigger requirement is specified in the deal_trigger column of the table \\nprc_deal_trig. \\nThere are two primary reasons for using deal triggers. The first reason is to determine if a \\ncustomer is included in—or excluded from—a defined group. For example, a customer \\nmay be included in the group called EMPLOYEE. In the simplest case, a customer who is \\nin the EMPLOYEE group is eligible to receive the deal.  \\nThe second reason to use a trigger is to apply a deal associated with a coupon.  \\nIn a line item deal, the trigger requirement is evaluated by the Deal Engine along with any \\nother requirements specified by a particular deal. In the final analysis, the Deal Engine \\ndetermines whether or not a trigger-based deal should be applied. If the Deal Engine \\ndetermines that a different deal provides a greater benefit, the trigger-based deal is not \\napplied. \\nIn a transaction based deal, the trigger-based deal is usually applied independently, and \\nin addition to any other deals that may be applied by the Deal Engine. \\nDeal trigger functionality: \\n▪ Multiple triggers that belong to the same grouping represent an OR relationship. \\nExample: \\n\"customer belongs to group \\'EMPLOYEE\\' or \\'EMPLOYEE_FAMILY\\' and coupon \\'12345\\' used\" \\n▪ Logic exists for an exclusionary deal trigger. \\nExample: \\n\"customer belongs to group \\'EMPLOYEE\\' and does not belong to group \\'VIP\\' and coupon \\'12345\\' used\" \\nDeal Trigger Formats \\n▪ Normal: <trigger_group>:<trigger_data>, For example: CUSTGROUP:EMPLOYEE \\n▪ Exclusionary: <trigger_group>:~<trigger_data>, For example: \\nCUSTGROUP:~EMPLOYEE  \\nRefer to the following sections for more information about these modifications. \\nMultiple Triggers Belonging To the Same Grouping \\nDeal trigger functionality operates such that multiple triggers belonging to the same \\ngrouping represent an OR relationship. The deal is applicable if it meets all othe r criteria \\nand if the customer belongs to either group. \\nNormal trigger evaluation involves grouping all of a deal’s triggers of a given type (either \\ncustomer group affiliation or coupon presence) and checking if any trigger in the group \\nhas its condition satisfied. If any one trigger in a group has a satisfied condition, then the \\nentire group is considered to have passed. If a deal has both groups of triggers, then both \\ngroups must pass evaluation for the deal to be applicable. \\nFor example, if a deal has triggers CUSTGROUP:EMPLOYEE and \\nCUSTGROUP:EMPLOYEE_FAMILY, then the deal is applicable if it meets all other \\ncriteria, and if the customer belongs to either group. (Prior to Oracle Retail Xstore Point \\nof Service version 4.0, the customer had to belong to both groups in order to get the '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 95}, page_content='Using Deal Triggers \\n80 \\ndeal). Note that this OR functionality only applies among members of a common trigger \\ngrouping, such as “CUSTGROUP” used in this example. \\nExclusionary Deal Trigger \\nAn exclusionary trigger is one in which if its condition is satisfied, then the deal will not be \\napplied to the transaction. Exclusionary triggers have the same condition types available \\nto them as normal deal triggers: customer group affiliation and coupon presence.  \\nIf any one exclusionary deal trigger has its condition satisfied, then the entire group fails \\nevaluation and the deal will not be applicable. \\nAn exclusionary condition is represented by a tilde (~) character preceding the value \\ncomponent of the trigger. Download records can either manually include this character \\n(field #5 in the DEAL_TRIGGER record type), or instead opt for the \\nDEAL_TRIGGER_EXCLUDE record type that is identical to DEAL_TRIGGER, but inserts \\nthe tilde automatically. \\nFor example, the final trigger code (prc_deal_trig.deal_trigger) for a \"VIP group does not \\nbelong\" condition would be \"CUSTGROUP:~VIP\". \\nNote: There are no changes to the other download record \\nthat populates triggers—COUPON_DEAL—since it doesn\\'t \\nmake any sense to define a coupon deal whose sole trigger \\ncondition is “coupon 12345 was NOT used”. If complex \\ncoupon conditions involving exclusions are desired, those \\nexclusions can be accommodated by either of the \\nDEAL_TRIGGER records after the coupon deal is defined. \\nLogically, all inclusions within a common dimension (For example, all of a deal\\'s \\n\"CUSTGROUP\" triggers) will be evaluated as OR conditions. Conversely, all exclusions \\nwithin a dimension will be evaluated as AND conditions.  \\nFor example, if a customer belongs to group \"EMPLOYEE\" OR \"EMPLOYEE_FAMILY\" \\nAND does not belong to either group \"VIP\" or \"CORPORATE\";  \\ngroup = (\"EMPLOYEE\" || \"EMPLOYEE_FAMILY) && ~\"VIP\" && ~\"CORPORATE\".  \\nAs before, each dimension\\'s conditions will be separately evaluated, with the deal\\'s full \\nset of triggers satisfied only if all dimensions are satisfied (customer group conditions \\nsatisfied AND coupon conditions satisfied). \\nDeal Example: \\nIf the deal triggers are: Then the deal is applied: \\nCUSTGROUP:EMPLOYEE \\nCUSTGROUP:MANAGERS \\nCUSTGROUP:~SEASONAL_EMPLOYEE\\nS \\nCUSTGROUP:~PT_EMPLOYEES \\nCOUPON:HALF_OFF \\nCOUPON:~ADDITIONAL_HALF_OFF \\nif the current customer is a member of either the \\nEMPLOYEE or MANAGERS group, but not a \\nmember of SEASONAL_EMPLOYEES and not a \\nmember of PT_EMPLOYEES and the HALF_OFF \\ncoupon has been added to the transaction and the \\nADDITIONAL_HALF_OFF coupon has not been \\nadded to the transaction. \\nDeal Trigger Setup \\nThe minimum setup for a deal trigger is the requirement to define it in the prc_deal_trig \\ntable. This table maps the entry in the deal_id column to the same entry in the table \\nprc_deal. This table also defines the trigger and how it is used in a transaction.  \\nThere may be additional database tables to configure. The setup for both of those \\nsituations is described in this section. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 96}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 81 \\n▪ “Deal 5A: Group Membership Triggers a Deal” \\nA deal trigger checks to see if the customer is in the EMPLOYEE group. This \\nexample also requires that any groups evaluated by the trigger must be set up in the \\ntable com_code_value.  \\n▪ “Deal 5B: Coupon Triggers a Deal” \\nA deal is triggered if a coupon is scanned during a transaction. This deal requires \\nsetup work in the table dsc_coupon_xref. Information in the table links the coupon to \\nthe deal trigger, and specifies the ring code, barcode or serial number input that \\ntriggers the deal. \\nDeal 5A: Group Membership Triggers a Deal \\nThis example provides the database table configuration that checks whether or not a \\ncustomer is included in the EMPLOYEE group before a deal is applied. If the customer is \\na member of the EMPLOYEE group, a 15% transaction discount will be applied \\nautomatically. \\nprc_deal Table: Deal 5A \\n \\nTable 7-1: prc_deal Table Setup for Deal 5A: Group Membership Triggers a Deal \\nField Value: Deal 5A \\norganization_id 1 \\ndeal_id EMPDISC \\ndescription Employee 15% Discount \\nconsumable FALSE(0) \\nact_deferred FALSE(0) \\neffective_date Null \\nend_date Null \\nstart_time Null \\nend_time Null \\ngenerosity_cap -1.000000 \\niteration_cap -1 \\npriority_nudge 20 \\nsubtotal_min Null \\nsubtotal_max Null \\ntrwide_action PERCENT_OFF \\ntrwide_amount 15.000000 \\ntaxability_code Null \\norg_code * \\norg_value * \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 97}, page_content='Using Deal Triggers \\n82 \\nField Value: Deal 5A \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag FALSE(0) \\ntargeted_flag FALSE(0) \\nprc_deal_trig Table: Deal 5A \\n \\nTable 7-2: prc_deal_trig Table Setup for Deal 5A: Group Membership Triggers a Deal \\nField Value: Deal 5A \\norganization_id 1 \\ndeal_id EMPDISC \\ndeal_trigger CUSTGROUP:EMPLOYEE \\norg_code * \\norg_value * \\ncom_code_value Table: Deal 5A \\n \\nTable 7-3: com_code_value Table Setup for Deal 5A: Group Membership Triggers a Deal \\nField Value: Deal 5A \\norganization_id 1 \\ncategory CUSTOMER_GROUPS \\ncode EMPLOYEE \\norg_code * \\norg_value * \\ndescription Employee \\nsort_order 3 \\nhidden_flag FALSE(0) \\nDeal 5B: Coupon Triggers a Deal \\nThis section provides a sample of the database table configuration for a situation in which \\na coupon is scanned and triggers a deal on an item. In this example, the coupon entitles \\nthe customer to buy a specific dress (SKU 1003) for only $10.00. The coupon can be \\nscanned at any point in the transaction, but will only be applied when the specific item is \\nadded to the transaction. \\nprc_deal Table: Deal 5B \\n \\nTable 7-4: prc_deal Table Setup for Deal 5B: Coupon Triggers a Deal '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 98}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 83 \\nField Value: Deal 5B \\norganization_id 1 \\ndeal_id DRESS COUPON \\ndescription Get Dress for $10 with Coupon \\nconsumable FALSE(0) \\nact_deferred FALSE(0) \\neffective_date Null \\nend_date Null \\nstart_time Null \\nend_time Null \\ngenerosity_cap -1.000000 \\niteration_cap -1 \\npriority_nudge 20 \\nsubtotal_min Null \\nsubtotal_max Null \\ntrwide_action Null \\ntrwide_amount Null \\ntaxability_code Null \\norg_code * \\norg_value * \\npromotion_id Null \\nhigher_nonaction_amt_flag FALSE(0) \\nexclude_price_override_flag FALSE(0) \\nexclude_discounted_flag FALSE(0) \\ntargeted_flag FALSE(0) \\n \\n  '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 99}, page_content='Using Deal Triggers \\n84 \\nprc_deal_item Table: Deal 5B \\n \\nTable 7-5: prc_deal_item Table Setup for Deal 5B: Coupon Triggers a Deal \\nField Value: Deal 5B \\norganization_id 1 \\ndeal_id DRESS COUPON \\nitem_ordinal 1 \\norg_code * \\norg_value * \\nconsumable TRUE(1) \\nqty_min 1.0000 \\nqty_max 1.0000 \\nmin_item_total Null \\ndeal_action NEW_PRICE \\naction_arg 10.00 \\naction_arg_qty Null \\nprc_deal_field_test Table: Deal 5B \\n \\nTable 7-6: prc_deal_field_test Table Setup for Deal 5B: Coupon Triggers a Deal \\nField Value: Deal 5B \\norganization_id 1 \\ndeal_id DRESS COUPON \\nitem_ordinal 1 \\nitem_condition_seq 1 \\norg_code * \\norg_value * \\nitem_condition_group 1 \\nitem_field SKU \\nmatch_rule EQUAL \\nvalue1 1003 \\nvalue2 Null \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 100}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 85 \\nprc_deal_trig Table: Deal 5B \\n \\nTable 7-7: prc_deal_trig Table Setup for Deal 5B: Coupon Triggers a Deal \\nField Value: Deal 5B \\norganization_id 1 \\ndeal_id DRESS COUPON \\ndeal_trigger COUPON:INPUT_COUPON:12345 \\nNote: “12345” represents the ring code, \\nbarcode, or serial number for the coupon. \\norg_code * \\norg_value * \\nrecord_state Null \\ndsc_coupon_xref Table: Deal 5B \\nNote: When no tender_id or discount_code are specified, \\nthis is interpreted as a deal coupon. \\n \\nTable 7-8: dsc_coupon_xref Table for Deal 5B: Coupon Triggers a Deal \\nField Value: Deal 5B \\norganization_id 1 \\ncoupon_serial_nbr 12345 \\nNote: The entry in this field represents the \\nserial number, barcode, or ring code for the \\ncoupon. \\norg_code * \\norg_value * \\ndiscount_code Null \\ntender_id Null \\ncoupon_type INPUT_COUPON \\neffective_date Null \\nexpiration_date Null \\nserialized_flag False \\nNote: Serialized Coupons \\nOracle Retail Xstore Point of Service has the ability to \\nconsume single-use deal coupons originating from Customer \\nEngagement CRM. (dsc_coupon_xref.serialized_flag set to \\nTrue) \\nTo use this feature, the system property \"PromotionServices\" \\nin system.properties must be set to: \\n\"dtv.xst.crm.relate.impl.PromotionServicesFactory”. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 101}, page_content='Using Deal Triggers \\n86 \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 102}, page_content=' \\nOracle Retail Xstore Point of Service Deal Pricing Guide 87 \\n8 \\nDeal Best Pricing \\n \\nOverview \\nOracle Retail Xstore Point-of-Service’s Deal Engine Best Pricing functionality works by \\ncalculating the best deal amount, while at the same time, prevents a customer from \\ngetting a better price by breaking a single transaction into multiple transactions.  \\nThis section uses a few examples to explain this Best Pricing methodology. As you will \\nsee in the following examples, there are certain situations where the lowest -priced item \\nmay not be designated as the “target” item in a buy one, get one (BOGO) type deal. \\nThese examples are provided to help clear up any confusion about Oracle Retail Xstore \\nPoint-of-Service best-deal processing. \\nAssumptions and conventions used in this section: \\nThere is an operating assumption that all items in the examples that follow are either:  \\n▪ “triggers” — the “buy x” items that activate a given application of the deal \\n<OR> \\n▪ “targets” — the “get y” items that receive the deal discount activated by a given set  of \\ntriggers \\nTo further differentiate triggers and targets in the following examples, targets will be \\nhighlighted, while their corresponding triggers will be highlighted in a related, but darker \\ncolor. \\nThe “Deal Group” column in the following examples indicates shared membership in a \\ngiven trigger/target relationship. In other words, all items belonging to the same deal \\ngroup are either triggers or targets for a common, single application of the deal.  \\nIf an item is not involved in the application of a deal, either as a trigger or a target, its deal \\ngroup will be indicated with an asterisk (*). \\nBest Deal Pricing Scenario - Buy 2 Get 1 Free \\nDeal Transaction Example 1 \\n \\nTable 8-1: Transaction 1 \\n# Item Base Price Ext. Price Deal Group \\n1 333 21.90  0.00 A \\n2 444 24.90 24.90 A \\n3 555 29.90 29.90 A \\nThis deal involves three items – two trigger items and a single target item. Since there \\nare only three items in the transaction (and reflecting our assumption that all items are \\neither triggers or targets for this deal), then: \\n▪ all items must belong to the same deal group, and  \\n▪ the lowest-priced item should become the target for the single deal triggered by the \\nother two.  '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 103}, page_content='Deal Best Pricing \\n88 \\nConclusion: \\nThat’s what happens here – the lowest-priced item (21.90) – receives the zero-price deal, \\ncourtesy of the higher-priced (24.90 and 29.90) triggers. \\nDeal Transaction Example 2 \\nTable 8-2: Transaction 2 \\n# Item Base Price Ext. Price Deal Group \\n1 333 21.90 21.90 * \\n2 444 24.90 0.00 A \\n3 555 29.90 29.90 A \\n4 666 29.90 29.90 A \\nNow some explanation is required. If your assumption is that the “lowest-priced” item \\nshould always be discounted”, then this result may look confusing at first.  \\nBy design, Oracle Retail Xstore Point of Service has a “best price” Deal Engine that also \\nworks to ensure that the customer cannot get a better deal just by breaking one purchase \\ninto multiple transactions (though customers can certainly get a worse deal by doing so; \\nfor example, if they were to purchase these four items individually in four separate \\ntransactions).  \\nWhat would happen if Oracle Retail Xstore Point of Service DID NOT use Best Deal \\nPricing? \\nIn this section, we will consider what would happen if Oracle Retail Xstore Point of \\nService always discounted the lowest-priced item of all possible targets, rather than \\ncalculating the best deal.  \\nImportant: These examples (Customer A and Customer B) \\nare provided for illustration purposes only and do not \\nrepresent the way Oracle Retail Xstore Point of Service \\nactually processes deals. \\nTo further clarify this “lowest-priced-item-always” scenario, consider a case involving two \\ncustomers:  \\n▪ one purchasing these four items in a single transaction - Customer A  \\n▪ one purchasing these four items across two separate transactions - Customer B  \\nCustomer A \\nTable 8-3: Customer A - Transaction 1 \\n# Item Base Price Ext. Price Deal Group \\n1 333 21.90 0.00 A \\n2 444 24.90 24.90 A \\n3 555 29.90 29.90 A \\n4 666 29.90 29.90 * \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 104}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 89 \\nTable 8-4: Customer B - Transaction 1 \\n# Item Base Price Ext. Price Deal Group \\n1 333 21.90 21.90 * \\n \\nCustomer B \\nTable 8-5: Customer B - Transaction 2 \\n# Item Base Price Ext. Price Deal Group \\n1 444 24.90 0.00 A \\n2 555 29.90 29.90 A \\n3 666 29.90 29.90 A \\n \\nConclusion: \\nNotice that in this scenario, Customer B receives a better discount than Customer A — \\n24.90 versus 21.90 — despite purchasing the same four items. This is the type of pricing \\ninequity that Oracle Retail Xstore Point-of-Service’s Deal Engine has been designed to \\nprevent. \\nAlgorithm For Item Targets \\nTo simplify this explanation, the complexities of considering multiple deal definitions, or \\nmultiple applications of the same deal, will be ignored. This explanation also assumes, as \\nwith the examples, that all items qualify as both triggers and targets; that is, Buy X Get X \\nas opposed to Buy X Get Y, where X ≠ Y). \\nThe algorithm employed by the Deal Engine to determine which items are targets works \\naccording to the following process: \\n▪ Pre-sort the items in descending order by price. \\n▪ Starting with the highest-priced items, determine all possible combinations of triggers \\nand targets (that is, Deal Groups), based on the assertion that a target’s triggers \\nshould be as close in price to it as possible (a task made easier by the pre-sorting in \\nstep 1). \\n– Exclusive Membership Rule: No item may participate in more than a single \\ngroup, either as a trigger or as a target. \\nNote that there has been some confusion regarding this elimination process, and the \\n“consumable” flag that may be enabled/disabled for a given deal. The consumable \\nflag only affects the composition of groups when considering multiple deals, not \\nmultiple applications of the same deal. In other words, you can optionally allow or \\nprohibit a single item to serve as a trigger or target for multiple deals simultaneously. \\n(However, that’s not relevant to this single-deal scenario). \\n▪ For each possible combination determined in step 2, select as potential targets those \\nitems with the lowest price in the group. \\n▪ Select as the actual target, the highest-priced potential target determined in step 3. \\n \\nApplying the Algorithm to Deal Transaction Example 2 \\nThe table below shows the items purchased in Deal Transaction Example 2. (Refer to \\n“Deal Transaction Example 2” for more information about this transaction). '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 105}, page_content='Deal Best Pricing \\n90 \\nBecause of the restriction in step 2, “No item may participate in more than a single group, \\neither as a trigger or as a target”, only a single group can be created here. And because \\nOracle Retail Xstore Point of Service starts with the most expensive items and works its \\nway down, that group will include all but the lowest-priced item at 21.90. \\n \\nTable 8-6: Deal Transaction 2 \\n# Item Base Price Ext. Price Deal Group \\n1 333 21.90 21.90 * \\n2 444 24.90 0.00 A \\n3 555 29.90 29.90 A \\n4 666 29.90 29.90 A \\n \\nThe table 8-7 below shows the algorithm applied to Deal Transaction Example 2. \\nTable 8-7: Potential trigger/target groups & corresponding deal amount offered by their \\ntargets \\nGroup \\n[items] \\nTrigger \\n#1 \\nTrigger \\n#2 \\nTarget Target \\nAmount \\nGroup \\nAmount \\nBest \\nGroup \\nBest \\nTarget \\nBest Deal \\nAmount \\n \\n    A \\n[2,3,4] \\n \\n3 4 2 24.90  \\n \\n24.90 \\n \\n \\nA \\n \\n \\n2 \\n \\n \\n24.90 2 4 3 29.90 \\n2 3 4 29.90 \\nSo, from this group, Oracle Retail Xstore Point of Service selects the lowest-priced item \\nto act as the group’s target candidate – item #2 at 24.90. And, since it’s the only group in \\nthe scenario, that’s the item chosen as the actual target for the deal. \\nAdditional Best-Pricing Deal Examples \\nThe following deal examples show transactions with more than four items. A table \\nshowing how the algorithm was applied to achieve the deal results is also provided, along \\nwith a brief explanation.  \\nDeal Transaction Example 3 \\nIn Deal Transaction Example 3, only a single three-item group—the one that includes all \\nthree highest-priced 29.90 items—can be assembled, due to the exclusive membership \\nrule. (See the restriction defined in step 2).  \\nThe lowest-priced item in this group is irrelevant because all three items have the same \\nprice (29.90). Any one of the items is eligible, but the applied deal amount will be 29.90.  '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 106}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 91 \\nTable 8-8: Transaction 3 \\n# Item Base Price Ext. Price Deal Group \\n1 333 21.90 21.90 * \\n2 444 24.90 24.90 * \\n3 555 29.90 29.90 A \\n4 666 29.90 29.90 A \\n5 777 29.90 0.00 A \\nApplying the Algorithm to Deal Transaction Example 3 \\nNote: In this example, Oracle Retail Xstore Point-of-\\nService’s choice of item #5 is arbitrary, but is internally \\nconsistent. \\n \\nTable 8-9: Potential trigger/target groups & corresponding deal amount offered by their \\ntargets \\nGroup \\n[items] \\nTrigger \\n#1 \\nTrigger \\n#2 \\nTarget Target \\nAmount \\nGroup \\nAmount \\nBest \\nGroup \\nBest \\nTarget \\nBest Deal \\nAmount \\n \\n    A \\n[3,4,5] \\n \\n4 5 3 29.90  \\n \\n29.90 \\n \\n \\nA \\n \\n \\n3,4,5 \\n \\n \\n29.90 3 5 4 29.90 \\n3 4 5 29.90 \\nDeal Transaction Example 4 \\nIn Deal Transaction Example 4, there are six trigger/target items, which means the deal \\nmust be applied twice. Selecting two targets is just a natural extension of selecting one \\n(as shown in the previous examples). In this scenario, an additional “best tar get” must be \\nselected using the same highest-of-the-lowest logic we’ve been using. \\n \\nTable 8-10: Transaction 4 \\n# Item Base Price Ext. Price Deal Group \\n1 333 21.90 21.90 B \\n2 444 24.90 24.90 B \\n3 555 29.90 29.90 A \\n4 666 29.90 29.90 A \\n5 777 29.90 0.00 A \\n6 333 21.90 0.00 B \\nNote: Again, as in Deal Transaction Example 3 on page 8, \\nOracle Retail Xstore Point-of-Service’s choice of item #5 as \\nopposed to #3 or #4, and its choice of #6 as opposed to #1, \\nare arbitrary. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 107}, page_content='Deal Best Pricing \\n92 \\nApplying the Algorithm to Deal Transaction Example 4 \\n \\nTable 8-11: Potential trigger/target groups & corresponding deal amount offered by their \\ntargets \\nGroup \\n[items] \\nTrigger \\n#1 \\nTrigger \\n#2 \\nTarget Target \\nAmount \\nGroup \\nAmount \\nBest \\nGroup \\nBest \\nTarget \\nBest \\nDeal \\nAmount \\n \\n    A \\n[3,4,5] \\n4 5 3 29.90  \\n \\n29.90 \\n \\n \\nA \\n \\n \\n3,4,5 \\n \\n \\n29.90 3 5 4 29.90 \\n3 4 5 29.90 \\n \\n    B \\n[1,2,6] \\n2 6 1 21.90  \\n \\n21.90 \\n \\n \\nB \\n \\n \\n \\n1,6 \\n \\n \\n21.90 1 6 2 24.90 \\n1 2 6 21.90 \\nDeal Transaction Example 5 \\nIn Deal Transaction Example 5, an additional item has been added to “Deal Transaction \\nExample 4”. Note that the deals “shift” in this scenario, but the total discount amount \\nstays the same. \\n \\nTable 8-12: Transaction 5 \\n# Item Base Price Ext. Price Deal Group \\n1 333 21.90 0.00 B \\n2 444 24.90 24.90 B \\n3 555 29.90 29.90 A \\n4 666 29.90 29.90 A \\n5 777 29.90 0.00 A \\n6 333 21.90 21.90 * \\n7 444 24.90 24.90 B \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 108}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 93 \\nTable 8-13: Potential trigger/target groups & corresponding deal amount offered by their \\ntargets \\nGroup \\n[items] \\nTrigger \\n#1 \\nTrigger \\n#2 \\nTarget Target \\nAmount \\nGroup \\nAmount \\nBest \\nGroup \\nBest \\nTarget \\nBest \\nDeal \\nAmount \\n \\n    A \\n[3,4,5] \\n4 5 3 29.90  \\n \\n29.90 \\n \\n \\nA \\n \\n \\n3,4,5 \\n \\n \\n29.90 3 5 4 29.90 \\n3 4 5 29.90 \\n \\n    B \\n[1,2,7] \\n2 7 1 21.90  \\n \\n24.90 \\n \\n \\nB \\n \\n \\n1 \\n \\n \\n21.90 1 7 2 24.90 \\n1 2 7 24.90 \\nDeal Transaction Example 6 \\nIn Deal Transaction Example 6, two items have been added to “Deal Transaction \\nExample 5”, resulting in the ability to apply the deal three times. \\n \\nTable 8-14: Transaction 6 \\n# Item Base Price Ext. Price Deal Group \\n1 333 21.90 21.90 C \\n2 444 24.90 24.90 B \\n3 555 29.90 29.90 B \\n4 666 29.90 29.90 A \\n5 777 29.90 0.00 A \\n6 333 21.90 21.90 C \\n7 444 24.90 0.00 B \\n8 333 21.90 0.00 C \\n9 777 29.90 29.90 A \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 109}, page_content='Deal Best Pricing \\n94 \\nTable 8-15: Potential trigger/target groups & corresponding deal amount offered by their \\ntargets \\nGroup \\n[items] \\nTrigger \\n#1 \\nTrigger \\n#2 \\nTarget Target \\nAmount \\nGroup \\nAmount \\nBest \\nGroup \\nBest \\nTarget \\nBest \\nDeal \\nAmount \\n \\n    A \\n[4,5,9] \\n5 9 4 29.90  \\n \\n29.90 \\n \\n \\nA \\n \\n \\n4,5,9 \\n \\n \\n29.90 4 9 5 29.90 \\n4 5 9 29.90 \\n \\n    B \\n[2,3,7] \\n3 7 2 24.90  \\n \\n24.90 \\n \\n \\nB \\n \\n \\n2,7 \\n \\n \\n24.90 2 7 3 29.90 \\n2 3 7 24.90 \\n \\n    C \\n[1,6,8] \\n6 8 1 21.90  \\n \\n21.90 \\n \\n \\nC \\n \\n \\n1,6,8 \\n \\n \\n21.90 1 8 6 21.90 \\n1 6 8 21.90 \\nDeal Best Pricing Results \\nSetting aside some of the apparent arbitrary behavior when selecting from a given set of \\nsame-priced items, the examples in this chapter show how Oracle Retail Xstore Point-of-\\nService’s behavior is consistent with the goal of calculating the best deal amou nt, while \\nalso preventing the customer from achieving better results if a single transaction is \\nbroken into multiple transactions. \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 110}, page_content=' \\nOracle Retail Xstore Point of Service Deal Pricing Guide 95 \\n9 \\nDownload Records \\nOverview \\nThis chapter provides information about the relationship between the DataLoader records \\nand the Oracle Retail Xstore Point-of-Service database deal pricing tables described in \\nthis guide. \\nThe DataLoader is an application designed to adapt flat files of data into relational data \\nthat Oracle Retail Xstore Point of Service can use. These flat files are referred to \\ngenerically as “data files” within the DataLoader.  \\nThe DataLoader treats each line in the file as a record. Every file line begins with a \\ncommand field, followed by a record type field, which is followed by the appropriate data \\nfor that record: \\n▪ The first field in every line is a command field that describes what is to be done with \\nthe record described in the file line. \\n▪ The second field in the line is a record type field that describes the data represented \\nby the record. \\n▪ Subsequent fields contain the appropriate data for that record. \\nFields are typically delimited by an ASCII character and are referred to by the \\nDataLoader via their index number. Field position indices are 1-based, where the \\ncommand is field 1, the record type is field 2, the first piece of actual data is 3, and so on.  \\nFor more information about the DataLoader, refer to Oracle Retail Xstore Point-of-Service \\nHost Interface documentation. \\nFor more information about Oracle Retail Xstore Point-of-Service database tables, refer \\nto the Oracle Retail Xstore Point-of-Service Database Dictionary Guide. \\nDownload Record Layout \\nDEAL Record | prc_deal Table \\n \\nTable 9-1: DEAL Record - prc_deal \\nDEAL mnt  Field \\n# \\nXstore prc_deal Comment \\n  See”prc_deal Table”for more information. \\n   organization_id The unique identifier for a company, association, \\ninstitution, or other enterprise. \\nAction Code 1   Refer to the Oracle Retail Xstore Point-of-Service \\nHost Interface documentation for Action Code \\nvalues. \\nRecord Identifier 2   DEAL \\n\"DealId\"  3 deal_id Unique identifier for the deal. \\n\"Description\" 4 description Brief description of the deal. In some cases, this will \\nbe used as the line item description in the \\ntransaction on line items to which the deal applies. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 111}, page_content='Download Records \\n96 \\nDEAL mnt  Field \\n# \\nXstore prc_deal Comment \\n 5  Not used \\n\"Effective \\nDate\" \\n6 effective_date Date and time on which the deal becomes effective. \\nUsed with \"EndDate\" to determine the calendar \\ndates during which this deal is effective. If Null, deal \\nis retroactively effective. \\n\"EndDate\" 7 end_date Date and time on which the deal expires. Used with \\n\"EffectiveDate\" to determine the calendar dates \\nduring which this deal is effective. If NULL, the end \\ndate for the deal is indefinite. \\n\"StartTime\" 8 start_time Time each day when the deal becomes effective. \\nUsed with \"EndTime\" to determine if a deal is \\nusable during a particular time of day on effective \\ndays. (Allows deals to occur only before, during, or \\nafter a certain time, but on every day). \\nA null value here will result in a deal which is active \\nfrom the beginning of the day. \\n\"EndTime\" 9 end_time Time each day when the deal expires. Used with \\n\"StartTime\" to determine if a deal is usable during a \\nparticular time of day on effective days. (Allows \\ndeals to occur only before, during, or after a certain \\ntime, but on every day). \\nA null value here will result in a deal which has no \\nexpiration during the day(s) which it is applicable. \\n\"Generosity \\nCap\"  \\n10 generosity_cap Used to place an upper limit on the amount that the \\ndeal may discount from the transaction. A deal with \\na generosity cap will never result in a discount of \\nmore than the cap set here. \\nIf this upper limit is reached at any point during the \\napplication of the deal, the deal is applied to the \\nmaximum of this amount. \\n\"IterationCap\"  11 iteration_cap Used to place an upper limit on the number of times \\nthis deal may apply to the same transaction. In the \\ncase of transaction-wide deals, this should always \\nbe 1. In the case of item-based deals, this will \\nindicate the maximum number of times that a set of \\nitems may be matched in the transaction. A setting \\nof -1 will allow for an application to occur for every \\nmatching item set.  \\n\"Priority \\nNudge\" \\n \\n12 priority_nudge The arbitration value between equivalent deals. \\nUsed to provide an ordering of deals which have the \\nsame effect, but in which one may be preferable to \\nthe other. \\n\"Minimum \\nSubtotal\" \\n13 subtotal_min The minimum, pre-deal total amount of the \\ntransaction required for the deal to be applied. \\n\"Maximum \\nSubtotal\" \\n14 subtotal_max The maximum, pre-deal total amount of the \\ntransaction allowed for the deal to be applied. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 112}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 97 \\nDEAL mnt  Field \\n# \\nXstore prc_deal Comment \\n\"TransAction \\nType\" \\n15 trwide_action The method by which the deal will be applied to the \\nitem or transaction.  \\nThis is the type of action to take on the entire \\ntransaction; this should only be used by transaction-\\nwide deals, and deals with a transaction-wide action \\nset should not have actions set for any item rules. \\nThe following values are fixed: \\nNEW_PRICE \\nPERCENT_OFF \\nCURRENCY_OFF \\n\"TransAction \\nAmount\" \\n16 trwide_amount The dollar amount or percentage to be used when \\napplying the deal. Used in combination with the \\nmethod. \\nThis is the amount, or argument, to apply with the \\ntransaction-wide action. For example, if the \\n\"TransActionType\" is \"PercentOff\" this is the \\npercentage discount which this deal will apply. \\n\"Taxability \\nCode\" \\n17 taxability_code Indicates whether the deal should be applied before \\nor after tax is applied to the item or transaction. \\nValid values: \"POST_TAX\" or \\n\"PRE_TAX\"/\"DEFAULT\" \\nWhen \"POST_TAX\", the tax will be calculated \\nbefore the discount is applied. \\nFor any other value, the tax will be calculated after \\nthe discount is applied. \\n\"OrgCode\" 18 org_code Used to define the deal eligibility based on the \\norganization structure. This is the hierarchy level of \\nthe region for which the deal is valid (For example, \\n\"STORE\", \"DIVISION\", \"BRANCH\"). Values can \\ncome from loc_org_hierarchy or \\nloc_pricing_hierarchy. This field is used in \\nconjunction with OrgValue. The configuration to \\ndetermine which hierarchy table a deal is using is \\nfound in system.properties \\ndtv.xst.pricing.refresh.DealRegionHierarchy\\n.  \\n\"OrgValue\" 19 org_value Used to define the deal eligibility based on the \\norganization structure. This value indicates the \\nlocation code of the region for which the deal is \\nvalid. Values can come from loc_org_hierarchy or \\nloc_pricing_hierarchy. This field is used in \\nconjunction with OrgCode. The configuration to \\ndetermine which hierarchy table a deal is using is \\nfound in system.properties \\ndtv.xst.pricing.refresh.DealRegionHierarchy \\n(valid values: \"ORG\" or \"PRICE\"). \\n\"PromotionId\" 20 promotion_id Unique ID indicating the promotion associated with \\nthe deal. \\n\"Higher \\nNonactionAmt\" \\n21 higher_nonaction_amt_ \\nflag \\nIf true, total amount of the trigger item must be \\ngreater than the total discount item amount. For Buy \\nX, Get Y deals, “X” amount must be greater than “Y” \\namount to get the deal.  '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 113}, page_content='Download Records \\n98 \\nDEAL mnt  Field \\n# \\nXstore prc_deal Comment \\n\"ExcludePrice \\nOverride\" \\n22 exclude_price_override_flag If true, items with price changes will not be \\nconsidered for the deal. (exclude price override line \\nitems from the deal). \\n\"Exclude \\nDiscounted\" \\n23 exclude_discounted_flag If true, items with applied discounts/deals will not be \\nconsidered for the deal. (Exclude discounted line \\nitems from the deal). \\nNote: This applies to both manual discounts and \\ndeal discounts. \\n 24  Not used \\n\"Targeted\" 25 targeted_flag If true, indicates that a deal applies only to those \\ncustomers whose records explicitly identify it. If \\nFALSE, the deal is available to the general public, \\nregardless of the customer assigned to the \\ntransaction and in cases where no customer is \\nassigned at all.  \\n\"Deferred\" 26 act_deferred If true, this is a deferred deal. For standard deals \\nwhose actions apply to the current transaction, this \\ncolumn should be false. It will be true when used in \\nconjunction with features like rebates and \\nbounceback coupons. \\n\"UseWeek \\nSchedule\" \\n27 week_sched_flag If true, this deal has a schedule represented in the \\nprc_deal_week table, populated by the \\nDEAL_WEEK record. \\n\"Consumable\" 28 consumable If true, a deal is considered to be exclusive. If this \\ndeal applies, then no other deal can be applied. \\nWorks for transaction-level deals only. \\n“SortOrder” 29 sort_order The deal sort order. Defaults to 0 (Zero). \\n“Type” 30 type Used by the Deal Engine to detect specific deals \\nthat require special handling. \\n  create_date The date and time the record was created.  \\n   create_user_id The identification of the person who created the \\nrecord. \\n   update_date The date and time the record was last updated. \\n   update_user_id The identification of the person who updated the \\nrecord. \\n   record_state The record status.  \\n \\n  '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 114}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 99 \\n \\nTable 9-2: DEAL_ITEM record - prc_deal_item Table \\nDEAL_ITEM mnt Field # Xstore prc_deal_item Comment \\n  See “prc_deal_item Table” for more information. \\n   organization_id The unique identifier for a \\ncompany, association, institution, or \\nother enterprise. \\nAction Code 1   Refer to the Oracle Retail Xstore \\nPoint-of-Service Host Interface \\ndocumentation for Action Code \\nvalues. \\nRecord Identifier 2   DEAL_ITEM \\n\"DealId\"  3 deal_id Unique identifier for the deal. \\nCorresponds to prc_deal.deal_id \\n\"Ordinal\" 4 item_ordinal Defines the order in which the \\nitems are matched during the \\nexecution of the Deal Engine. This \\nis the ordinal of this item within the \\nitems to be matched by the deal. \\nEssentially, this column is a \\nsequence which resets to 1 for \\neach deal. \\n\"Consumable\" 5 consumable Default to True(1) except for rebate \\nand free gift card deal. \\nIf true, a deal has item matching \\nrules which consume the items that \\nthey match. (Item consumption is \\nlargely inapplicable to deferred \\ndeals). Any item rules in \\nsubsequent deals which could \\nmatch and consume the item will \\nbe unable to match an already \\nconsumed item. This allows deals \\nto exclude each other based on \\nwhat items they have matched.  \\nNote: This flag only affects the \\ncomposition of groups when \\nconsidering multiple deals, not \\nmultiple applications of the same \\ndeal. This flag is used to either \\nallow or prohibit a single item to \\nserve as a trigger or target for \\nmultiple deals simultaneously. \\n\"MinQty\" 6 qty_min Minimum quantity of this item \\nrequired to satisfy this item rule. A \\nMinQty of 0 puts no lower bound on \\nthe range. \\n\"MaxQty\"  7 qty_max Maximum quantity of this item \\nrequired to satisfy this item rule. \\n\"MinItemTotal\" 8 min_item_total Minimum subtotal of items \\nmatching this rule required to \\nsatisfy this item rule. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 115}, page_content='Download Records \\n100 \\nDEAL_ITEM mnt Field # Xstore prc_deal_item Comment \\n\"ActionType\" 9 deal_action Identifies how the deal is applied. \\nThe following values are fixed: \\nNEW_PRICE \\nPERCENT_OFF \\nCURRENCY_OFF \\n\"ActionArg\" 10 action_arg The amount that is applied on the \\ndeal, whether it is a new price, a \\ndollar discount, or a percentage \\ndiscount. \\n\"ActionArgQty\" 11 action_arg_qty Indicates the total number of items \\nto which the action is applied (and \\nthus, are required for the deal) as \\nreferenced by action_arg and \\ndeal_action. \\nFor example, if item A can be \\npurchased at 3 for $10, action_arg \\nwill be 10 and action_arg_qty will \\nbe 3 for this deal. Whereas, if item \\nA can be purchased at 3 for $10 \\neach (for a total of $30), action_arg \\nwill be 10 and action_arg_qty will \\nbe 1 for this deal. \\nNote: A special value of -1 is used \\nto apply action_arg to the actual \\nnumber of items that qualified for a \\ndeal. \\nFor example: Spend $100 and get \\na $10 discount deal...  \\nqty_min will be set to 1, qty_max \\nwill be set to -1, min_total will be \\nset to 100.00, action_arg will be set \\nto 10.00.  \\nWe want $10 to be split among all \\nqualifying items, but we don\\'t know \\nat this time how many items the \\ncustomer will buy, thus we need to \\nset action_arg_qty to -1. \\n\"OrgCode\" 15 org_code The organization level code based \\non the customer’s store structure. \\nFor example: STORE, DISTRICT, \\nREGION, or CHAIN. (to be defined \\nby clients) \\nDefault value set to * \\n\"OrgValue\" 16 org_value The value for the organization level \\ncode. For example: for store 123, \\nthe org_code will be STORE and \\nthe org_value will be 123) \\nDefault value set to * \\n   create_date The date and time the record was \\ncreated.  \\n   create_user_id The identification of the person who \\ncreated the record. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 116}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 101 \\nDEAL_ITEM mnt Field # Xstore prc_deal_item Comment \\n   update_date The date and time the record was \\nlast updated. \\n   update_user_id The identification of the person who \\nupdated the record. \\n   record_state The record status.  \\nDEAL_ITEM record | prc_deal_item Table \\n \\nTable 9-3: DEAL_ITEM_TEST record - prc_deal_field_test Table \\nDEAL_ITEM_TEST mnt Field # Xstore prc_deal_field_test Comment \\n  See “prc_deal_field_test Table” for more information. \\n   organization_id The unique identifier for a \\ncompany, association, \\ninstitution, or other \\nenterprise. \\nAction Code 1   Refer to the Oracle Retail \\nXstore Point-of-Service \\nHost Interface \\ndocumentation for Action \\nCode values. \\nRecord Identifier 2   DEAL_ITEM_TEST \\n\"DealId\"  3 deal_id Unique identifier for the \\ndeal. Corresponds to \\nprc_deal.deal_id \\n\"Ordinal\" 4 item_ordinal Unique identifier of a deal-\\nto-item mapping. \\nCorresponds to the item \\nordinal for the rule in which \\nthis field match is \\nincorporated. The ordinal \\ndefines the order in which \\nthe items are matched and \\ncorresponds to the \\n\"Ordinal\" field in the \\nDEAL_ITEM record. (The \\nDEAL_ITEM record \\ndefines the discounts or \\nactions taken on the items \\nwhen the deal is applied). '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 117}, page_content='Download Records \\n102 \\nDEAL_ITEM_TEST mnt Field # Xstore prc_deal_field_test Comment \\n\"Field\" 5 item_field Identifies the field in the \\nITEM record that is used \\nto determine how the deal \\nshould be applied to an \\nitem. The following values \\nare fixed: \\nUSE \\nSKU \\nQUANTITY \\nPRICE \\nMERCHLEVEL1 \\nMERCHLEVEL2 \\nMERCHLEVEL3 \\nMERCHLEVEL4 \\nVENDOR \\nMANUFACTURER \\nSEASON \\nSTYLE \\nEMPLOYEE \\nSALE_ITEM_TYPE_ONLY \\nITEM_STOCK_STATUS \\nDIMENSION1 \\nDIMENSION2 \\nDIMENSION3 \\nPRICE_OVERRIDE \\nDISCOUNTED \\nSEQ_NUMBER \\nITEM_PROPERTY \\n\"MatchRule\" 6 match_rule The comparison that will \\nbe used (on the values in \\nitem_field \"Field\") to \\ndetermine whether a deal \\nshould be applied to an \\nitem. The following values \\nare fixed:  \\nEQUAL \\nNOT_EQUAL \\nGREATER \\nLESS \\nBETWEEN \\n\"Value1\" 7 value1 The value that will be used \\nby the Match Rule to \\ncompare with the values in \\nitem_field (\"Field\"). If only \\none value is needed for \\nthe comparison, the value \\nin this field will be used. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 118}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 103 \\nDEAL_ITEM_TEST mnt Field # Xstore prc_deal_field_test Comment \\n\"Value2\" 8 value2 The value that will be used \\nby the Match Rule to \\ncompare with the values in \\nitem_field (\"Field\"). If a \\nsecond value is needed for \\nthe comparison (For \\nexample, BETWEEN), the \\nvalue in this field will be \\nused. \\n\"ItemCondition \\nSeq\" \\n9 item_condition_seq Indicates the sequence in \\nwhich two item conditions \\nwith the same \\n\"ItemConditionGroup\" \\nnumber are performed. \\nThis ensures a unique \\nprimary key for each \\nrecord. Used to support \\n“compound” (that is, \\nAND/OR grouped) deals. \\nDefault=”1” \\n\"ItemCondition \\nGroup\" \\n10 item_condition_group Allows for a deal to have \\nseveral different, individual \\ntests that are combined to \\nform a test group.  \\nEach different item \\ncondition group represents \\na condition that must be \\nsatisfied for the deal to \\napply. Different item \\ncondition groups represent \\nOR logic. Any group that is \\nsatisfied will result in the \\ndeal applying.  \\nTests that are part of the \\nsame item condition group \\nrepresent AND logic. All \\ntests within an item \\ncondition group must be \\nsatisfied in order for the \\ngroup to be satisfied. \\nFor example, if Condition \\nA and Condition B have a \\ndifferent value for \\n\"ItemConditionGroup\", \\nthe relationship will be \\n(Condition A OR Condition \\nB).  \\nIf Condition A and \\nCondition B have the \\nsame value for \\n\"ItemConditionGroup\", \\nthe relationship will be \\nCondition A AND \\nCondition B. \\nDefault=”1” '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 119}, page_content='Download Records \\n104 \\nDEAL_ITEM_TEST mnt Field # Xstore prc_deal_field_test Comment \\n\"OrgCode\" 11 org_code The organization level \\ncode based on the \\ncustomer’s store structure. \\nFor example: STORE, \\nDISTRICT, REGION, or \\nCHAIN. (to be defined by \\nclients) \\nDefault value set to * \\n\"OrgValue\" 12 org_value The value for the \\norganization level code. \\nFor example: for store \\n123, the org_code will be \\nSTORE and the org_value \\nwill be 123) \\nDefault value set to * \\n   create_date The date and time the \\nrecord was created.  \\n   create_user_id The identification of the \\nperson who created the \\nrecord. \\n   update_date The date and time the \\nrecord was last updated. \\n   update_user_id The identification of the \\nperson who updated the \\nrecord. \\n  record_state The record status.  \\nDEAL_ITEM_TEST record | prc_deal_field_test Table \\nDEAL_TRIGGER record | prc_deal_trig Table \\nImportant: The DEAL_TRIGGER_EXCLUDE record type is \\nidentical to the DEAL_TRIGGER record, but inserts a tilde \\n(~) for exclusions automatically. Download records can \\neither manually include this character (field #5 in the \\nDEAL_TRIGGER type) or instead opt for the \\nDEAL_TRIGGER_EXCLUDE record type. Refer to the \\nOracle Retail Xstore Point-of-Service Host Interface Guide \\nfor more information about these record types. \\n \\nTable 9-4: DEAL_TRIGGER record - prc_deal_trig Table \\nDEAL_TRIGGER mnt Field # Xstore \\nprc_deal_trig \\nComment \\n  See “prc_deal_trig Table” for more information. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 120}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 105 \\nDEAL_TRIGGER mnt Field # Xstore \\nprc_deal_trig \\nComment \\n  organization_id The unique identifier for a \\ncompany, association, \\ninstitution, or other \\nenterprise. \\nAction Code 1  Refer to the Oracle Retail \\nXstore Point-of-Service Host \\nInterface documentation for \\nAction Code values. \\nRecord Identifier 2  DEAL_TRIGGER \\n\"DealId\" 3 deal_id Unique identifier for the \\ndeal. Corresponds to \\nprc_deal.deal_id \\nNote: COUPON_DEAL \\nrecord also updates \\nprc_deal_trig.deal_id \\nTrigger Type* \\n(See Note below) \\n4 deal_trigger The type of trigger deal, \\nsuch as “CUSTGROUP”. \\nNote: COUPON_DEAL \\nrecord also updates \\nprc_deal_trig.deal_trigger \\nTrigger Value* \\n(See Note below) \\n5 deal_trigger The value that will trigger \\nthe deal such as \\n“EMPLOYEE”. \\nNote: COUPON_DEAL \\nrecord also updates \\nprc_deal_trig.deal_trigger \\n\"OrgCode\" 6 org_code The organization level code \\nbased on the customer’s \\nstore structure. For \\nexample: STORE, \\nDISTRICT, REGION, or \\nCHAIN. (to be defined by \\nclients) \\nDefault value set to * \\n\"OrgValue\" 7 org_value The value for the \\norganization level code. For \\nexample: for store 123, the \\norg_code will be STORE \\nand the org_value will be \\n123) \\nDefault value set to * \\n  create_date The date and time the \\nrecord was created.  \\n  create_user_id The identification of the \\nperson who created the \\nrecord. \\n  update_date The date and time the \\nrecord was last updated. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 121}, page_content='Download Records \\n106 \\nDEAL_TRIGGER mnt Field # Xstore \\nprc_deal_trig \\nComment \\n  update_user_id The identification of the \\nperson who updated the \\nrecord. \\n  record_state The record status.  \\nNote: The Trigger Type (Field #4) and the Trigger Value that \\ntriggers the deal (Field #5) are automatically concatenated \\nand separated with a “:” as a single entry in the database \\ncolumn prc_deal_trig.deal_trigger. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 122}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 107 \\nTable 9-5: REBATE record - *multiple Tables \\nREBATE mnt Field \\n# \\nXstore Table.column Comment \\n  organization_id The unique \\nidentifier for a \\ncompany, \\nassociation, \\ninstitution, or \\nother enterprise. \\nAction Code 1  Refer to the \\nOracle Retail \\nXstore Point-of-\\nServiceHost \\nInterface \\ndocumentation for \\nAction Code \\nvalues. \\nRecord Identifier 2  REBATE \\n\"DealId\" 3 prc_deal.deal_id \\nprc_deal_document_xref. \\ndeal_id \\nThe unique deal \\nidentifier. \\n\"Description\" 4 prc_deal.description Brief description \\nof the rebate. \\n 5  Not used. \\n\"EffectiveDate\" 6 prc_deal.effective_date \\ndoc_document_definition. \\nstart_redeem_date \\ndoc_document_definition. \\nstart_issue_date \\nDate and time on \\nwhich the rebate \\nbecomes \\neffective. \\n\"EndDate\" 7 prc_deal.end_date \\ndoc_document_definition. \\nend_redeem_date \\ndoc_document_definition. \\nend_issue_date \\nDate and time on \\nwhich the rebate \\nexpires. \\n\"StartTime\" 8 prc_deal.start_time Time each day \\nwhen the rebate \\nbecomes \\neffective. \\n\"EndTime\" 9 prc_deal.end_time Time each day \\nwhen the rebate \\nis no longer \\neffective. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 123}, page_content='Download Records \\n108 \\nREBATE mnt Field \\n# \\nXstore Table.column Comment \\n\"GenerosityCap\" 10 prc_deal.generosity_cap The maximum \\nbenefit amount \\nthat can be \\napplied to a \\ntransaction when \\nusing the rebate.  \\nIf this upper limit \\nis reached at any \\npoint during the \\napplication of the \\ndeal, the deal is \\napplied to the \\nmaximum of this \\namount. \\n\"IterationCap\" 11 prc_deal.iteration_cap Used to place an \\nupper limit on the \\nnumber of times \\nthis rebate deal \\nmay apply to the \\nsame transaction. \\n\"PriorityNudge\" 12 prc_deal.priority_nudge The arbitration \\nvalue between \\nequivalent deals. \\nUsed to provide \\nan ordering of \\ndeals which have \\nthe same effect, \\nbut in which one \\nmay be preferable \\nto the other. \\n\"Minimum \\nSubtotal\" \\n13 prc_deal.subtotal_min The minimum, \\npre-rebate total \\namount of the \\ntransaction \\nrequired for the \\nrebate to be \\napplied. \\n\"TransAction \\nType\" \\n14 prc_deal.trwide_action The method by \\nwhich the rebate \\nwill be applied to \\nthe item or \\ntransaction. The \\nfollowing values \\nare fixed: \\nNEW_PRICE \\nPERCENT_OFF \\nCURRENCY_OF\\nF '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 124}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 109 \\nREBATE mnt Field \\n# \\nXstore Table.column Comment \\n\"TransAction \\nAmount\" \\n15 prc_deal.trwide_amount The dollar amount \\nor percentage to \\nbe used when \\napplying the \\nrebate. Used in \\ncombination with \\nthe method. \\n\"SeriesId\" 16 doc_document_def_properties. \\nseries_id \\ndoc_document_definition \\n.series_id \\nprc_deal_document_xref.series_id \\nIdentifier for a \\nseries and its \\npromotional time \\nframe. \\n\"DocumentType\" 17 doc_document_def_ \\nproperties.document_type \\ndoc_document_definition \\n.document_type \\nprc_deal_document_xref \\n.document_type \\nIdentifier for the \\ntype of document \\nthat will be \\nprovided for the \\nrebate. \\n\"FileName\" 18 doc_document_definition \\n.file_name \\nThe file name of \\nthe rebate form to \\nbe printed when \\nissuing a rebate. \\n\"VendorId\" 19 doc_document_definition \\n.vendor_id \\nUnique ID \\nindicating the \\nvendor associated \\nwith the rebate. \\nUsed for lookups \\nwhen reprinting \\ndocuments. \\n\"Description\" 20 doc_document_definition \\n.description \\nA description of \\nthe rebate. \\n\"TextCodeValue\" 21 doc_document_definition \\n.text_code_value \\nIdentifier for the \\ntext that will print \\non the rebate \\nreceipt. This value \\nis used to retrieve \\ntext from the \\ncom_receipt_text \\ntable; for both \\nreceipt type and \\nsegment type. \\nUsed from \\nRcptConfig.xml in \\na Textblock to tie \\nin a block of text \\nfrom \\ncom_receipt_text. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 125}, page_content='Download Records \\n110 \\nREBATE mnt Field \\n# \\nXstore Table.column Comment \\n\"OrgCode\" 22 *multiple tables.org_code \\n<Dao  \\nname=\"Deal\"> \\n<Dao name=\"DealDocumentXref\"> \\n<Dao name=\"DocumentDefinition\"> \\n<Dao \\nname=\"DocumentDefinitionProperties\"> \\nThe organization \\nlevel code based \\non the customer’s \\nstore structure. \\nFor example: \\nSTORE, \\nDISTRICT, \\nREGION, or \\nCHAIN. (to be \\ndefined by clients) \\nDefault value set \\nto * \\n\"OrgValue\" 23 *multiple tables.org_value \\n<Dao  \\nname=\"Deal\"> \\n<Dao name=\"DealDocumentXref\"> \\n<Dao name=\"DocumentDefinition\"> \\n<Dao \\nname=\"DocumentDefinitionProperties\"> \\nThe value for the \\norganization level \\ncode. For \\nexample: for store \\n123, the org_code \\nwill be STORE \\nand the org_value \\nwill be 123) \\nDefault value set \\nto * \\n  create_date Multiple tables \\n  create_user_id Multiple tables \\n  update_date Multiple tables \\n  update_user_id Multiple tables \\n  record_state Multiple tables \\nREBATE record | *multiple Tables \\n \\nTable 9-6: CODE_VALUE record - com_code_value Table \\nCODE_VALUE mnt Field # Xstore \\ncom_code_value Table \\nComment \\n  See “CODE_VALUE record | com_code_value Table” or \\nan example of this table in use. \\n  organization_id The unique identifier for a \\ncompany, association, \\ninstitution, or other \\nenterprise. \\nAction Code 1  Refer to the Oracle Retail \\nXstore Point-of-Service \\nHost Interface \\ndocumentation for Action \\nCode values. \\nRecord Identifier 2  CODE_VALUE '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 126}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 111 \\nCODE_VALUE mnt Field # Xstore \\ncom_code_value Table \\nComment \\n“Category” 3 category The code value category \\nidentifier, used for \\ngrouping multiple codes. \\n“Code” 4 code The code value for a \\ncategory. \\n“Description” 5 description A text description of the \\ncode. \\n“SortOrder” 6 sort_order Used to sort codes within \\na category for display. \\n“Hidden” 7 hidden_flag Determines whether or not \\nthis code is displayed to \\nthe user.  \\nFalse or NULL = the code \\nwill be displayed. \\nTrue = the code will not be \\ndisplayed. \\n\"OrgCode\" 8 org_code The organization level \\ncode based on the \\ncustomer’s store structure. \\nFor example: STORE, \\nDISTRICT, REGION, or \\nCHAIN. (to be defined by \\nclients) \\nDefault value set to * \\n\"OrgValue\" 9 org_value The value for the \\norganization level code. \\nFor example: for store \\n123, the org_code will be \\nSTORE and the org_value \\nwill be 123) \\nDefault value set to * \\n  create_date The date and time the \\nrecord was created.  \\n  create_user_id The identification of the \\nperson who created the \\nrecord. \\n  update_date The date and time the \\nrecord was last updated. \\n  update_user_id The identification of the \\nperson who updated the \\nrecord. \\n  record_state The record status.  \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 127}, page_content='Download Records \\n112 \\nCODE_VALUE record | com_code_value Table \\n \\nTable 9-7: COUPON_XREF record - dsc_coupon_xref \\nCOUPON_XREF mnt Field \\n# \\nXstore \\ndsc_coupon_xref \\nTable \\nComment \\n  See “COUPON_XREF record | dsc_coupon_xref Table” for an \\nexample of this table in use. \\n  organization_id The unique identifier for a company, \\nassociation, institution, or other \\nenterprise. \\nAction Code 1  Refer to the Oracle Retail Xstore Point-\\nof-Service Host Interface \\ndocumentation for Action Code values. \\nRecord Identifier 2  COUPON_XREF \\n\"CouponSerial \\nNumber\"  \\n3 coupon_serial_nbr The entry in this field represents the \\nserial number, barcode, or ring code for \\nthe coupon. \\nNote: COUPON_DEAL Record also \\nupdates dsc_coupon_xref.coupon_ \\nserial_nbr \\n\"DiscountCode\" 4 discount_code Unique identifier of a discount. \\n*A value must be specified for either \\ndiscount_code or tender_id. \\n\"TenderId\" 5 tender_id Unique identifier of a tender coupon. \\n*A value must be specified for either \\ndiscount_code or tender_id. \\n\"EffectiveDate\" 6 effective_date Date and time the coupon reference \\nbecomes effective. \\nNote: COUPON_DEAL Record also \\nupdates \\ndsc_coupon_xref.effective_date \\n\"Expiration \\nDate\" \\n7 expiration_date Date and time the coupon reference \\nexpires. \\nNote: COUPON_DEAL Record also \\nupdates \\ndsc_coupon_xref.expiration_date \\n\"CouponType\" 8 coupon_type A code for the type of coupon. For \\nexample, INPUT_COUPON. \\n\"Serialized\" 9 serialized_flag If true, this is a serialized coupon type. \\n\"OrgCode\" 10 org_code The organization level code based on \\nthe customer’s store structure. For \\nexample: STORE, DISTRICT, \\nREGION, or CHAIN. (to be defined by \\nclients) \\nDefault value set to * '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 128}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 113 \\nCOUPON_XREF mnt Field \\n# \\nXstore \\ndsc_coupon_xref \\nTable \\nComment \\n\"OrgValue\" 11 org_value The value for the organization level \\ncode. For example: for store 123, the \\norg_code will be STORE and the \\norg_value will be 123) \\nDefault value set to * \\n  create_date The date and time the record was \\ncreated.  \\n  create_user_id The identification of the person who \\ncreated the record. \\n  update_date The date and time the record was last \\nupdated. \\n  update_user_id The identification of the person who \\nupdated the record. \\n  record_state The record status.  \\nCOUPON_XREF record | dsc_coupon_xref Table \\nNote: When no tender_id or discount_code are specified, \\nthis is interpreted as a deal coupon. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 129}, page_content='Download Records \\n114 \\nDEAL_CUST_GROUPS record | prc_deal_cust_groups Table \\n \\nTable 9-8: DEAL_CUST_GROUPS record - prc_deal_cust_groups Table \\nDEAL_CUST_GROUPS \\nmnt \\nField # Xstore \\nprc_deal_cust_groups \\nComment \\n  organization_id The unique identifier for a \\ncompany, association, \\ninstitution, or other \\nenterprise. \\nAction Code 1  Refer to the Oracle Retail \\nXstore Point-of-Service \\nHost Interface \\ndocumentation for Action \\nCode values. \\nRecord Identifier 2  DEAL_CUST_GROUPS \\n\"DealId\" 3 deal_id Unique identifier for the \\ndeal. Corresponds to \\nprc_deal.deal_id \\n\"CustomerGroup \\nId\" \\n4 cust_group_id Unique identifier for a \\ncustomer group. \\n\"OrgCode\" 5 org_code The organization level code \\nbased on the customer’s \\nstore structure. For \\nexample: STORE, \\nDISTRICT, REGION, or \\nCHAIN. (to be defined by \\nclients) \\nDefault value set to * \\n\"OrgValue\" 6 org_value The value for the \\norganization level code. For \\nexample: for store 123, the \\norg_code will be STORE \\nand the org_value will be \\n123) \\nDefault value set to * \\n  create_date The date and time the \\nrecord was created.  \\n  create_user_id The identification of the \\nperson who created the \\nrecord. \\n  update_date The date and time the \\nrecord was last updated. \\n  update_user_id The identification of the \\nperson who updated the \\nrecord. \\n  record_state The record status.  \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 130}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 115 \\nDEAL_WEEK record | prc_deal_week Table \\n \\nTable 9-9: DEAL_WEEK record - prc_deal_week \\nDEAL_WEEK mnt Field # Xstore \\nprc_deal_week \\nComment \\n  organization_id The unique identifier for a \\ncompany, association, \\ninstitution, or other \\nenterprise. \\nAction Code 1  Refer to the Oracle Retail \\nXstore Point-of-Service \\nHost Interface \\ndocumentation for Action \\nCode values. \\nRecord Identifier 2  DEAL_WEEK \\n\"DealId\" 3 deal_id Unique identifier for the \\ndeal. Corresponds to \\nprc_deal.deal_id \\n\"DayCode\" 4 day_code The code representing the \\nday to apply the deal: \\nSUN, MON, TUE, WED, \\nTHU, FRI, SAT \\n\"StartTime\" 5 start_time The starting time of the deal \\nfor the given day. \\n\"EndTime\" 6 end_time The ending time of the deal \\nfor the given day. \\n\"OrgCode\" 7 org_code The organization level code \\nbased on the customer’s \\nstore structure. For \\nexample: STORE, \\nDISTRICT, REGION, or \\nCHAIN. (to be defined by \\nclients) \\nDefault value set to * \\n\"OrgValue\" 8 org_value The value for the \\norganization level code. For \\nexample: for store 123, the \\norg_code will be STORE \\nand the org_value will be \\n123) \\nDefault value set to * \\n  create_date The date and time the \\nrecord was created.  \\n  create_user_id The identification of the \\nperson who created the \\nrecord. \\n  update_date The date and time the \\nrecord was last updated. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 131}, page_content='Download Records \\n116 \\nDEAL_WEEK mnt Field # Xstore \\nprc_deal_week \\nComment \\n  update_user_id The identification of the \\nperson who updated the \\nrecord. \\nCOUPON_DEAL record | *multiple Tables \\nFields 3-23, 25-27 - Updates the prc_deal table (See “DEAL Record | prc_deal Table”) \\nFields 3, 18-19, 24 - Updates the prc_deal_trig table (See “DEAL_TRIGGER record | \\nprc_deal_trig Table”) \\nFields 6-7, 18-19, 24, 28 - Updates the dsc_coupon_xref table (See “COUPON_XREF \\nrecord | dsc_coupon_xref Table”) \\nNote: Refer to the Oracle Retail Xstore Point-of-Service Host \\nInterface Guide for more information. \\n '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 132}, page_content=' \\nOracle Retail Xstore Point of Service Deal Pricing Guide 117 \\nAppendix \\nRevision History \\nRevision History Version 23.0.0 \\nXstore \\nPoint-of-\\nService \\nVersion \\nDocument \\nVersion \\nDetail \\n23.0 01 ▪ Initial doc \\n23.0 02 ▪ changed department, subdepartment, class and subclass to \\nMERCHLEVEL 1-4 \\nRevision History Version 22.0 \\nXstore \\nPoint-of-\\nService \\nVersion \\nDocument \\nVersion \\nDetail \\n22.0 01 ▪ prc_deal_field_test Table added ANY_ITEM value to Item field \\nRevision History Version 20.0 \\nXstore \\nPoint-of-\\nService \\nVersion \\nDocument \\nVersion \\nDetail \\n20.0 01 ▪ added prc_deal_loc Table to Ancillary Deal Tables section \\nRevision History Version 19.0 \\nXstore \\nPoint-of-\\nService \\nVersion \\nDocument \\nVersion \\nDetail \\n19.0 01 ▪ Updated min_item_total description in prc_deal_item Table \\nsection \\n▪ Removed Deal C:section in chapter 4 Merchandise Level Subtotal \\nDeals \\n▪ Updated Merchandise Level Subtotal Deals section \\n▪ Updated Ancillary Deal Tables section '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 133}, page_content='Revision History \\n118 \\nRevision History Version 18.0 \\nXstore \\nPoint-of-\\nService \\nVersion \\nDocument \\nVersion \\nDetail \\n18.0 01 General proofreading. \\n18.0 02 Updated DealSetupConfig.xml to pricing.xml \\nRevision History Version 17.0 \\nXstore \\nPoint-of-\\nService \\nVersion \\nDocument \\nVersion \\nDetail \\n17.0 01 General proofreading. \\n17.0 02 Updated DealSetupConfig.xml to pricing.xml \\nRevision History Version 16.0 \\nXstore \\nPoint-of-\\nService \\nVersion \\nDocument \\nVersion \\nDetail \\n16.0 01 General proofreading. \\nRevision History Version 15.0 \\nXstore \\nPoint-of-\\nService \\nVersion \\nDocument \\nVersion \\nDetail \\n15.0 01 Updated to Oracle Layout. \\nprc_deal Table – field group_id added \\nRevision History Version 7.1 \\nXstore \\nPoint-of-\\nService \\nVersion \\nDocument \\nVersion \\nDetail \\n7.1 01 Updated cover pages and added note regarding re-branding. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 134}, page_content='Oracle Retail Xstore Point of Service 23.0.0 \\nOracle Retail Xstore Point of Service Deal Pricing Guide 119 \\nRevision History Version 7.0 \\nXstore \\nVersion \\nDocument \\nVersion \\nDetail \\n7.0 01 Added processing flow information \\nprc_deal_field_test.item_field; changed valid value from SHIP_SALE \\nto SEND_SALE. Note: All references of SHIP_SALE were changed to \\nSEND_SALE throughout the system. \\nRevision History Version 6.5 \\nXstore \\nVersion \\nDocument \\nVersion \\nDetail \\n6.5 01 Removed references to substitute price deals. This deal type is no \\nlonger supported in base. (prc_deal_item.field_sub, \\nprc_deal_item.sub_percent_change, and \\nprc_deal_item.sub_currency_change) \\nAdded prc_deal.sort_order and prc_deal.type \\nAdded XML Configuration section \\nRevision History Version 6.0 \\nXstore \\nVersion \\nDocument \\nVersion \\nDetail \\n6.0 01 Added deferred deal example for a sale \\nRevision History Version 5.5 \\nXstore \\nVersion \\nDocument \\nVersion \\nDetail \\n5.5 01 Updated the description for action_arg_qty in the prc_deal_item table. \\nA special value of -1 will apply action_arg to the actual number of \\nitems that qualified for a deal. \\nAdded Merchandise Level Subtotal Deals chapter. \\nUpdated prc_deal_field_test table: \\nadded item_field, ITEM_PROPERTY. \\nadded new information for value1 rules if using ITEM_PROPERTY \\nitem_field. \\nadded new information for match_rule. \\nAdded Item Properties Deal example. \\nUpdated prc_deal.exclude_discounted_flag description. This flag \\napplies to both manual discounts and deal discounts. \\nAdded consumable attribute to the prc_deal table. \\nAdded image and explanation for deal display in Xstore. '),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 135}, page_content='Revision History \\n120 \\nRevision History: Version 4.0 through 5.0 \\nXstore Version Document \\nVersion \\nDetail \\n4.0 01 Added SQL server data type information for date and time \\nfields. \\nAdded day/time-specific information. \\n4.0.1 02 Added deal trigger information. \\n4.5 01 Added reference for finding Kit information.  \\n4.8 01 Doc reformatted, added serialized coupon information \\n4.8 02 Updated per QA Regression Testing \\n5.0 01 Updated for DB changes: org_code and org_value added \\nto tables with a default value of * \\n5.0 02 Removed Gift Card as a deferred deal option - not \\nsupported. \\n ')]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8uRXu6LFzyd"
      },
      "source": [
        "There are many different ways to split a document. For this example, we'll use a simple splitter that splits the document into chunks of a fixed size. Check [Text Splitters](https://python.langchain.com/docs/modules/data_connection/document_transformers/) for more information about different approaches to splitting documents.\n",
        "\n",
        "For illustration purposes, let's split the transcription into chunks of 100 characters with an overlap of 20 characters and display the first few chunks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1desXu9Fzyd",
        "outputId": "8fdc61a0-3395-47ba-babb-5030b94db25d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'transcription.txt'}, page_content=\"I think it's possible that physics has exploits and we should be trying to find them. arranging some\"),\n",
              " Document(metadata={'source': 'transcription.txt'}, page_content='arranging some kind of a crazy quantum mechanical system that somehow gives you buffer overflow,'),\n",
              " Document(metadata={'source': 'transcription.txt'}, page_content='buffer overflow, somehow gives you a rounding error in the floating point. Synthetic intelligences'),\n",
              " Document(metadata={'source': 'transcription.txt'}, page_content=\"intelligences are kind of like the next stage of development. And I don't know where it leads to.\"),\n",
              " Document(metadata={'source': 'transcription.txt'}, page_content='where it leads to. Like at some point, I suspect the universe is some kind of a puzzle. These')]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
        "text_splitter.split_documents(text_documents)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
        "text_splitter.split_documents(xstore_documents)[:5]"
      ],
      "metadata": {
        "id": "9RiVlMvdB5fg",
        "outputId": "cb4e25bc-97c0-4a2b-df42-eb4938464591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 0}, page_content='Oracle® Retail Xstore Point of Service \\nDeal Pricing Guide \\nRelease 23.0.0 \\nF80981-02'),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 0}, page_content='F80981-02 \\nAugust 2023'),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 1}, page_content='Oracle® Retail Xstore Point of Service Deal Pricing Guide, Release 23.0.0 \\nF80981-02'),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 1}, page_content='F80981-02 \\nCopyright © 2023, Oracle and/or its affiliates. All rights reserved. \\nPrimary Author:'),\n",
              " Document(metadata={'source': 'xstoresuite-2300-dpg.pdf', 'page': 1}, page_content='This software and related documentation are provided under a license agreement containing')]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NievBEm5Fzyd"
      },
      "source": [
        "For our specific application, let's use 1000 characters instead:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "iOHXJrfzFzyd"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "text_documents = text_splitter.split_documents(text_documents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "xstore_documents = text_splitter.split_documents(xstore_documents)"
      ],
      "metadata": {
        "id": "fh8jQJCdDUwy"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i-36VTUFzyd"
      },
      "source": [
        "## Finding the relevant chunks\n",
        "\n",
        "Given a particular question, we need to find the relevant chunks from the transcription to send to the model. Here is where the idea of **embeddings** comes into play.\n",
        "\n",
        "An embedding is a mathematical representation of the semantic meaning of a word, sentence, or document. It's a projection of a concept in a high-dimensional space. Embeddings have a simple characteristic: The projection of related concepts will be close to each other, while concepts with different meanings will lie far away. You can use the [Cohere's Embed Playground](https://dashboard.cohere.com/playground/embed) to visualize embeddings in two dimensions.\n",
        "\n",
        "To provide with the most relevant chunks, we can use the embeddings of the question and the chunks of the transcription to compute the similarity between them. We can then select the chunks with the highest similarity to the question and use them as the context for the model:\n",
        "\n",
        "<img src='https://github.com/haoransun/youtube-rag/blob/main/images/system3.png?raw=1' width=\"1200\">\n",
        "\n",
        "Let's generate embeddings for an arbitrary query:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vYu7tbFFzyd",
        "outputId": "1b63fa1e-5444-4895-ed99-5914240b6a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding length: 768\n",
            "[-0.03004870004951954, 0.05798434093594551, -0.021751737222075462, 0.01909419521689415, -0.023824144154787064, 0.04075177013874054, -0.00881603267043829, -0.021996544674038887, -0.024955572560429573, 0.01082204282283783]\n"
          ]
        }
      ],
      "source": [
        "# from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.embeddings import HuggingFaceHubEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceHubEmbeddings()\n",
        "embedded_query = embeddings.embed_query(\"Who is Mary's sister?\")\n",
        "\n",
        "print(f\"Embedding length: {len(embedded_query)}\")\n",
        "print(embedded_query[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHw0ORBcFzye"
      },
      "source": [
        "To illustrate how embeddings work, let's first generate the embeddings for two different sentences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "Od9ymJq3Fzye"
      },
      "outputs": [],
      "source": [
        "sentence1 = embeddings.embed_query(\"Mary's sister is Susana\")\n",
        "sentence2 = embeddings.embed_query(\"Pedro's mother is a teacher\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8jAhAjtFzye"
      },
      "source": [
        "We can now compute the similarity between the query and each of the two sentences. The closer the embeddings are, the more similar the sentences will be.\n",
        "\n",
        "We can use [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) to calculate the similarity between the query and each of the sentences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh0oZZxfFzye",
        "outputId": "f18305bb-0dde-4800-b4b3-f892cce3c2f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7945074985667395, 0.23615689012730634)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "query_sentence1_similarity = cosine_similarity([embedded_query], [sentence1])[0][0]\n",
        "query_sentence2_similarity = cosine_similarity([embedded_query], [sentence2])[0][0]\n",
        "\n",
        "query_sentence1_similarity, query_sentence2_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRBcH7i1Fzye"
      },
      "source": [
        "## Setting up a Vector Store\n",
        "\n",
        "We need an efficient way to store document chunks, their embeddings, and perform similarity searches at scale. To do this, we'll use a **vector store**.\n",
        "\n",
        "A vector store is a database of embeddings that specializes in fast similarity searches.\n",
        "\n",
        "<img src='https://github.com/haoransun/youtube-rag/blob/main/images/system4.png?raw=1' width=\"1200\">\n",
        "\n",
        "To understand how a vector store works, let's create one in memory and add a few embeddings to it:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docarray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYx3zr13CLtA",
        "outputId": "f900c397-0e7f-42e2-8014-5eb485f39225"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: docarray in /usr/local/lib/python3.10/dist-packages (0.40.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from docarray) (1.26.4)\n",
            "Requirement already satisfied: orjson>=3.8.2 in /usr/local/lib/python3.10/dist-packages (from docarray) (3.10.12)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from docarray) (2.10.3)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.10/dist-packages (from docarray) (13.9.4)\n",
            "Requirement already satisfied: types-requests>=2.28.11.6 in /usr/local/lib/python3.10/dist-packages (from docarray) (2.32.0.20241016)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from docarray) (0.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->docarray) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->docarray) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->docarray) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray) (2.18.0)\n",
            "Requirement already satisfied: urllib3>=2 in /usr/local/lib/python3.10/dist-packages (from types-requests>=2.28.11.6->docarray) (2.2.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->docarray) (1.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "qOj4Xw91Fzye"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
        "\n",
        "vectorstore1 = DocArrayInMemorySearch.from_texts(\n",
        "    [\n",
        "        \"Mary's sister is Susana\",\n",
        "        \"John and Tommy are brothers\",\n",
        "        \"Patricia likes white cars\",\n",
        "        \"Pedro's mother is a teacher\",\n",
        "        \"Lucia drives an Audi\",\n",
        "        \"Mary has two siblings\",\n",
        "    ],\n",
        "    embedding=embeddings,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAh_R6PdFzye"
      },
      "source": [
        "We can now query the vector store to find the most similar embeddings to a given query:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLXvC1uUFzye",
        "outputId": "867994f0-5b46-4193-974a-529185d814d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(metadata={}, page_content='Mary has two siblings'),\n",
              "  0.8007960942903177),\n",
              " (Document(metadata={}, page_content=\"Mary's sister is Susana\"),\n",
              "  0.7945075519110865),\n",
              " (Document(metadata={}, page_content='Lucia drives an Audi'),\n",
              "  0.3152865457025518)]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "vectorstore1.similarity_search_with_score(query=\"Who is Mary's sister?\", k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyK0a44LFzyj"
      },
      "source": [
        "## Connecting the vector store to the chain\n",
        "\n",
        "We can use the vector store to find the most relevant chunks from the transcription to send to the model. Here is how we can connect the vector store to the chain:\n",
        "\n",
        "<img src='https://github.com/haoransun/youtube-rag/blob/main/images/chain4.png?raw=1' width=\"1200\">\n",
        "\n",
        "We need to configure a [Retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/). The retriever will run a similarity search in the vector store and return the most similar documents back to the next step in the chain.\n",
        "\n",
        "We can get a retriever directly from the vector store we created before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GKW53FAFzyj",
        "outputId": "1d281ba8-ebd3-4060-c8ed-50943cc9b434"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='Mary has two siblings'),\n",
              " Document(metadata={}, page_content=\"Mary's sister is Susana\"),\n",
              " Document(metadata={}, page_content='Lucia drives an Audi'),\n",
              " Document(metadata={}, page_content='John and Tommy are brothers')]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "retriever1 = vectorstore1.as_retriever()\n",
        "retriever1.invoke(\"Who is Mary's sister?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiHV9UviFzyj"
      },
      "source": [
        "Our prompt expects two parameters, \"context\" and \"question.\" We can use the retriever to find the chunks we'll use as the context to answer the question.\n",
        "\n",
        "We can create a map with the two inputs by using the [`RunnableParallel`](https://python.langchain.com/docs/expression_language/how_to/map) and [`RunnablePassthrough`](https://python.langchain.com/docs/expression_language/how_to/passthrough) classes. This will allow us to pass the context and question to the prompt as a map with the keys \"context\" and \"question.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FUSWS6BFzyj",
        "outputId": "0cc1f96b-12d8-4032-9fe4-ca86157fdac3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': [Document(metadata={}, page_content='Patricia likes white cars'),\n",
              "  Document(metadata={}, page_content='Lucia drives an Audi'),\n",
              "  Document(metadata={}, page_content=\"Pedro's mother is a teacher\"),\n",
              "  Document(metadata={}, page_content=\"Mary's sister is Susana\")],\n",
              " 'question': \"What color is Patricia's car?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "setup = RunnableParallel(context=retriever1, question=RunnablePassthrough())\n",
        "setup.invoke(\"What color is Patricia's car?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGKE4C6jFzyj"
      },
      "source": [
        "Let's now add the setup map to the chain and run it:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "hAUd4W8GFzyj",
        "outputId": "d541ffde-f399-4193-b01d-d9c5ad148ef8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "HfHubHTTPError",
          "evalue": "500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/google/gemma-2-2b-it (Request ID: idxsz5lMRI1K4P_OLs6rO)\n\nModel too busy, unable to get response in less than 60 second(s)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/google/gemma-2-2b-it",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-bc585bf64770>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mchain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What color is Patricia's car?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         return (\n\u001b[0;32m--> 390\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    391\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    753\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    754\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m                 )\n\u001b[1;32m    949\u001b[0m             ]\n\u001b[0;32m--> 950\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    951\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             output = (\n\u001b[0;32m--> 779\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    780\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m             text = (\n\u001b[0;32m-> 1502\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/huggingface_hub.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_model_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         response = self.client.post(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"parameters\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;31m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;31m# as well (request id and/or server error message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/google/gemma-2-2b-it (Request ID: idxsz5lMRI1K4P_OLs6rO)\n\nModel too busy, unable to get response in less than 60 second(s)"
          ]
        }
      ],
      "source": [
        "chain = setup | prompt | model | parser\n",
        "chain.invoke(\"What color is Patricia's car?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2KCLRk8Fzyj"
      },
      "source": [
        "Let's invoke the chain using another example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "8CvZchpdFzyj",
        "outputId": "6c281451-36e5-41ea-d6ca-44222bd23c98"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "HfHubHTTPError",
          "evalue": "500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/google/gemma-2-2b-it (Request ID: mj2uLzIV0tAKNrvWld15y)\n\nModel too busy, unable to get response in less than 60 second(s)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/google/gemma-2-2b-it",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-17c78db8f8a9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What car does Lucia drive?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         return (\n\u001b[0;32m--> 390\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    391\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    753\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    754\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m                 )\n\u001b[1;32m    949\u001b[0m             ]\n\u001b[0;32m--> 950\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    951\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             output = (\n\u001b[0;32m--> 779\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    780\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m             text = (\n\u001b[0;32m-> 1502\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/huggingface_hub.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_model_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         response = self.client.post(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"parameters\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;31m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;31m# as well (request id and/or server error message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/google/gemma-2-2b-it (Request ID: mj2uLzIV0tAKNrvWld15y)\n\nModel too busy, unable to get response in less than 60 second(s)"
          ]
        }
      ],
      "source": [
        "chain.invoke(\"What car does Lucia drive?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM8tjmnnFzyk"
      },
      "source": [
        "## Loading transcription into the vector store\n",
        "\n",
        "We initialized the vector store with a few random strings. Let's create a new vector store using the chunks from the video transcription."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sx9XDz6Fzyk"
      },
      "outputs": [],
      "source": [
        "vectorstore2 = DocArrayInMemorySearch.from_documents(documents, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lmTtjKtFzyk"
      },
      "source": [
        "Let's set up a new chain using the correct vector store. This time we are using a different equivalent syntax to specify the [`RunnableParallel`](https://python.langchain.com/docs/expression_language/how_to/map) portion of the chain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "EV_IIwn0Fzyk",
        "outputId": "9b1818b1-954c-460a-9b0e-46e1440608fb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "HfHubHTTPError",
          "evalue": "500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/google/gemma-2-2b-it (Request ID: kN-tQIm4Gs-c2zfcgidO6)\n\nModel too busy, unable to get response in less than 60 second(s)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/google/gemma-2-2b-it",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-1921064f7456>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m|\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is synthetic intelligence?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         return (\n\u001b[0;32m--> 390\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    391\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    753\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    754\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m                 )\n\u001b[1;32m    949\u001b[0m             ]\n\u001b[0;32m--> 950\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    951\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             output = (\n\u001b[0;32m--> 779\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    780\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m             text = (\n\u001b[0;32m-> 1502\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/huggingface_hub.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_model_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         response = self.client.post(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"parameters\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;31m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;31m# as well (request id and/or server error message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/google/gemma-2-2b-it (Request ID: kN-tQIm4Gs-c2zfcgidO6)\n\nModel too busy, unable to get response in less than 60 second(s)"
          ]
        }
      ],
      "source": [
        "chain = (\n",
        "    {\"context\": vectorstore2.as_retriever(), \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | parser\n",
        ")\n",
        "chain.invoke(\"What is synthetic intelligence?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVc08tfMFzyk"
      },
      "source": [
        "## Setting up Pinecone\n",
        "\n",
        "So far we've used an in-memory vector store. In practice, we need a vector store that can handle large amounts of data and perform similarity searches at scale. For this example, we'll use [Pinecone](https://www.pinecone.io/).\n",
        "\n",
        "The first step is to create a Pinecone account, set up an index, get an API key, and set it as an environment variable `PINECONE_API_KEY`.\n",
        "\n",
        "Then, we can load the transcription documents into Pinecone:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is required\n",
        "os.environ['PINECONE_API_KEY'] = 'pcsk_7LGVBg_CJMCAcnPB15MchbNFAxvyXKjhAXvzG76cnXV23C8b51hqVpqAtw6JBAATafyr3M'\n",
        "\n"
      ],
      "metadata": {
        "id": "ITeiEheGCfq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcW9or_eFzyk"
      },
      "outputs": [],
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "index_name = \"youtube-index2\"\n",
        "# The dimension is 768 to match the index created on Pinecone\n",
        "pinecone = PineconeVectorStore.from_documents(\n",
        "    documents, embeddings, index_name=index_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_name"
      ],
      "metadata": {
        "id": "nEA_jY5_7Vp0",
        "outputId": "55d0a4d8-3e2f-4ecf-d809-95664e514a74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pinecone.data.index.Index at 0x7d9e4503e320>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIrZPRAtFzyk"
      },
      "source": [
        "Let's now run a similarity search on pinecone to make sure everything works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmSi4bdOFzyk",
        "outputId": "c928aafe-fd04-45f7-ce2f-430badeee995"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='915f1c24-3ae1-4c81-bfaf-496b7a4859a9', metadata={'source': 'transcription.txt'}, page_content=\"It's like high quality audio and you're speaking usually pretty clearly. I don't know what open AI's plans are either. Yeah, there's always fun projects basically. And stable diffusion also is opening up a huge amount of experimentation. I would say in the visual realm and generating images and videos and movies. I'll think like videos now. And so that's going to be pretty crazy. That's going to almost certainly work and it's going to be really interesting when the cost of content creation is going to fall to zero. You used to need a painter for a few months to paint a thing and now it's going to be speak to your phone to get your video. So Hollywood will start using it to generate scenes, which completely opens up. Yeah, so you can make a movie like Avatar eventually for under a million dollars. Much less. Maybe just by talking to your phone. I mean, I know it sounds kind of crazy. And then there'd be some voting mechanism. Like how do you have a, like, would there be a show on\"),\n",
              " Document(id='cbc83c89-c77e-4ce6-acca-76893a88e6e2', metadata={'source': 'transcription.txt'}, page_content=\"get to another celebrity and might get into other big accounts. And then it'll just, so with just that simple goal, get them to respond. Yeah. Maximize the probability of actual response. Yeah, I mean, you could prompt a powerful model like this with their, it's opinion about how to do any possible thing you're interested in. So they will check us. They're kind of on track to become these oracles. I could sort of think of it that way. They are oracles currently is just text, but they will have calculators, they will have access to Google search, they will have all kinds of gadgets and gizmos, they will be able to operate the internet and find different information. And yeah, in some sense, that's kind of like currently what it looks like in terms of the development. Do you think it'll be an improvement eventually over what Google is for access to human knowledge? Like it'll be a more effective search engine to access human knowledge. I think there's definitely scope in building a\"),\n",
              " Document(id='e55bb1ac-b8d5-4245-a92b-932f04fa4bd3', metadata={'source': 'transcription.txt'}, page_content=\"there be a show on Netflix that's generated completely automatically? So, yeah, and what does it look like also when you can generate it on demand? And it's, and there's infinity of it. Yeah. Oh, man. All the synthetic content. I mean, it's humbling because we treat ourselves as special for being able to generate art and ideas and all that kind of stuff. If that can be done in an automated way by AI. Yeah. I think it's fascinating to me how these, the predictions of AI and what it's going to look like and what it's going to be capable of are completely inverted and wrong. And sci-fi of 50s and 60s is just like totally not right. They imagine AI as like super calculating their approvers and we're getting things that can talk to you about emotions. It can do art. It's just like weird. Are you excited about that feature? Just AI's like hybrid systems, heterogeneous systems of humans and AI's talking about emotions, Netflix and children and AI system that's where the Netflix thing you\")]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "pinecone.similarity_search(\"What is Hollywood going to start doing?\")[:3]\n",
        "# return 3 most similar docs related to your question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-3G8gKBFzyl"
      },
      "source": [
        "Let's setup the new chain using Pinecone as the vector store:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "lvC-3KkaFzyl",
        "outputId": "6dfe9113-214f-491b-a81d-2a89940f4456"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "HfHubHTTPError",
          "evalue": "500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/google/gemma-2-2b-it (Request ID: qph4cFRZTk2vLwcuCvT_R)\n\nModel too busy, unable to get response in less than 60 second(s)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/google/gemma-2-2b-it",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-303e385250c5>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is Hollywood going to start doing?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         return (\n\u001b[0;32m--> 390\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    391\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    753\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    754\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m                 )\n\u001b[1;32m    949\u001b[0m             ]\n\u001b[0;32m--> 950\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    951\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             output = (\n\u001b[0;32m--> 779\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    780\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m             text = (\n\u001b[0;32m-> 1502\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/huggingface_hub.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_model_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         response = self.client.post(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"parameters\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;31m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;31m# as well (request id and/or server error message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/google/gemma-2-2b-it (Request ID: qph4cFRZTk2vLwcuCvT_R)\n\nModel too busy, unable to get response in less than 60 second(s)"
          ]
        }
      ],
      "source": [
        "chain = (\n",
        "    {\"context\": pinecone.as_retriever(), \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | parser\n",
        ")\n",
        "\n",
        "chain.invoke(\"What is Hollywood going to start doing?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3K9zm_qFzyl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}